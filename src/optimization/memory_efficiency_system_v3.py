# -*- coding: utf-8 -*-
"""
ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 (Memory Efficiency System v3.0)
RTX3080æœ€é©åŒ–çµ±åˆãƒ»è‡ªå‹•ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ»å‹•çš„ãƒãƒƒãƒ•ã‚¡ç®¡ç†

ä¸»è¦æ©Ÿèƒ½:
1. RTX3080 VRAM/RAM æœ€é©åŒ–
2. è‡ªå‹•ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
3. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ»ä¿®å¾©
4. å‹•çš„ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºèª¿æ•´
5. OOMäºˆé˜²ã‚·ã‚¹ãƒ†ãƒ 
6. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ
"""

import gc
import os
import sys
import time
import threading
import psutil
import json
import logging
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass, field
from collections import deque, defaultdict
from pathlib import Path
import weakref

# GPUé–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import torch
    import torch.cuda
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("WARNING: PyTorch not detected: CPU optimization only")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from .rtx3080_optimizer import RTX3080Optimizer
    from ..integration.cross_suppression_engine import SessionMemoryBuffer
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“ç‰ˆã‚’ä½¿ç”¨
    RTX3080Optimizer = None
    SessionMemoryBuffer = None


@dataclass
class MemorySnapshot:
    """ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: float
    process_rss_mb: float
    process_vms_mb: float
    system_available_mb: float
    system_used_percent: float
    gpu_allocated_mb: Optional[float] = None
    gpu_reserved_mb: Optional[float] = None
    gpu_free_mb: Optional[float] = None
    cache_size_mb: float = 0.0
    buffer_count: int = 0
    gc_count: int = 0


@dataclass
class MemoryAlert:
    """ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ãƒ¼ãƒˆ"""
    level: str  # INFO, WARNING, CRITICAL
    message: str
    timestamp: float
    metrics: Dict[str, Any] = field(default_factory=dict)
    recovery_action: Optional[str] = None


class MemoryEfficiencySystemV3:
    """
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0
    RTX3080çµ±åˆãƒ»è‡ªå‹•æœ€é©åŒ–ãƒ»äºˆé˜²çš„ç®¡ç†
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # åŸºæœ¬è¨­å®š
        self.monitoring_enabled = self.config.get('monitoring_enabled', True)
        self.auto_gc_enabled = self.config.get('auto_gc_enabled', True)
        self.leak_detection_enabled = self.config.get('leak_detection_enabled', True)
        self.oom_prevention_enabled = self.config.get('oom_prevention_enabled', True)
        
        # RTX3080æœ€é©åŒ–
        self.rtx3080_optimization = self.config.get('rtx3080_optimization', True)
        self.gpu_memory_target_percent = self.config.get('gpu_memory_target_percent', 85.0)
        
        # ç›£è¦–è¨­å®š
        self.monitoring_interval = self.config.get('monitoring_interval', 1.0)  # ç§’
        self.snapshot_history_size = self.config.get('snapshot_history_size', 1000)
        self.leak_detection_window = self.config.get('leak_detection_window', 300)  # 5åˆ†
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤
        self.warning_threshold_percent = self.config.get('warning_threshold_percent', 85.0)
        self.critical_threshold_percent = self.config.get('critical_threshold_percent', 95.0)
        self.gpu_warning_threshold_percent = self.config.get('gpu_warning_threshold_percent', 90.0)
        
        # GCè¨­å®š
        self.gc_trigger_threshold_mb = self.config.get('gc_trigger_threshold_mb', 100.0)
        self.aggressive_gc_threshold_percent = self.config.get('aggressive_gc_threshold_percent', 90.0)
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.snapshot_history: deque = deque(maxlen=self.snapshot_history_size)
        self.alert_history: deque = deque(maxlen=100)
        
        # çµ±è¨ˆ
        self.stats = {
            'total_snapshots': 0,
            'total_alerts': 0,
            'gc_triggers': 0,
            'leak_detections': 0,
            'oom_preventions': 0,
            'memory_recovered_mb': 0.0
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒãƒƒãƒ•ã‚¡ç®¡ç†
        self.managed_caches: Dict[str, weakref.WeakValueDictionary] = {}
        self.managed_buffers: Dict[str, Any] = {}
        
        # RTX3080æœ€é©åŒ–å™¨
        self.rtx_optimizer = None
        if self.rtx3080_optimization and RTX3080Optimizer:
            try:
                self.rtx_optimizer = RTX3080Optimizer(self.config)
                print("âœ… RTX3080æœ€é©åŒ–å™¨çµ±åˆå®Œäº†")
            except Exception as e:
                print(f"âš ï¸ RTX3080æœ€é©åŒ–å™¨åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # ç·Šæ€¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.emergency_callbacks: List[Callable] = []
        
        # ãƒ­ã‚°è¨­å®š
        self.logger = self._setup_logging()
        
        print(f"ğŸš€ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 åˆæœŸåŒ–å®Œäº†")
        print(f"   â”œâ”€ RTX3080æœ€é©åŒ–: {'æœ‰åŠ¹' if self.rtx_optimizer else 'ç„¡åŠ¹'}")
        print(f"   â”œâ”€ è‡ªå‹•GC: {'æœ‰åŠ¹' if self.auto_gc_enabled else 'ç„¡åŠ¹'}")
        print(f"   â”œâ”€ ãƒªãƒ¼ã‚¯æ¤œå‡º: {'æœ‰åŠ¹' if self.leak_detection_enabled else 'ç„¡åŠ¹'}")
        print(f"   â”œâ”€ OOMäºˆé˜²: {'æœ‰åŠ¹' if self.oom_prevention_enabled else 'ç„¡åŠ¹'}")
        print(f"   â””â”€ ç›£è¦–é–“éš”: {self.monitoring_interval}ç§’")

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger('MemoryEfficiencyV3')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger

    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if self.is_monitoring:
            self.logger.warning("ç›£è¦–ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
            return
        
        self.is_monitoring = True
        self.snapshot_history.clear()
        self.alert_history.clear()
        
        # åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        initial_snapshot = self._take_memory_snapshot()
        self.snapshot_history.append(initial_snapshot)
        
        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.monitor_thread = threading.Thread(
            target=self._monitoring_loop, 
            daemon=True,
            name="MemoryMonitorV3"
        )
        self.monitor_thread.start()
        
        self.logger.info(f"ğŸ” ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹ (é–“éš”: {self.monitoring_interval}ç§’)")
        
        # RTX3080æœ€é©åŒ–é©ç”¨
        if self.rtx_optimizer:
            self._apply_rtx3080_optimizations()

    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        if not self.is_monitoring:
            return
        
        self.is_monitoring = False
        
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        
        # æœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_efficiency_report()
        self.logger.info(f"ğŸ›‘ ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢ - çµ±è¨ˆ: {final_stats['summary']}")

    def _monitoring_loop(self):
        """ç›£è¦–ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        while self.is_monitoring:
            try:
                # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—
                snapshot = self._take_memory_snapshot()
                self.snapshot_history.append(snapshot)
                self.stats['total_snapshots'] += 1
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆè©•ä¾¡
                alerts = self._evaluate_alerts(snapshot)
                for alert in alerts:
                    self._handle_alert(alert)
                
                # è‡ªå‹•GCè©•ä¾¡
                if self.auto_gc_enabled:
                    self._evaluate_auto_gc(snapshot)
                
                # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º
                if self.leak_detection_enabled and len(self.snapshot_history) > 20:
                    self._detect_memory_leaks()
                
                # OOMäºˆé˜²
                if self.oom_prevention_enabled:
                    self._prevent_oom(snapshot)
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(max(self.monitoring_interval, 1.0))

    def _take_memory_snapshot(self) -> MemorySnapshot:
        """ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—"""
        process = psutil.Process()
        memory_info = process.memory_info()
        system_memory = psutil.virtual_memory()
        
        # GPUçµ±è¨ˆ
        gpu_allocated_mb = None
        gpu_reserved_mb = None
        gpu_free_mb = None
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            try:
                gpu_allocated_mb = torch.cuda.memory_allocated() / (1024 ** 2)
                gpu_reserved_mb = torch.cuda.memory_reserved() / (1024 ** 2)
                
                # ç©ºãVRAMè¨ˆç®—
                if self.rtx_optimizer:
                    total_vram = self.rtx_optimizer.gpu_info.get('memory_total', 10240)
                    gpu_free_mb = total_vram - gpu_reserved_mb
                
            except Exception as e:
                self.logger.debug(f"GPUçµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
        cache_size_mb = sum(
            sys.getsizeof(cache) / (1024 ** 2) 
            for cache in self.managed_caches.values()
        )
        
        buffer_count = len(self.managed_buffers)
        gc_count = sum(gc.get_count())
        
        return MemorySnapshot(
            timestamp=time.time(),
            process_rss_mb=memory_info.rss / (1024 ** 2),
            process_vms_mb=memory_info.vms / (1024 ** 2),
            system_available_mb=system_memory.available / (1024 ** 2),
            system_used_percent=system_memory.percent,
            gpu_allocated_mb=gpu_allocated_mb,
            gpu_reserved_mb=gpu_reserved_mb,
            gpu_free_mb=gpu_free_mb,
            cache_size_mb=cache_size_mb,
            buffer_count=buffer_count,
            gc_count=gc_count
        )

    def _evaluate_alerts(self, snapshot: MemorySnapshot) -> List[MemoryAlert]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆè©•ä¾¡"""
        alerts = []
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ãƒ¼ãƒˆ
        if snapshot.system_used_percent >= self.critical_threshold_percent:
            alerts.append(MemoryAlert(
                level="CRITICAL",
                message=f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒå±é™ºãƒ¬ãƒ™ãƒ«: {snapshot.system_used_percent:.1f}%",
                timestamp=snapshot.timestamp,
                metrics={"memory_percent": snapshot.system_used_percent},
                recovery_action="emergency_gc"
            ))
        elif snapshot.system_used_percent >= self.warning_threshold_percent:
            alerts.append(MemoryAlert(
                level="WARNING",
                message=f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„: {snapshot.system_used_percent:.1f}%",
                timestamp=snapshot.timestamp,
                metrics={"memory_percent": snapshot.system_used_percent},
                recovery_action="soft_gc"
            ))
        
        # GPUãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ãƒ¼ãƒˆ
        if snapshot.gpu_reserved_mb and snapshot.gpu_free_mb:
            gpu_usage_percent = (snapshot.gpu_reserved_mb / (snapshot.gpu_reserved_mb + snapshot.gpu_free_mb)) * 100
            
            if gpu_usage_percent >= self.gpu_warning_threshold_percent:
                alerts.append(MemoryAlert(
                    level="WARNING",
                    message=f"GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„: {gpu_usage_percent:.1f}%",
                    timestamp=snapshot.timestamp,
                    metrics={"gpu_usage_percent": gpu_usage_percent},
                    recovery_action="gpu_cache_clear"
                ))
        
        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªæ€¥å¢—ã‚¢ãƒ©ãƒ¼ãƒˆ
        if len(self.snapshot_history) >= 2:
            prev_snapshot = self.snapshot_history[-2]
            memory_growth = snapshot.process_rss_mb - prev_snapshot.process_rss_mb
            
            if memory_growth > self.gc_trigger_threshold_mb:
                alerts.append(MemoryAlert(
                    level="INFO",
                    message=f"ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªæ€¥å¢—: +{memory_growth:.1f}MB",
                    timestamp=snapshot.timestamp,
                    metrics={"memory_growth_mb": memory_growth},
                    recovery_action="preventive_gc"
                ))
        
        return alerts

    def _handle_alert(self, alert: MemoryAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†"""
        self.alert_history.append(alert)
        self.stats['total_alerts'] += 1
        
        # ãƒ­ã‚°å‡ºåŠ›
        log_level = getattr(self.logger, alert.level.lower(), self.logger.info)
        log_level(f"ğŸš¨ {alert.message}")
        
        # å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        if alert.recovery_action:
            recovered_mb = self._execute_recovery_action(alert.recovery_action)
            if recovered_mb > 0:
                self.stats['memory_recovered_mb'] += recovered_mb
                self.logger.info(f"âœ… ãƒ¡ãƒ¢ãƒªå›å¾©: {recovered_mb:.1f}MB")

    def _execute_recovery_action(self, action: str) -> float:
        """å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        memory_before = psutil.Process().memory_info().rss / (1024 ** 2)
        
        try:
            if action == "emergency_gc":
                self._emergency_garbage_collection()
            elif action == "soft_gc":
                self._soft_garbage_collection()
            elif action == "preventive_gc":
                self._preventive_garbage_collection()
            elif action == "gpu_cache_clear":
                self._clear_gpu_cache()
            elif action == "cache_cleanup":
                self._cleanup_managed_caches()
            
            time.sleep(0.1)  # GCå®Œäº†å¾…æ©Ÿ
            
        except Exception as e:
            self.logger.error(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ '{action}' å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
        
        memory_after = psutil.Process().memory_info().rss / (1024 ** 2)
        return max(0.0, memory_before - memory_after)

    def _emergency_garbage_collection(self):
        """ç·Šæ€¥ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
        self.logger.warning("ğŸ†˜ ç·Šæ€¥ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
        
        # å…¨ä¸–ä»£GC
        for i in range(3):
            collected = gc.collect()
            self.logger.debug(f"GCä¸–ä»£{i}: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å")
        
        # GPU ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # ç®¡ç†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        self._cleanup_managed_caches()
        
        # ç·Šæ€¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        for callback in self.emergency_callbacks:
            try:
                callback()
            except Exception as e:
                self.logger.error(f"ç·Šæ€¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.stats['gc_triggers'] += 1

    def _soft_garbage_collection(self):
        """ã‚½ãƒ•ãƒˆã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
        collected = gc.collect()
        self.logger.debug(f"ã‚½ãƒ•ãƒˆGC: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å")
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        self.stats['gc_triggers'] += 1

    def _preventive_garbage_collection(self):
        """äºˆé˜²çš„ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
        # ä¸–ä»£0ã®ã¿
        collected = gc.collect(0)
        self.logger.debug(f"äºˆé˜²GC: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å")

    def _clear_gpu_cache(self):
        """GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            self.logger.debug("GPU ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")

    def _cleanup_managed_caches(self):
        """ç®¡ç†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cleaned_count = 0
        
        for cache_name, cache in self.managed_caches.items():
            try:
                cache.clear()
                cleaned_count += 1
            except Exception as e:
                self.logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ '{cache_name}' ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.logger.debug(f"ç®¡ç†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {cleaned_count}ã‚­ãƒ£ãƒƒã‚·ãƒ¥")

    def _evaluate_auto_gc(self, snapshot: MemorySnapshot):
        """è‡ªå‹•GCè©•ä¾¡"""
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã«åŸºã¥ãåˆ¤å®š
        if snapshot.system_used_percent >= self.aggressive_gc_threshold_percent:
            self._soft_garbage_collection()
        
        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªå¢—åŠ ã«åŸºã¥ãåˆ¤å®š
        if len(self.snapshot_history) >= 5:
            recent_snapshots = list(self.snapshot_history)[-5:]
            memory_trend = recent_snapshots[-1].process_rss_mb - recent_snapshots[0].process_rss_mb
            
            if memory_trend > self.gc_trigger_threshold_mb * 2:
                self._preventive_garbage_collection()

    def _detect_memory_leaks(self):
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º"""
        if len(self.snapshot_history) < 60:  # 1åˆ†ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
            return
        
        # éå»5åˆ†ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        cutoff_time = time.time() - self.leak_detection_window
        recent_snapshots = [
            s for s in self.snapshot_history 
            if s.timestamp >= cutoff_time
        ]
        
        if len(recent_snapshots) < 20:
            return
        
        # ç·šå½¢å›å¸°ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‚¾ãã‚’è¨ˆç®—
        timestamps = [s.timestamp for s in recent_snapshots]
        memory_values = [s.process_rss_mb for s in recent_snapshots]
        
        slope = self._calculate_linear_regression_slope(timestamps, memory_values)
        
        # å‚¾ããŒæ­£ã§ä¸€å®šå€¤ä»¥ä¸Šã®å ´åˆã€ãƒªãƒ¼ã‚¯ã¨åˆ¤å®š
        leak_threshold_mb_per_minute = 5.0
        leak_threshold_per_second = leak_threshold_mb_per_minute / 60.0
        
        if slope > leak_threshold_per_second:
            self.stats['leak_detections'] += 1
            
            alert = MemoryAlert(
                level="WARNING",
                message=f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º: {slope * 60:.2f}MB/åˆ†ã®å¢—åŠ ",
                timestamp=time.time(),
                metrics={"leak_rate_mb_per_min": slope * 60},
                recovery_action="soft_gc"
            )
            
            self._handle_alert(alert)

    def _calculate_linear_regression_slope(self, x_values: List[float], y_values: List[float]) -> float:
        """ç·šå½¢å›å¸°ã®å‚¾ãã‚’è¨ˆç®—"""
        n = len(x_values)
        if n < 2:
            return 0.0
        
        sum_x = sum(x_values)
        sum_y = sum(y_values)
        sum_xy = sum(x * y for x, y in zip(x_values, y_values))
        sum_xx = sum(x * x for x in x_values)
        
        denominator = n * sum_xx - sum_x * sum_x
        if denominator == 0:
            return 0.0
        
        slope = (n * sum_xy - sum_x * sum_y) / denominator
        return slope

    def _prevent_oom(self, snapshot: MemorySnapshot):
        """OOMäºˆé˜²"""
        # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªãŒ1GBæœªæº€ã®å ´åˆ
        if snapshot.system_available_mb < 1024:
            self.stats['oom_preventions'] += 1
            
            alert = MemoryAlert(
                level="CRITICAL",
                message=f"OOMå±é™º: åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª {snapshot.system_available_mb:.0f}MB",
                timestamp=snapshot.timestamp,
                metrics={"available_mb": snapshot.system_available_mb},
                recovery_action="emergency_gc"
            )
            
            self._handle_alert(alert)

    def _apply_rtx3080_optimizations(self):
        """RTX3080æœ€é©åŒ–é©ç”¨"""
        if not self.rtx_optimizer:
            return
        
        try:
            # GPU ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            optimization_config = self.rtx_optimizer.get_current_config()
            
            if TORCH_AVAILABLE and torch.cuda.is_available():
                # PyTorchãƒ¡ãƒ¢ãƒªè¨­å®š
                torch.cuda.set_per_process_memory_fraction(
                    self.gpu_memory_target_percent / 100.0
                )
                
                # ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–é˜²æ­¢
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
            
            self.logger.info("âœ… RTX3080æœ€é©åŒ–é©ç”¨å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"RTX3080æœ€é©åŒ–é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")

    def register_cache(self, name: str, cache: Any):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç™»éŒ²"""
        if hasattr(cache, 'clear'):
            self.managed_caches[name] = weakref.WeakValueDictionary({'cache': cache})
            self.logger.debug(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ '{name}' ç™»éŒ²å®Œäº†")
        else:
            self.logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ '{name}' ã«clear()ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")

    def register_buffer(self, name: str, buffer: Any):
        """ãƒãƒƒãƒ•ã‚¡ç™»éŒ²"""
        self.managed_buffers[name] = buffer
        self.logger.debug(f"ãƒãƒƒãƒ•ã‚¡ '{name}' ç™»éŒ²å®Œäº†")

    def register_emergency_callback(self, callback: Callable):
        """ç·Šæ€¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²"""
        self.emergency_callbacks.append(callback)
        self.logger.debug("ç·Šæ€¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²å®Œäº†")

    def get_current_memory_info(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªæƒ…å ±å–å¾—"""
        if not self.snapshot_history:
            return {}
        
        latest = self.snapshot_history[-1]
        
        return {
            'timestamp': latest.timestamp,
            'process_memory_mb': latest.process_rss_mb,
            'system_available_mb': latest.system_available_mb,
            'system_usage_percent': latest.system_used_percent,
            'gpu_allocated_mb': latest.gpu_allocated_mb,
            'gpu_free_mb': latest.gpu_free_mb,
            'cache_size_mb': latest.cache_size_mb,
            'buffer_count': latest.buffer_count,
            'monitoring_active': self.is_monitoring
        }

    def get_efficiency_report(self) -> Dict[str, Any]:
        """åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        if not self.snapshot_history:
            return {'error': 'ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ ãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        # çµ±è¨ˆè¨ˆç®—
        snapshots = list(self.snapshot_history)
        duration_minutes = (snapshots[-1].timestamp - snapshots[0].timestamp) / 60
        
        memory_values = [s.process_rss_mb for s in snapshots]
        peak_memory = max(memory_values)
        avg_memory = sum(memory_values) / len(memory_values)
        min_memory = min(memory_values)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
        alert_counts = defaultdict(int)
        for alert in self.alert_history:
            alert_counts[alert.level] += 1
        
        return {
            'summary': {
                'monitoring_duration_minutes': duration_minutes,
                'total_snapshots': len(snapshots),
                'peak_memory_mb': peak_memory,
                'average_memory_mb': avg_memory,
                'memory_variance_mb': peak_memory - min_memory
            },
            'performance': {
                'gc_triggers': self.stats['gc_triggers'],
                'leak_detections': self.stats['leak_detections'],
                'oom_preventions': self.stats['oom_preventions'],
                'total_memory_recovered_mb': self.stats['memory_recovered_mb']
            },
            'alerts': {
                'total_alerts': len(self.alert_history),
                'by_level': dict(alert_counts),
                'alert_rate_per_hour': len(self.alert_history) / max(duration_minutes / 60, 0.01)
            },
            'optimizations': {
                'rtx3080_enabled': self.rtx_optimizer is not None,
                'auto_gc_enabled': self.auto_gc_enabled,
                'leak_detection_enabled': self.leak_detection_enabled,
                'managed_caches': len(self.managed_caches),
                'managed_buffers': len(self.managed_buffers)
            }
        }

    def force_memory_cleanup(self) -> Dict[str, float]:
        """å¼·åˆ¶ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        memory_before = psutil.Process().memory_info().rss / (1024 ** 2)
        
        # ç®¡ç†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        self._cleanup_managed_caches()
        
        # ç·Šæ€¥GC
        self._emergency_garbage_collection()
        
        # çµ±è¨ˆæ›´æ–°
        time.sleep(0.5)  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†å¾…æ©Ÿ
        memory_after = psutil.Process().memory_info().rss / (1024 ** 2)
        recovered = max(0.0, memory_before - memory_after)
        
        self.stats['memory_recovered_mb'] += recovered
        
        return {
            'memory_before_mb': memory_before,
            'memory_after_mb': memory_after,
            'recovered_mb': recovered,
            'success': recovered > 0
        }

    def shutdown(self):
        """ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†"""
        self.logger.info("ğŸ”„ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 çµ‚äº†ä¸­...")
        
        # ç›£è¦–åœæ­¢
        self.stop_monitoring()
        
        # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanup_result = self.force_memory_cleanup()
        
        # çµ±è¨ˆä¿å­˜
        self._save_session_stats()
        
        self.logger.info(f"âœ… ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†å®Œäº† - æœ€çµ‚å›å¾©: {cleanup_result['recovered_mb']:.1f}MB")

    def _save_session_stats(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆä¿å­˜"""
        try:
            stats_dir = Path("logs/memory_efficiency")
            stats_dir.mkdir(parents=True, exist_ok=True)
            
            session_data = {
                'timestamp': time.time(),
                'stats': self.stats,
                'efficiency_report': self.get_efficiency_report(),
                'config': self.config
            }
            
            timestamp_str = time.strftime("%Y%m%d_%H%M%S")
            stats_file = stats_dir / f"memory_session_{timestamp_str}.json"
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆä¿å­˜: {stats_file}")
            
        except Exception as e:
            self.logger.error(f"çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def create_memory_efficiency_system(config: Dict[str, Any] = None) -> MemoryEfficiencySystemV3:
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    default_config = {
        'monitoring_enabled': True,
        'auto_gc_enabled': True,
        'leak_detection_enabled': True,
        'oom_prevention_enabled': True,
        'rtx3080_optimization': True,
        'monitoring_interval': 1.0,
        'warning_threshold_percent': 85.0,
        'critical_threshold_percent': 95.0,
        'gpu_warning_threshold_percent': 90.0,
        'gc_trigger_threshold_mb': 100.0,
        'aggressive_gc_threshold_percent': 90.0
    }
    
    if config:
        default_config.update(config)
    
    return MemoryEfficiencySystemV3(default_config)


# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_memory_efficiency_system():
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ
    system = create_memory_efficiency_system({
        'monitoring_interval': 0.5,
        'warning_threshold_percent': 50.0  # ãƒ†ã‚¹ãƒˆç”¨ä½é–¾å€¤
    })
    
    try:
        # ç›£è¦–é–‹å§‹
        system.start_monitoring()
        
        # ãƒ¡ãƒ¢ãƒªè² è·ãƒ†ã‚¹ãƒˆ
        test_data = []
        for i in range(100):
            test_data.append([0] * 100000)  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¢—åŠ 
            time.sleep(0.01)
        
        # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªæƒ…å ±
        memory_info = system.get_current_memory_info()
        print(f"ğŸ“Š ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_info['process_memory_mb']:.1f}MB")
        
        # å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
        cleanup_result = system.force_memory_cleanup()
        print(f"ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çµæœ: {cleanup_result}")
        
        # åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ
        efficiency_report = system.get_efficiency_report()
        print(f"ğŸ“ˆ åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ: {efficiency_report['summary']}")
        
        # ãƒ†ã‚¹ãƒˆæˆåŠŸ
        print("âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  v3.0 ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        
    finally:
        # ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†
        system.shutdown()


if __name__ == "__main__":
    test_memory_efficiency_system() 