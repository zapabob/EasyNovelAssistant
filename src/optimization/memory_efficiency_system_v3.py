# -*- coding: utf-8 -*-
"""
„É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 (Memory Efficiency System v3.0)
RTX3080ÊúÄÈÅ©ÂåñÁµ±Âêà„ÉªËá™Âãï„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„Éª„É°„É¢„É™„É™„Éº„ÇØÊ§úÂá∫„ÉªÂãïÁöÑ„Éê„ÉÉ„Éï„Ç°ÁÆ°ÁêÜ

‰∏ªË¶ÅÊ©üËÉΩ:
1. RTX3080 VRAM/RAM ÊúÄÈÅ©Âåñ
2. Ëá™Âãï„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥
3. „É°„É¢„É™„É™„Éº„ÇØÊ§úÂá∫„Éª‰øÆÂæ©
4. ÂãïÁöÑ„Éê„ÉÉ„Éï„Ç°„Çµ„Ç§„Ç∫Ë™øÊï¥
5. OOM‰∫àÈò≤„Ç∑„Çπ„ÉÜ„É†
6. „É™„Ç¢„É´„Çø„Ç§„É†Áõ£Ë¶ñ„Éª„Ç¢„É©„Éº„Éà
"""

import gc
import os
import sys
import time
import threading
import psutil
import json
import logging
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass, field
from collections import deque, defaultdict
from pathlib import Path
import weakref

# GPUÈñ¢ÈÄ£„É¢„Ç∏„É•„Éº„É´Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
try:
    import torch
    import torch.cuda
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("WARNING: PyTorch not detected: CPU optimization only")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÜÖ„É¢„Ç∏„É•„Éº„É´
try:
    from .rtx3080_optimizer import RTX3080Optimizer
    from ..integration.cross_suppression_engine import SessionMemoryBuffer
except ImportError:
    # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: Á∞°ÊòìÁâà„Çí‰ΩøÁî®
    RTX3080Optimizer = None
    SessionMemoryBuffer = None


@dataclass
class MemorySnapshot:
    """„É°„É¢„É™„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà"""
    timestamp: float
    process_rss_mb: float
    process_vms_mb: float
    system_available_mb: float
    system_used_percent: float
    gpu_allocated_mb: Optional[float] = None
    gpu_reserved_mb: Optional[float] = None
    gpu_free_mb: Optional[float] = None
    cache_size_mb: float = 0.0
    buffer_count: int = 0
    gc_count: int = 0


@dataclass
class MemoryAlert:
    """„É°„É¢„É™„Ç¢„É©„Éº„Éà"""
    level: str  # INFO, WARNING, CRITICAL
    message: str
    timestamp: float
    metrics: Dict[str, Any] = field(default_factory=dict)
    recovery_action: Optional[str] = None


class MemoryEfficiencySystemV3:
    """
    „É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0
    RTX3080Áµ±Âêà„ÉªËá™ÂãïÊúÄÈÅ©Âåñ„Éª‰∫àÈò≤ÁöÑÁÆ°ÁêÜ
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # Âü∫Êú¨Ë®≠ÂÆö
        self.monitoring_enabled = self.config.get('monitoring_enabled', True)
        self.auto_gc_enabled = self.config.get('auto_gc_enabled', True)
        self.leak_detection_enabled = self.config.get('leak_detection_enabled', True)
        self.oom_prevention_enabled = self.config.get('oom_prevention_enabled', True)
        
        # RTX3080ÊúÄÈÅ©Âåñ
        self.rtx3080_optimization = self.config.get('rtx3080_optimization', True)
        self.gpu_memory_target_percent = self.config.get('gpu_memory_target_percent', 85.0)
        
        # Áõ£Ë¶ñË®≠ÂÆö
        self.monitoring_interval = self.config.get('monitoring_interval', 1.0)  # Áßí
        self.snapshot_history_size = self.config.get('snapshot_history_size', 1000)
        self.leak_detection_window = self.config.get('leak_detection_window', 300)  # 5ÂàÜ
        
        # „Ç¢„É©„Éº„ÉàÈñæÂÄ§
        self.warning_threshold_percent = self.config.get('warning_threshold_percent', 85.0)
        self.critical_threshold_percent = self.config.get('critical_threshold_percent', 95.0)
        self.gpu_warning_threshold_percent = self.config.get('gpu_warning_threshold_percent', 90.0)
        
        # GCË®≠ÂÆö
        self.gc_trigger_threshold_mb = self.config.get('gc_trigger_threshold_mb', 100.0)
        self.aggressive_gc_threshold_percent = self.config.get('aggressive_gc_threshold_percent', 90.0)
        
        # Áä∂ÊÖãÁÆ°ÁêÜ
        self.is_monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.snapshot_history: deque = deque(maxlen=self.snapshot_history_size)
        self.alert_history: deque = deque(maxlen=100)
        
        # Áµ±Ë®à
        self.stats = {
            'total_snapshots': 0,
            'total_alerts': 0,
            'gc_triggers': 0,
            'leak_detections': 0,
            'oom_preventions': 0,
            'memory_recovered_mb': 0.0
        }
        
        # „Ç≠„É£„ÉÉ„Ç∑„É•„Éª„Éê„ÉÉ„Éï„Ç°ÁÆ°ÁêÜ
        self.managed_caches: Dict[str, weakref.WeakValueDictionary] = {}
        self.managed_buffers: Dict[str, Any] = {}
        
        # RTX3080ÊúÄÈÅ©ÂåñÂô®
        self.rtx_optimizer = None
        if self.rtx3080_optimization and RTX3080Optimizer:
            try:
                self.rtx_optimizer = RTX3080Optimizer(self.config)
                print("‚úÖ RTX3080ÊúÄÈÅ©ÂåñÂô®Áµ±ÂêàÂÆå‰∫Ü")
            except Exception as e:
                print(f"‚ö†Ô∏è RTX3080ÊúÄÈÅ©ÂåñÂô®ÂàùÊúüÂåñÂ§±Êïó: {e}")
        
        # Á∑äÊÄ•„Ç≥„Éº„É´„Éê„ÉÉ„ÇØ
        self.emergency_callbacks: List[Callable] = []
        
        # „É≠„Ç∞Ë®≠ÂÆö
        self.logger = self._setup_logging()
        
        print(f"üöÄ „É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 ÂàùÊúüÂåñÂÆå‰∫Ü")
        print(f"   ‚îú‚îÄ RTX3080ÊúÄÈÅ©Âåñ: {'ÊúâÂäπ' if self.rtx_optimizer else 'ÁÑ°Âäπ'}")
        print(f"   ‚îú‚îÄ Ëá™ÂãïGC: {'ÊúâÂäπ' if self.auto_gc_enabled else 'ÁÑ°Âäπ'}")
        print(f"   ‚îú‚îÄ „É™„Éº„ÇØÊ§úÂá∫: {'ÊúâÂäπ' if self.leak_detection_enabled else 'ÁÑ°Âäπ'}")
        print(f"   ‚îú‚îÄ OOM‰∫àÈò≤: {'ÊúâÂäπ' if self.oom_prevention_enabled else 'ÁÑ°Âäπ'}")
        print(f"   ‚îî‚îÄ Áõ£Ë¶ñÈñìÈöî: {self.monitoring_interval}Áßí")

    def _setup_logging(self) -> logging.Logger:
        """„É≠„Ç∞Ë®≠ÂÆö"""
        logger = logging.getLogger('MemoryEfficiencyV3')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger

    def start_monitoring(self):
        """Áõ£Ë¶ñÈñãÂßã"""
        if self.is_monitoring:
            self.logger.warning("Áõ£Ë¶ñ„ÅØÊó¢„Å´ÂÆüË°å‰∏≠„Åß„Åô")
            return
        
        self.is_monitoring = True
        self.snapshot_history.clear()
        self.alert_history.clear()
        
        # ÂàùÊúü„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà
        initial_snapshot = self._take_memory_snapshot()
        self.snapshot_history.append(initial_snapshot)
        
        # Áõ£Ë¶ñ„Çπ„É¨„ÉÉ„ÉâÈñãÂßã
        self.monitor_thread = threading.Thread(
            target=self._monitoring_loop, 
            daemon=True,
            name="MemoryMonitorV3"
        )
        self.monitor_thread.start()
        
        self.logger.info(f"üîç „É°„É¢„É™Áõ£Ë¶ñÈñãÂßã (ÈñìÈöî: {self.monitoring_interval}Áßí)")
        
        # RTX3080ÊúÄÈÅ©ÂåñÈÅ©Áî®
        if self.rtx_optimizer:
            self._apply_rtx3080_optimizations()

    def stop_monitoring(self):
        """Áõ£Ë¶ñÂÅúÊ≠¢"""
        if not self.is_monitoring:
            return
        
        self.is_monitoring = False
        
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        
        # ÊúÄÁµÇÁµ±Ë®à
        final_stats = self.get_efficiency_report()
        self.logger.info(f"üõë „É°„É¢„É™Áõ£Ë¶ñÂÅúÊ≠¢ - Áµ±Ë®à: {final_stats['summary']}")

    def _monitoring_loop(self):
        """Áõ£Ë¶ñ„É°„Ç§„É≥„É´„Éº„Éó"""
        while self.is_monitoring:
            try:
                # „Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„ÉàÂèñÂæó
                snapshot = self._take_memory_snapshot()
                self.snapshot_history.append(snapshot)
                self.stats['total_snapshots'] += 1
                
                # „Ç¢„É©„Éº„ÉàË©ï‰æ°
                alerts = self._evaluate_alerts(snapshot)
                for alert in alerts:
                    self._handle_alert(alert)
                
                # Ëá™ÂãïGCË©ï‰æ°
                if self.auto_gc_enabled:
                    self._evaluate_auto_gc(snapshot)
                
                # „É°„É¢„É™„É™„Éº„ÇØÊ§úÂá∫
                if self.leak_detection_enabled and len(self.snapshot_history) > 20:
                    self._detect_memory_leaks()
                
                # OOM‰∫àÈò≤
                if self.oom_prevention_enabled:
                    self._prevent_oom(snapshot)
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"Áõ£Ë¶ñ„É´„Éº„Éó„Ç®„É©„Éº: {e}")
                time.sleep(max(self.monitoring_interval, 1.0))

    def _take_memory_snapshot(self) -> MemorySnapshot:
        """„É°„É¢„É™„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„ÉàÂèñÂæó"""
        process = psutil.Process()
        memory_info = process.memory_info()
        system_memory = psutil.virtual_memory()
        
        # GPUÁµ±Ë®à
        gpu_allocated_mb = None
        gpu_reserved_mb = None
        gpu_free_mb = None
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            try:
                gpu_allocated_mb = torch.cuda.memory_allocated() / (1024 ** 2)
                gpu_reserved_mb = torch.cuda.memory_reserved() / (1024 ** 2)
                
                # Á©∫„ÅçVRAMË®àÁÆó
                if self.rtx_optimizer:
                    total_vram = self.rtx_optimizer.gpu_info.get('memory_total', 10240)
                    gpu_free_mb = total_vram - gpu_reserved_mb
                
            except Exception as e:
                self.logger.debug(f"GPUÁµ±Ë®àÂèñÂæó„Ç®„É©„Éº: {e}")
        
        # „Ç≠„É£„ÉÉ„Ç∑„É•„Éª„Éê„ÉÉ„Éï„Ç°„Çµ„Ç§„Ç∫
        cache_size_mb = sum(
            sys.getsizeof(cache) / (1024 ** 2) 
            for cache in self.managed_caches.values()
        )
        
        buffer_count = len(self.managed_buffers)
        gc_count = sum(gc.get_count())
        
        return MemorySnapshot(
            timestamp=time.time(),
            process_rss_mb=memory_info.rss / (1024 ** 2),
            process_vms_mb=memory_info.vms / (1024 ** 2),
            system_available_mb=system_memory.available / (1024 ** 2),
            system_used_percent=system_memory.percent,
            gpu_allocated_mb=gpu_allocated_mb,
            gpu_reserved_mb=gpu_reserved_mb,
            gpu_free_mb=gpu_free_mb,
            cache_size_mb=cache_size_mb,
            buffer_count=buffer_count,
            gc_count=gc_count
        )

    def _evaluate_alerts(self, snapshot: MemorySnapshot) -> List[MemoryAlert]:
        """„Ç¢„É©„Éº„ÉàË©ï‰æ°"""
        alerts = []
        
        # „Ç∑„Çπ„ÉÜ„É†„É°„É¢„É™„Ç¢„É©„Éº„Éà
        if snapshot.system_used_percent >= self.critical_threshold_percent:
            alerts.append(MemoryAlert(
                level="CRITICAL",
                message=f"„Ç∑„Çπ„ÉÜ„É†„É°„É¢„É™‰ΩøÁî®Áéá„ÅåÂç±Èô∫„É¨„Éô„É´: {snapshot.system_used_percent:.1f}%",
                timestamp=snapshot.timestamp,
                metrics={"memory_percent": snapshot.system_used_percent},
                recovery_action="emergency_gc"
            ))
        elif snapshot.system_used_percent >= self.warning_threshold_percent:
            alerts.append(MemoryAlert(
                level="WARNING",
                message=f"„Ç∑„Çπ„ÉÜ„É†„É°„É¢„É™‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ: {snapshot.system_used_percent:.1f}%",
                timestamp=snapshot.timestamp,
                metrics={"memory_percent": snapshot.system_used_percent},
                recovery_action="soft_gc"
            ))
        
        # GPU„É°„É¢„É™„Ç¢„É©„Éº„Éà
        if snapshot.gpu_reserved_mb and snapshot.gpu_free_mb:
            gpu_usage_percent = (snapshot.gpu_reserved_mb / (snapshot.gpu_reserved_mb + snapshot.gpu_free_mb)) * 100
            
            if gpu_usage_percent >= self.gpu_warning_threshold_percent:
                alerts.append(MemoryAlert(
                    level="WARNING",
                    message=f"GPU „É°„É¢„É™‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ: {gpu_usage_percent:.1f}%",
                    timestamp=snapshot.timestamp,
                    metrics={"gpu_usage_percent": gpu_usage_percent},
                    recovery_action="gpu_cache_clear"
                ))
        
        # „Éó„É≠„Çª„Çπ„É°„É¢„É™ÊÄ•Â¢ó„Ç¢„É©„Éº„Éà
        if len(self.snapshot_history) >= 2:
            prev_snapshot = self.snapshot_history[-2]
            memory_growth = snapshot.process_rss_mb - prev_snapshot.process_rss_mb
            
            if memory_growth > self.gc_trigger_threshold_mb:
                alerts.append(MemoryAlert(
                    level="INFO",
                    message=f"„Éó„É≠„Çª„Çπ„É°„É¢„É™ÊÄ•Â¢ó: +{memory_growth:.1f}MB",
                    timestamp=snapshot.timestamp,
                    metrics={"memory_growth_mb": memory_growth},
                    recovery_action="preventive_gc"
                ))
        
        return alerts

    def _handle_alert(self, alert: MemoryAlert):
        """„Ç¢„É©„Éº„ÉàÂá¶ÁêÜ"""
        self.alert_history.append(alert)
        self.stats['total_alerts'] += 1
        
        # „É≠„Ç∞Âá∫Âäõ
        log_level = getattr(self.logger, alert.level.lower(), self.logger.info)
        log_level(f"üö® {alert.message}")
        
        # ÂõûÂæ©„Ç¢„ÇØ„Ç∑„Éß„É≥ÂÆüË°å
        if alert.recovery_action:
            recovered_mb = self._execute_recovery_action(alert.recovery_action)
            if recovered_mb > 0:
                self.stats['memory_recovered_mb'] += recovered_mb
                self.logger.info(f"‚úÖ „É°„É¢„É™ÂõûÂæ©: {recovered_mb:.1f}MB")

    def _execute_recovery_action(self, action: str) -> float:
        """ÂõûÂæ©„Ç¢„ÇØ„Ç∑„Éß„É≥ÂÆüË°å"""
        memory_before = psutil.Process().memory_info().rss / (1024 ** 2)
        
        try:
            if action == "emergency_gc":
                self._emergency_garbage_collection()
            elif action == "soft_gc":
                self._soft_garbage_collection()
            elif action == "preventive_gc":
                self._preventive_garbage_collection()
            elif action == "gpu_cache_clear":
                self._clear_gpu_cache()
            elif action == "cache_cleanup":
                self._cleanup_managed_caches()
            
            time.sleep(0.1)  # GCÂÆå‰∫ÜÂæÖÊ©ü
            
        except Exception as e:
            self.logger.error(f"ÂõûÂæ©„Ç¢„ÇØ„Ç∑„Éß„É≥ '{action}' ÂÆüË°å„Ç®„É©„Éº: {e}")
            return 0.0
        
        memory_after = psutil.Process().memory_info().rss / (1024 ** 2)
        return max(0.0, memory_before - memory_after)

    def _emergency_garbage_collection(self):
        """Á∑äÊÄ•„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥"""
        self.logger.warning("üÜò Á∑äÊÄ•„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥ÂÆüË°å")
        
        # ÂÖ®‰∏ñ‰ª£GC
        for i in range(3):
            collected = gc.collect()
            self.logger.debug(f"GC‰∏ñ‰ª£{i}: {collected}„Ç™„Éñ„Ç∏„Çß„ÇØ„ÉàÂõûÂèé")
        
        # GPU „Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # ÁÆ°ÁêÜ„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢
        self._cleanup_managed_caches()
        
        # Á∑äÊÄ•„Ç≥„Éº„É´„Éê„ÉÉ„ÇØÂÆüË°å
        for callback in self.emergency_callbacks:
            try:
                callback()
            except Exception as e:
                self.logger.error(f"Á∑äÊÄ•„Ç≥„Éº„É´„Éê„ÉÉ„ÇØ„Ç®„É©„Éº: {e}")
        
        self.stats['gc_triggers'] += 1

    def _soft_garbage_collection(self):
        """„ÇΩ„Éï„Éà„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥"""
        collected = gc.collect()
        self.logger.debug(f"„ÇΩ„Éï„ÉàGC: {collected}„Ç™„Éñ„Ç∏„Çß„ÇØ„ÉàÂõûÂèé")
        
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        self.stats['gc_triggers'] += 1

    def _preventive_garbage_collection(self):
        """‰∫àÈò≤ÁöÑ„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥"""
        # ‰∏ñ‰ª£0„ÅÆ„Åø
        collected = gc.collect(0)
        self.logger.debug(f"‰∫àÈò≤GC: {collected}„Ç™„Éñ„Ç∏„Çß„ÇØ„ÉàÂõûÂèé")

    def _clear_gpu_cache(self):
        """GPU„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢"""
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            self.logger.debug("GPU „Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢ÂÆå‰∫Ü")

    def _cleanup_managed_caches(self):
        """ÁÆ°ÁêÜ„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó"""
        cleaned_count = 0
        
        for cache_name, cache in self.managed_caches.items():
            try:
                cache.clear()
                cleaned_count += 1
            except Exception as e:
                self.logger.error(f"„Ç≠„É£„ÉÉ„Ç∑„É• '{cache_name}' „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„Ç®„É©„Éº: {e}")
        
        self.logger.debug(f"ÁÆ°ÁêÜ„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó: {cleaned_count}„Ç≠„É£„ÉÉ„Ç∑„É•")

    def _evaluate_auto_gc(self, snapshot: MemorySnapshot):
        """Ëá™ÂãïGCË©ï‰æ°"""
        # „É°„É¢„É™‰ΩøÁî®Áéá„Å´Âü∫„Å•„ÅèÂà§ÂÆö
        if snapshot.system_used_percent >= self.aggressive_gc_threshold_percent:
            self._soft_garbage_collection()
        
        # „Éó„É≠„Çª„Çπ„É°„É¢„É™Â¢óÂä†„Å´Âü∫„Å•„ÅèÂà§ÂÆö
        if len(self.snapshot_history) >= 5:
            recent_snapshots = list(self.snapshot_history)[-5:]
            memory_trend = recent_snapshots[-1].process_rss_mb - recent_snapshots[0].process_rss_mb
            
            if memory_trend > self.gc_trigger_threshold_mb * 2:
                self._preventive_garbage_collection()

    def _detect_memory_leaks(self):
        """„É°„É¢„É™„É™„Éº„ÇØÊ§úÂá∫"""
        if len(self.snapshot_history) < 60:  # 1ÂàÜ‰ª•‰∏ä„ÅÆ„Éá„Éº„Çø„ÅåÂøÖË¶Å
            return
        
        # ÈÅéÂéª5ÂàÜ„ÅÆ„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà
        cutoff_time = time.time() - self.leak_detection_window
        recent_snapshots = [
            s for s in self.snapshot_history 
            if s.timestamp >= cutoff_time
        ]
        
        if len(recent_snapshots) < 20:
            return
        
        # Á∑öÂΩ¢ÂõûÂ∏∞„Åß„É°„É¢„É™‰ΩøÁî®Èáè„ÅÆÂÇæ„Åç„ÇíË®àÁÆó
        timestamps = [s.timestamp for s in recent_snapshots]
        memory_values = [s.process_rss_mb for s in recent_snapshots]
        
        slope = self._calculate_linear_regression_slope(timestamps, memory_values)
        
        # ÂÇæ„Åç„ÅåÊ≠£„Åß‰∏ÄÂÆöÂÄ§‰ª•‰∏ä„ÅÆÂ†¥Âêà„ÄÅ„É™„Éº„ÇØ„Å®Âà§ÂÆö
        leak_threshold_mb_per_minute = 5.0
        leak_threshold_per_second = leak_threshold_mb_per_minute / 60.0
        
        if slope > leak_threshold_per_second:
            self.stats['leak_detections'] += 1
            
            alert = MemoryAlert(
                level="WARNING",
                message=f"„É°„É¢„É™„É™„Éº„ÇØÊ§úÂá∫: {slope * 60:.2f}MB/ÂàÜ„ÅÆÂ¢óÂä†",
                timestamp=time.time(),
                metrics={"leak_rate_mb_per_min": slope * 60},
                recovery_action="soft_gc"
            )
            
            self._handle_alert(alert)

    def _calculate_linear_regression_slope(self, x_values: List[float], y_values: List[float]) -> float:
        """Á∑öÂΩ¢ÂõûÂ∏∞„ÅÆÂÇæ„Åç„ÇíË®àÁÆó"""
        n = len(x_values)
        if n < 2:
            return 0.0
        
        sum_x = sum(x_values)
        sum_y = sum(y_values)
        sum_xy = sum(x * y for x, y in zip(x_values, y_values))
        sum_xx = sum(x * x for x in x_values)
        
        denominator = n * sum_xx - sum_x * sum_x
        if denominator == 0:
            return 0.0
        
        slope = (n * sum_xy - sum_x * sum_y) / denominator
        return slope

    def _prevent_oom(self, snapshot: MemorySnapshot):
        """OOM‰∫àÈò≤"""
        # Âà©Áî®ÂèØËÉΩ„É°„É¢„É™„Åå1GBÊú™Ê∫Ä„ÅÆÂ†¥Âêà
        if snapshot.system_available_mb < 1024:
            self.stats['oom_preventions'] += 1
            
            alert = MemoryAlert(
                level="CRITICAL",
                message=f"OOMÂç±Èô∫: Âà©Áî®ÂèØËÉΩ„É°„É¢„É™ {snapshot.system_available_mb:.0f}MB",
                timestamp=snapshot.timestamp,
                metrics={"available_mb": snapshot.system_available_mb},
                recovery_action="emergency_gc"
            )
            
            self._handle_alert(alert)

    def _apply_rtx3080_optimizations(self):
        """RTX3080ÊúÄÈÅ©ÂåñÈÅ©Áî®"""
        if not self.rtx_optimizer:
            return
        
        try:
            # GPU „É°„É¢„É™ÊúÄÈÅ©Âåñ
            optimization_config = self.rtx_optimizer.get_current_config()
            
            if TORCH_AVAILABLE and torch.cuda.is_available():
                # PyTorch„É°„É¢„É™Ë®≠ÂÆö
                torch.cuda.set_per_process_memory_fraction(
                    self.gpu_memory_target_percent / 100.0
                )
                
                # „É°„É¢„É™Êñ≠ÁâáÂåñÈò≤Ê≠¢
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
            
            self.logger.info("‚úÖ RTX3080ÊúÄÈÅ©ÂåñÈÅ©Áî®ÂÆå‰∫Ü")
            
        except Exception as e:
            self.logger.error(f"RTX3080ÊúÄÈÅ©ÂåñÈÅ©Áî®„Ç®„É©„Éº: {e}")

    def register_cache(self, name: str, cache: Any):
        """„Ç≠„É£„ÉÉ„Ç∑„É•ÁôªÈå≤"""
        if hasattr(cache, 'clear'):
            self.managed_caches[name] = weakref.WeakValueDictionary({'cache': cache})
            self.logger.debug(f"„Ç≠„É£„ÉÉ„Ç∑„É• '{name}' ÁôªÈå≤ÂÆå‰∫Ü")
        else:
            self.logger.warning(f"„Ç≠„É£„ÉÉ„Ç∑„É• '{name}' „Å´clear()„É°„ÇΩ„ÉÉ„Éâ„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")

    def register_buffer(self, name: str, buffer: Any):
        """„Éê„ÉÉ„Éï„Ç°ÁôªÈå≤"""
        self.managed_buffers[name] = buffer
        self.logger.debug(f"„Éê„ÉÉ„Éï„Ç° '{name}' ÁôªÈå≤ÂÆå‰∫Ü")

    def register_emergency_callback(self, callback: Callable):
        """Á∑äÊÄ•„Ç≥„Éº„É´„Éê„ÉÉ„ÇØÁôªÈå≤"""
        self.emergency_callbacks.append(callback)
        self.logger.debug("Á∑äÊÄ•„Ç≥„Éº„É´„Éê„ÉÉ„ÇØÁôªÈå≤ÂÆå‰∫Ü")

    def get_current_memory_info(self) -> Dict[str, Any]:
        """ÁèæÂú®„ÅÆ„É°„É¢„É™ÊÉÖÂ†±ÂèñÂæó"""
        if not self.snapshot_history:
            return {}
        
        latest = self.snapshot_history[-1]
        
        return {
            'timestamp': latest.timestamp,
            'process_memory_mb': latest.process_rss_mb,
            'system_available_mb': latest.system_available_mb,
            'system_usage_percent': latest.system_used_percent,
            'gpu_allocated_mb': latest.gpu_allocated_mb,
            'gpu_free_mb': latest.gpu_free_mb,
            'cache_size_mb': latest.cache_size_mb,
            'buffer_count': latest.buffer_count,
            'monitoring_active': self.is_monitoring
        }

    def get_efficiency_report(self) -> Dict[str, Any]:
        """ÂäπÁéá„É¨„Éù„Éº„ÉàÂèñÂæó"""
        if not self.snapshot_history:
            return {'error': '„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà „Éá„Éº„Çø„Å™„Åó'}
        
        # Áµ±Ë®àË®àÁÆó
        snapshots = list(self.snapshot_history)
        duration_minutes = (snapshots[-1].timestamp - snapshots[0].timestamp) / 60
        
        memory_values = [s.process_rss_mb for s in snapshots]
        peak_memory = max(memory_values)
        avg_memory = sum(memory_values) / len(memory_values)
        min_memory = min(memory_values)
        
        # „Ç¢„É©„Éº„ÉàÁµ±Ë®à
        alert_counts = defaultdict(int)
        for alert in self.alert_history:
            alert_counts[alert.level] += 1
        
        return {
            'summary': {
                'monitoring_duration_minutes': duration_minutes,
                'total_snapshots': len(snapshots),
                'peak_memory_mb': peak_memory,
                'average_memory_mb': avg_memory,
                'memory_variance_mb': peak_memory - min_memory
            },
            'performance': {
                'gc_triggers': self.stats['gc_triggers'],
                'leak_detections': self.stats['leak_detections'],
                'oom_preventions': self.stats['oom_preventions'],
                'total_memory_recovered_mb': self.stats['memory_recovered_mb']
            },
            'alerts': {
                'total_alerts': len(self.alert_history),
                'by_level': dict(alert_counts),
                'alert_rate_per_hour': len(self.alert_history) / max(duration_minutes / 60, 0.01)
            },
            'optimizations': {
                'rtx3080_enabled': self.rtx_optimizer is not None,
                'auto_gc_enabled': self.auto_gc_enabled,
                'leak_detection_enabled': self.leak_detection_enabled,
                'managed_caches': len(self.managed_caches),
                'managed_buffers': len(self.managed_buffers)
            }
        }

    def force_memory_cleanup(self) -> Dict[str, float]:
        """Âº∑Âà∂„É°„É¢„É™„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó"""
        memory_before = psutil.Process().memory_info().rss / (1024 ** 2)
        
        # ÁÆ°ÁêÜ„Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢
        self._cleanup_managed_caches()
        
        # Á∑äÊÄ•GC
        self._emergency_garbage_collection()
        
        # Áµ±Ë®àÊõ¥Êñ∞
        time.sleep(0.5)  # „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÂÆå‰∫ÜÂæÖÊ©ü
        memory_after = psutil.Process().memory_info().rss / (1024 ** 2)
        recovered = max(0.0, memory_before - memory_after)
        
        self.stats['memory_recovered_mb'] += recovered
        
        return {
            'memory_before_mb': memory_before,
            'memory_after_mb': memory_after,
            'recovered_mb': recovered,
            'success': recovered > 0
        }

    def shutdown(self):
        """„Ç∑„Çπ„ÉÜ„É†ÁµÇ‰∫Ü"""
        self.logger.info("üîÑ „É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 ÁµÇ‰∫Ü‰∏≠...")
        
        # Áõ£Ë¶ñÂÅúÊ≠¢
        self.stop_monitoring()
        
        # ÊúÄÁµÇ„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
        cleanup_result = self.force_memory_cleanup()
        
        # Áµ±Ë®à‰øùÂ≠ò
        self._save_session_stats()
        
        self.logger.info(f"‚úÖ „Ç∑„Çπ„ÉÜ„É†ÁµÇ‰∫ÜÂÆå‰∫Ü - ÊúÄÁµÇÂõûÂæ©: {cleanup_result['recovered_mb']:.1f}MB")

    def _save_session_stats(self):
        """„Çª„ÉÉ„Ç∑„Éß„É≥Áµ±Ë®à‰øùÂ≠ò"""
        try:
            stats_dir = Path("logs/memory_efficiency")
            stats_dir.mkdir(parents=True, exist_ok=True)
            
            session_data = {
                'timestamp': time.time(),
                'stats': self.stats,
                'efficiency_report': self.get_efficiency_report(),
                'config': self.config
            }
            
            timestamp_str = time.strftime("%Y%m%d_%H%M%S")
            stats_file = stats_dir / f"memory_session_{timestamp_str}.json"
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"üìä „Çª„ÉÉ„Ç∑„Éß„É≥Áµ±Ë®à‰øùÂ≠ò: {stats_file}")
            
        except Exception as e:
            self.logger.error(f"Áµ±Ë®à‰øùÂ≠ò„Ç®„É©„Éº: {e}")


def create_memory_efficiency_system(config: Dict[str, Any] = None) -> MemoryEfficiencySystemV3:
    """„É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 „Éï„Ç°„ÇØ„Éà„É™Èñ¢Êï∞"""
    default_config = {
        'monitoring_enabled': True,
        'auto_gc_enabled': True,
        'leak_detection_enabled': True,
        'oom_prevention_enabled': True,
        'rtx3080_optimization': True,
        'monitoring_interval': 1.0,
        'warning_threshold_percent': 85.0,
        'critical_threshold_percent': 95.0,
        'gpu_warning_threshold_percent': 90.0,
        'gc_trigger_threshold_mb': 100.0,
        'aggressive_gc_threshold_percent': 90.0
    }
    
    if config:
        default_config.update(config)
    
    return MemoryEfficiencySystemV3(default_config)


# „ÉÜ„Çπ„ÉàÈñ¢Êï∞
def test_memory_efficiency_system():
    """„É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É†„ÅÆ„ÉÜ„Çπ„Éà"""
    print("üß™ „É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 „ÉÜ„Çπ„ÉàÈñãÂßã")
    
    # „Ç∑„Çπ„ÉÜ„É†‰ΩúÊàê
    system = create_memory_efficiency_system({
        'monitoring_interval': 0.5,
        'warning_threshold_percent': 50.0  # „ÉÜ„Çπ„ÉàÁî®‰ΩéÈñæÂÄ§
    })
    
    try:
        # Áõ£Ë¶ñÈñãÂßã
        system.start_monitoring()
        
        # „É°„É¢„É™Ë≤†Ëç∑„ÉÜ„Çπ„Éà
        test_data = []
        for i in range(100):
            test_data.append([0] * 100000)  # „É°„É¢„É™‰ΩøÁî®ÈáèÂ¢óÂä†
            time.sleep(0.01)
        
        # ÁèæÂú®„ÅÆ„É°„É¢„É™ÊÉÖÂ†±
        memory_info = system.get_current_memory_info()
        print(f"üìä ÁèæÂú®„ÅÆ„É°„É¢„É™‰ΩøÁî®Èáè: {memory_info['process_memory_mb']:.1f}MB")
        
        # Âº∑Âà∂„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„ÉÜ„Çπ„Éà
        cleanup_result = system.force_memory_cleanup()
        print(f"üßπ „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÁµêÊûú: {cleanup_result}")
        
        # ÂäπÁéá„É¨„Éù„Éº„Éà
        efficiency_report = system.get_efficiency_report()
        print(f"üìà ÂäπÁéá„É¨„Éù„Éº„Éà: {efficiency_report['summary']}")
        
        # „ÉÜ„Çπ„ÉàÊàêÂäü
        print("‚úÖ „É°„É¢„É™ÂäπÁéáÂåñ„Ç∑„Çπ„ÉÜ„É† v3.0 „ÉÜ„Çπ„ÉàÂÆå‰∫Ü")
        
    except Exception as e:
        print(f"‚ùå „ÉÜ„Çπ„Éà„Ç®„É©„Éº: {e}")
        
    finally:
        # „Ç∑„Çπ„ÉÜ„É†ÁµÇ‰∫Ü
        system.shutdown()


if __name__ == "__main__":
    test_memory_efficiency_system() 