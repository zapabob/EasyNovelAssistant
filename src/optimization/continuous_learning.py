# -*- coding: utf-8 -*-
"""
Continuous Learning System for NKAT Expression Enhancement
ç¶™ç¶šè©•ä¾¡&å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ã¨LoRAå¾®èª¿æ•´
"""

import json
import os
import time
import threading
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import numpy as np
from tqdm import tqdm
import logging

@dataclass
class UserFeedback:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
    timestamp: float
    session_id: str
    input_text: str
    generated_text: str
    user_rating: int  # 1-5ã‚¹ã‚±ãƒ¼ãƒ«
    feedback_type: str  # "like", "dislike", "neutral"
    quality_metrics: Dict[str, float]
    nkat_parameters: Dict[str, Any]
    comments: Optional[str] = None
    user_id: Optional[str] = None

@dataclass
class GenerationMetrics:
    """ç”Ÿæˆãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: float
    session_id: str
    diversity_score: float
    contradiction_rate: float
    style_consistency: float
    processing_time: float
    memory_usage: float
    nkat_parameters: Dict[str, Any]
    
class FeedbackCollector:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.db_path = config.get('feedback_db_path', 'data/feedback.db')
        self.auto_collect = config.get('auto_collect_feedback', True)
        self.collection_interval = config.get('collection_interval', 3600)  # 1æ™‚é–“
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self._init_database()
        
        # åé›†çµ±è¨ˆ
        self.stats = {
            'total_feedbacks': 0,
            'positive_feedbacks': 0,
            'negative_feedbacks': 0,
            'average_rating': 0.0,
            'collection_rate': 0.0
        }
        
        # ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡
        self.feedback_buffer = deque(maxlen=100)
        self.metrics_buffer = deque(maxlen=500)
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰åé›†
        if self.auto_collect:
            self.collection_thread = threading.Thread(target=self._auto_collection_loop, daemon=True)
            self.collection_thread.start()
        
        logging.info("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†å™¨åˆæœŸåŒ–å®Œäº†")
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS feedbacks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    session_id TEXT,
                    input_text TEXT,
                    generated_text TEXT,
                    user_rating INTEGER,
                    feedback_type TEXT,
                    quality_metrics TEXT,
                    nkat_parameters TEXT,
                    comments TEXT,
                    user_id TEXT
                )
            ''')
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    session_id TEXT,
                    diversity_score REAL,
                    contradiction_rate REAL,
                    style_consistency REAL,
                    processing_time REAL,
                    memory_usage REAL,
                    nkat_parameters TEXT
                )
            ''')
            
            conn.commit()
    
    def collect_user_feedback(self, feedback: UserFeedback):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†"""
        # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        self.feedback_buffer.append(feedback)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO feedbacks (
                    timestamp, session_id, input_text, generated_text,
                    user_rating, feedback_type, quality_metrics, nkat_parameters,
                    comments, user_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                feedback.timestamp,
                feedback.session_id,
                feedback.input_text,
                feedback.generated_text,
                feedback.user_rating,
                feedback.feedback_type,
                json.dumps(feedback.quality_metrics),
                json.dumps(feedback.nkat_parameters),
                feedback.comments,
                feedback.user_id
            ))
            conn.commit()
        
        # çµ±è¨ˆæ›´æ–°
        self._update_feedback_stats(feedback)
        
        logging.info(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†: è©•ä¾¡={feedback.user_rating}/5, ã‚¿ã‚¤ãƒ—={feedback.feedback_type}")
    
    def collect_generation_metrics(self, metrics: GenerationMetrics):
        """ç”Ÿæˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        self.metrics_buffer.append(metrics)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO metrics (
                    timestamp, session_id, diversity_score, contradiction_rate,
                    style_consistency, processing_time, memory_usage, nkat_parameters
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                metrics.timestamp,
                metrics.session_id,
                metrics.diversity_score,
                metrics.contradiction_rate,
                metrics.style_consistency,
                metrics.processing_time,
                metrics.memory_usage,
                json.dumps(metrics.nkat_parameters)
            ))
            conn.commit()
    
    def _update_feedback_stats(self, feedback: UserFeedback):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±è¨ˆæ›´æ–°"""
        self.stats['total_feedbacks'] += 1
        
        if feedback.user_rating >= 4:
            self.stats['positive_feedbacks'] += 1
        elif feedback.user_rating <= 2:
            self.stats['negative_feedbacks'] += 1
        
        # å¹³å‡è©•ä¾¡æ›´æ–°
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT AVG(user_rating) FROM feedbacks')
            result = cursor.fetchone()
            self.stats['average_rating'] = result[0] if result[0] else 0.0
    
    def _auto_collection_loop(self):
        """è‡ªå‹•åé›†ãƒ«ãƒ¼ãƒ—"""
        while True:
            try:
                time.sleep(self.collection_interval)
                self._periodic_collection()
            except Exception as e:
                logging.error(f"è‡ªå‹•åé›†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _periodic_collection(self):
        """å®šæœŸåé›†å‡¦ç†"""
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        system_metrics = self._collect_system_metrics()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        performance_analysis = self._analyze_performance()
        
        logging.info(f"å®šæœŸåé›†å®Œäº†: ã‚·ã‚¹ãƒ†ãƒ ={len(system_metrics)}, è§£æ={len(performance_analysis)}")
    
    def _collect_system_metrics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            import psutil
            
            return {
                'cpu_usage': psutil.cpu_percent(),
                'memory_usage': psutil.virtual_memory().percent,
                'disk_usage': psutil.disk_usage('/').percent,
                'timestamp': time.time()
            }
        except ImportError:
            return {'timestamp': time.time(), 'error': 'psutil not available'}
    
    def _analyze_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        if len(self.metrics_buffer) < 10:
            return {}
        
        recent_metrics = list(self.metrics_buffer)[-20:]
        
        return {
            'avg_diversity': np.mean([m.diversity_score for m in recent_metrics]),
            'avg_contradiction_rate': np.mean([m.contradiction_rate for m in recent_metrics]),
            'avg_processing_time': np.mean([m.processing_time for m in recent_metrics]),
            'trend_diversity': self._calculate_trend([m.diversity_score for m in recent_metrics]),
            'trend_contradiction': self._calculate_trend([m.contradiction_rate for m in recent_metrics])
        }
    
    def _calculate_trend(self, values: List[float]) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        if len(values) < 2:
            return "unknown"
        
        first_half = np.mean(values[:len(values)//2])
        second_half = np.mean(values[len(values)//2:])
        
        if second_half > first_half * 1.05:
            return "improving"
        elif second_half < first_half * 0.95:
            return "declining"
        else:
            return "stable"
    
    def get_feedback_summary(self, days: int = 7) -> Dict[str, Any]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¦ç´„å–å¾—"""
        cutoff_time = time.time() - (days * 24 * 3600)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # æœŸé–“å†…ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            cursor.execute('''
                SELECT user_rating, feedback_type, quality_metrics, nkat_parameters
                FROM feedbacks WHERE timestamp > ?
            ''', (cutoff_time,))
            
            recent_feedbacks = cursor.fetchall()
        
        if not recent_feedbacks:
            return {"message": f"éå»{days}æ—¥é–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        # çµ±è¨ˆè¨ˆç®—
        ratings = [fb[0] for fb in recent_feedbacks]
        avg_rating = np.mean(ratings)
        
        type_counts = defaultdict(int)
        for fb in recent_feedbacks:
            type_counts[fb[1]] += 1
        
        return {
            'period_days': days,
            'total_feedbacks': len(recent_feedbacks),
            'average_rating': avg_rating,
            'rating_distribution': {i: ratings.count(i) for i in range(1, 6)},
            'feedback_types': dict(type_counts),
            'satisfaction_rate': sum(1 for r in ratings if r >= 4) / len(ratings) * 100
        }

class LoRATrainer:
    """LoRAå¾®èª¿æ•´ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.enabled = config.get('lora_training_enabled', True)
        self.training_schedule = config.get('training_schedule', 'weekly')
        self.batch_size = config.get('lora_batch_size', 8)
        self.learning_rate = config.get('lora_learning_rate', 1e-5)
        self.rank = config.get('lora_rank', 16)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        self.training_data_dir = config.get('training_data_dir', 'data/training')
        os.makedirs(self.training_data_dir, exist_ok=True)
        
        # è¨“ç·´çµ±è¨ˆ
        self.training_stats = {
            'total_trainings': 0,
            'successful_trainings': 0,
            'last_training_time': 0,
            'average_training_time': 0,
            'performance_improvements': []
        }
        
        logging.info(f"LoRAãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«={self.training_schedule}")
    
    def prepare_training_data(self, feedback_collector: FeedbackCollector) -> bool:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        if not self.enabled:
            return False
        
        # é«˜è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
        positive_feedbacks = self._get_positive_feedbacks(feedback_collector)
        
        if len(positive_feedbacks) < 10:
            logging.warning("ååˆ†ãªé«˜è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆæœ€å°10ä»¶å¿…è¦ï¼‰")
            return False
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        training_file = os.path.join(self.training_data_dir, f"training_{int(time.time())}.jsonl")
        
        with open(training_file, 'w', encoding='utf-8') as f:
            for feedback in positive_feedbacks:
                training_sample = {
                    'prompt': feedback[2],  # input_text
                    'completion': feedback[3],  # generated_text
                    'rating': feedback[4],  # user_rating
                    'quality_metrics': json.loads(feedback[5]),
                    'nkat_parameters': json.loads(feedback[6])
                }
                f.write(json.dumps(training_sample, ensure_ascii=False) + '\n')
        
        logging.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(positive_feedbacks)}ä»¶ â†’ {training_file}")
        return True
    
    def _get_positive_feedbacks(self, feedback_collector: FeedbackCollector) -> List[Tuple]:
        """é«˜è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å–å¾—"""
        cutoff_time = time.time() - (7 * 24 * 3600)  # éå»1é€±é–“
        
        with sqlite3.connect(feedback_collector.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT * FROM feedbacks 
                WHERE timestamp > ? AND user_rating >= 4
                ORDER BY user_rating DESC, timestamp DESC
                LIMIT 100
            ''', (cutoff_time,))
            
            return cursor.fetchall()
    
    def execute_training(self, feedback_collector: FeedbackCollector) -> bool:
        """LoRAè¨“ç·´å®Ÿè¡Œ"""
        if not self.enabled:
            return False
        
        start_time = time.time()
        
        try:
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™
            if not self.prepare_training_data(feedback_collector):
                return False
            
            # å®Ÿéš›ã®è¨“ç·´å®Ÿè¡Œï¼ˆæ¨¡æ“¬ï¼‰
            success = self._run_lora_training()
            
            # çµ±è¨ˆæ›´æ–°
            training_time = time.time() - start_time
            self._update_training_stats(success, training_time)
            
            if success:
                logging.info(f"LoRAè¨“ç·´å®Œäº†: {training_time:.1f}ç§’")
            else:
                logging.error("LoRAè¨“ç·´å¤±æ•—")
            
            return success
            
        except Exception as e:
            logging.error(f"LoRAè¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _run_lora_training(self) -> bool:
        """å®Ÿéš›ã®LoRAè¨“ç·´å®Ÿè¡Œï¼ˆæ¨¡æ“¬å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã“ã§LoRAãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
        # ä¾‹: peft, transformers, torchç­‰
        
        print("ğŸ”„ LoRAå¾®èª¿æ•´ã‚’é–‹å§‹...")
        
        # æ¨¡æ“¬è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹
        for epoch in tqdm(range(3), desc="Training Epochs"):
            time.sleep(1)  # å®Ÿéš›ã®è¨“ç·´æ™‚é–“ã‚’æ¨¡æ“¬
            
            # æ¨¡æ“¬æå¤±è¨ˆç®—
            mock_loss = 1.0 - (epoch * 0.3)
            print(f"  Epoch {epoch+1}: Loss = {mock_loss:.3f}")
        
        print("âœ… LoRAå¾®èª¿æ•´å®Œäº†")
        return True
    
    def _update_training_stats(self, success: bool, training_time: float):
        """è¨“ç·´çµ±è¨ˆæ›´æ–°"""
        self.training_stats['total_trainings'] += 1
        self.training_stats['last_training_time'] = time.time()
        
        if success:
            self.training_stats['successful_trainings'] += 1
        
        # å¹³å‡è¨“ç·´æ™‚é–“æ›´æ–°
        if self.training_stats['total_trainings'] == 1:
            self.training_stats['average_training_time'] = training_time
        else:
            current_avg = self.training_stats['average_training_time']
            new_avg = (current_avg + training_time) / 2
            self.training_stats['average_training_time'] = new_avg
    
    def get_training_report(self) -> Dict[str, Any]:
        """è¨“ç·´ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        success_rate = 0
        if self.training_stats['total_trainings'] > 0:
            success_rate = self.training_stats['successful_trainings'] / self.training_stats['total_trainings'] * 100
        
        return {
            'enabled': self.enabled,
            'training_schedule': self.training_schedule,
            'statistics': self.training_stats,
            'success_rate': success_rate,
            'last_training': datetime.fromtimestamp(self.training_stats['last_training_time']).isoformat() if self.training_stats['last_training_time'] > 0 else "æœªå®Ÿæ–½",
            'configuration': {
                'batch_size': self.batch_size,
                'learning_rate': self.learning_rate,
                'rank': self.rank
            }
        }

class MetricsTracker:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.tracking_enabled = config.get('metrics_tracking_enabled', True)
        self.ci_integration = config.get('ci_integration_enabled', False)
        self.alert_thresholds = config.get('alert_thresholds', {
            'diversity_min': 0.30,
            'contradiction_max': 0.10,
            'processing_time_max': 5.0
        })
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´
        self.metrics_history = deque(maxlen=1000)
        self.alerts = deque(maxlen=50)
        
        # CIçµ±åˆè¨­å®š
        self.ci_webhook = config.get('ci_webhook_url')
        self.ci_report_interval = config.get('ci_report_interval', 3600)  # 1æ™‚é–“
        
        logging.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡å™¨åˆæœŸåŒ–å®Œäº†")
    
    def track_metrics(self, metrics: Dict[str, Any]):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡"""
        if not self.tracking_enabled:
            return
        
        timestamp = time.time()
        metrics_entry = {
            'timestamp': timestamp,
            'metrics': metrics.copy()
        }
        
        self.metrics_history.append(metrics_entry)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        self._check_alerts(metrics, timestamp)
        
        # CIçµ±åˆ
        if self.ci_integration:
            self._send_ci_metrics(metrics_entry)
    
    def _check_alerts(self, metrics: Dict[str, Any], timestamp: float):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        alerts_triggered = []
        
        # å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯
        if 'diversity_score' in metrics:
            if metrics['diversity_score'] < self.alert_thresholds['diversity_min']:
                alerts_triggered.append({
                    'type': 'diversity_low',
                    'value': metrics['diversity_score'],
                    'threshold': self.alert_thresholds['diversity_min'],
                    'message': f"èªå½™å¤šæ§˜æ€§ãŒä½ä¸‹: {metrics['diversity_score']:.2f} < {self.alert_thresholds['diversity_min']:.2f}"
                })
        
        # çŸ›ç›¾ç‡ãƒã‚§ãƒƒã‚¯
        if 'contradiction_rate' in metrics:
            if metrics['contradiction_rate'] > self.alert_thresholds['contradiction_max']:
                alerts_triggered.append({
                    'type': 'contradiction_high',
                    'value': metrics['contradiction_rate'],
                    'threshold': self.alert_thresholds['contradiction_max'],
                    'message': f"çŸ›ç›¾ç‡ãŒä¸Šæ˜‡: {metrics['contradiction_rate']:.2f} > {self.alert_thresholds['contradiction_max']:.2f}"
                })
        
        # å‡¦ç†æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if 'processing_time' in metrics:
            if metrics['processing_time'] > self.alert_thresholds['processing_time_max']:
                alerts_triggered.append({
                    'type': 'processing_slow',
                    'value': metrics['processing_time'],
                    'threshold': self.alert_thresholds['processing_time_max'],
                    'message': f"å‡¦ç†æ™‚é–“ãŒé•·ã„: {metrics['processing_time']:.2f}s > {self.alert_thresholds['processing_time_max']:.2f}s"
                })
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨˜éŒ²
        for alert in alerts_triggered:
            alert['timestamp'] = timestamp
            self.alerts.append(alert)
            logging.warning(f"ğŸš¨ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert['message']}")
    
    def _send_ci_metrics(self, metrics_entry: Dict[str, Any]):
        """CIçµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡"""
        try:
            if self.ci_webhook:
                import requests
                
                payload = {
                    'timestamp': metrics_entry['timestamp'],
                    'metrics': metrics_entry['metrics'],
                    'system': 'EasyNovelAssistant-NKAT'
                }
                
                response = requests.post(self.ci_webhook, json=payload, timeout=10)
                if response.status_code == 200:
                    logging.debug("CI ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡æˆåŠŸ")
                else:
                    logging.warning(f"CI ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡å¤±æ•—: {response.status_code}")
        except Exception as e:
            logging.error(f"CIçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_metrics_report(self, hours: int = 24) -> Dict[str, Any]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        cutoff_time = time.time() - (hours * 3600)
        
        recent_metrics = [
            entry for entry in self.metrics_history
            if entry['timestamp'] > cutoff_time
        ]
        
        if not recent_metrics:
            return {"message": f"éå»{hours}æ™‚é–“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        # çµ±è¨ˆè¨ˆç®—
        diversity_scores = [m['metrics'].get('diversity_score', 0) for m in recent_metrics]
        contradiction_rates = [m['metrics'].get('contradiction_rate', 0) for m in recent_metrics]
        processing_times = [m['metrics'].get('processing_time', 0) for m in recent_metrics]
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
        recent_alerts = [
            alert for alert in self.alerts
            if alert['timestamp'] > cutoff_time
        ]
        
        return {
            'period_hours': hours,
            'total_samples': len(recent_metrics),
            'diversity_stats': {
                'average': np.mean(diversity_scores) if diversity_scores else 0,
                'min': min(diversity_scores) if diversity_scores else 0,
                'max': max(diversity_scores) if diversity_scores else 0,
                'trend': self._calculate_trend(diversity_scores)
            },
            'contradiction_stats': {
                'average': np.mean(contradiction_rates) if contradiction_rates else 0,
                'min': min(contradiction_rates) if contradiction_rates else 0,
                'max': max(contradiction_rates) if contradiction_rates else 0,
                'trend': self._calculate_trend(contradiction_rates)
            },
            'performance_stats': {
                'average_processing_time': np.mean(processing_times) if processing_times else 0,
                'min_processing_time': min(processing_times) if processing_times else 0,
                'max_processing_time': max(processing_times) if processing_times else 0
            },
            'alerts': {
                'total': len(recent_alerts),
                'by_type': {alert_type: sum(1 for a in recent_alerts if a['type'] == alert_type) 
                           for alert_type in set(a['type'] for a in recent_alerts)},
                'recent': list(recent_alerts)[-5:]  # æœ€æ–°5ä»¶
            },
            'alert_thresholds': self.alert_thresholds
        }
    
    def _calculate_trend(self, values: List[float]) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        if len(values) < 2:
            return "unknown"
        
        first_half = np.mean(values[:len(values)//2])
        second_half = np.mean(values[len(values)//2:])
        
        if second_half > first_half * 1.05:
            return "improving"
        elif second_half < first_half * 0.95:
            return "declining"
        else:
            return "stable"

class ContinuousLearningSystem:
    """ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.enabled = config.get('continuous_learning_enabled', True)
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.feedback_collector = FeedbackCollector(config)
        self.lora_trainer = LoRATrainer(config)
        self.metrics_tracker = MetricsTracker(config)
        
        # é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
        self.weekly_scheduler = threading.Thread(target=self._weekly_schedule, daemon=True)
        if self.enabled:
            self.weekly_scheduler.start()
        
        logging.info("ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def record_interaction(self, prompt: str, generated_text: str, 
                          user_feedback: Optional[Dict[str, Any]] = None,
                          metrics: Optional[Dict[str, Any]] = None,
                          session_id: str = "default"):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²"""
        if not self.enabled:
            return
        
        timestamp = time.time()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²
        if user_feedback:
            feedback = UserFeedback(
                timestamp=timestamp,
                session_id=session_id,
                input_text=prompt,
                generated_text=generated_text,
                user_rating=user_feedback.get('rating', 3),
                feedback_type=user_feedback.get('type', 'neutral'),
                quality_metrics=user_feedback.get('quality_metrics', {}),
                nkat_parameters=user_feedback.get('nkat_parameters', {}),
                comments=user_feedback.get('comments'),
                user_id=user_feedback.get('user_id')
            )
            self.feedback_collector.collect_user_feedback(feedback)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        if metrics:
            generation_metrics = GenerationMetrics(
                timestamp=timestamp,
                session_id=session_id,
                diversity_score=metrics.get('diversity_score', 0.0),
                contradiction_rate=metrics.get('contradiction_rate', 0.0),
                style_consistency=metrics.get('style_consistency', 0.0),
                processing_time=metrics.get('processing_time', 0.0),
                memory_usage=metrics.get('memory_usage', 0.0),
                nkat_parameters=metrics.get('nkat_parameters', {})
            )
            self.feedback_collector.collect_generation_metrics(generation_metrics)
            self.metrics_tracker.track_metrics(metrics)
    
    def _weekly_schedule(self):
        """é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ"""
        while self.enabled:
            try:
                # 1é€±é–“å¾…æ©Ÿ
                time.sleep(7 * 24 * 3600)
                
                logging.info("ğŸ—“ï¸ é€±æ¬¡å­¦ç¿’ã‚¿ã‚¹ã‚¯é–‹å§‹")
                
                # LoRAå¾®èª¿æ•´å®Ÿè¡Œ
                if self.lora_trainer.execute_training(self.feedback_collector):
                    logging.info("âœ… é€±æ¬¡LoRAå¾®èª¿æ•´å®Œäº†")
                else:
                    logging.warning("âš ï¸ é€±æ¬¡LoRAå¾®èª¿æ•´ã‚¹ã‚­ãƒƒãƒ—")
                
                # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                self._generate_weekly_report()
                
            except Exception as e:
                logging.error(f"é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_weekly_report(self):
        """é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            report = {
                'timestamp': time.time(),
                'week': datetime.now().strftime('%Y-W%U'),
                'feedback_summary': self.feedback_collector.get_feedback_summary(7),
                'training_report': self.lora_trainer.get_training_report(),
                'metrics_report': self.metrics_tracker.get_metrics_report(24 * 7)
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            os.makedirs('reports', exist_ok=True)
            report_file = f"reports/weekly_report_{int(time.time())}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logging.info(f"ğŸ“Š é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
            
        except Exception as e:
            logging.error(f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_comprehensive_report(self) -> Dict[str, Any]:
        """ç·åˆãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        return {
            'system_status': {
                'enabled': self.enabled,
                'components': {
                    'feedback_collector': True,
                    'lora_trainer': self.lora_trainer.enabled,
                    'metrics_tracker': self.metrics_tracker.tracking_enabled
                }
            },
            'feedback_summary': self.feedback_collector.get_feedback_summary(7),
            'training_status': self.lora_trainer.get_training_report(),
            'metrics_overview': self.metrics_tracker.get_metrics_report(24),
            'recommendations': self._generate_recommendations()
        }
    
    def _generate_recommendations(self) -> List[str]:
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        recommendations = []
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã«åŸºã¥ãææ¡ˆ
        feedback_summary = self.feedback_collector.get_feedback_summary(7)
        if feedback_summary.get('satisfaction_rate', 0) < 70:
            recommendations.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦å‘ä¸Š: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’æ¤œè¨")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æã«åŸºã¥ãææ¡ˆ
        metrics_report = self.metrics_tracker.get_metrics_report(24)
        if metrics_report.get('diversity_stats', {}).get('average', 0) < 0.30:
            recommendations.append("èªå½™å¤šæ§˜æ€§å‘ä¸Š: Î³å€¤ã‚’ä¸‹ã’ã‚‹æ¤œè¨")
        
        if metrics_report.get('contradiction_stats', {}).get('average', 0) > 0.10:
            recommendations.append("çŸ›ç›¾ç‡å‰Šæ¸›: å“è³ªã‚¬ãƒ¼ãƒ‰å¼·åŒ–ã‚’æ¤œè¨")
        
        if not recommendations:
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ ã¯è‰¯å¥½ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        
        return recommendations

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
def test_continuous_learning():
    """ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    config = {
        'continuous_learning_enabled': True,
        'feedback_db_path': 'test_feedback.db',
        'lora_training_enabled': True,
        'metrics_tracking_enabled': True
    }
    
    system = ContinuousLearningSystem(config)
    
    # ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
    print("ğŸ§ª ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    for i in range(5):
        system.record_interaction(
            prompt=f"ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ{i+1}",
            generated_text=f"ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ{i+1}",
            user_feedback={
                'rating': 4 if i % 2 == 0 else 3,
                'type': 'like' if i % 2 == 0 else 'neutral',
                'quality_metrics': {'diversity': 0.3 + i*0.1},
                'nkat_parameters': {'theta_rank': 6, 'theta_gamma': 0.98}
            },
            metrics={
                'diversity_score': 0.3 + i*0.05,
                'contradiction_rate': 0.1 - i*0.02,
                'processing_time': 2.5 + i*0.5
            }
        )
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = system.get_comprehensive_report()
    print("ğŸ“Š ç·åˆãƒ¬ãƒãƒ¼ãƒˆ:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_continuous_learning() 