# -*- coding: utf-8 -*-
"""
NKAT Integration Manager
Phase 3: çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼

ã€çµ±åˆæ©Ÿèƒ½ã€‘
1. æ—¢å­˜NKATçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æº
2. Advanced Tensor Processingã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ
3. EasyNovelAssistantã¨ã®çµ±åˆç®¡ç†
4. åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å”èª¿
5. LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æº
6. ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ

Author: EasyNovelAssistant Development Team
Date: 2025-01-06
Version: Phase 3 Integration Manager
"""

import os
import sys
import json
import time
import threading
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from collections import defaultdict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
src_dir = os.path.join(project_root, "src")
sys.path.insert(0, project_root)
sys.path.insert(0, src_dir)

try:
    from nkat.nkat_advanced_tensor import NKATAdvancedProcessor, create_advanced_nkat_processor
    from nkat.nkat_integration import NKATIntegration, TextConsistencyProcessor
    from nkat.advanced_consistency import AdvancedConsistencyProcessor, ConsistencyLevel
    NKAT_COMPONENTS_AVAILABLE = True
except ImportError:
    NKAT_COMPONENTS_AVAILABLE = False

try:
    from utils.repetition_suppressor_v3 import AdvancedRepetitionSuppressorV3
    from integration.lora_style_coordinator import LoRAStyleCoordinator
    from integration.cross_suppression_engine import CrossSuppressionEngine
    INTEGRATION_SYSTEMS_AVAILABLE = True
except ImportError:
    INTEGRATION_SYSTEMS_AVAILABLE = False


@dataclass
class NKATProcessingResult:
    """NKATå‡¦ç†çµæœ"""
    original_text: str
    enhanced_text: str
    processing_stages: Dict[str, Any]
    quality_metrics: Dict[str, float]
    performance_metrics: Dict[str, float]
    system_coordination: Dict[str, bool]
    total_processing_time_ms: float
    success: bool
    error_message: Optional[str] = None


@dataclass
class SystemCoordination:
    """ã‚·ã‚¹ãƒ†ãƒ å”èª¿çŠ¶æ…‹"""
    repetition_suppression_active: bool
    lora_coordination_active: bool
    cross_suppression_active: bool
    nkat_advanced_active: bool
    nkat_legacy_active: bool
    coordination_efficiency: float


class NKATIntegrationManager:
    """NKATçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._default_config()
        self.logger = logging.getLogger(__name__)
        
        # ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.advanced_processor: Optional[NKATAdvancedProcessor] = None
        self.legacy_nkat: Optional[NKATIntegration] = None
        self.consistency_processor: Optional[AdvancedConsistencyProcessor] = None
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
        self.repetition_suppressor: Optional[AdvancedRepetitionSuppressorV3] = None
        self.lora_coordinator: Optional[LoRAStyleCoordinator] = None
        self.cross_engine: Optional[CrossSuppressionEngine] = None
        
        # çµ±åˆçŠ¶æ…‹ç®¡ç†
        self.system_coordination = SystemCoordination(
            repetition_suppression_active=False,
            lora_coordination_active=False,
            cross_suppression_active=False,
            nkat_advanced_active=False,
            nkat_legacy_active=False,
            coordination_efficiency=0.0
        )
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.performance_stats = {
            'total_requests': 0,
            'successful_processes': 0,
            'average_processing_time': 0.0,
            'quality_improvements': 0,
            'system_errors': 0,
            'coordination_score': 0.0
        }
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•å‡¦ç†
        self.processing_lock = threading.RLock()
        
        self._initialize_systems()
        self.logger.info("ğŸ¯ NKATçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†")
    
    def _default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            # NKAT Advancedè¨­å®š
            'nkat_advanced': {
                'enabled': True,
                'tensor_dimension': 256,
                'quality_threshold': 0.7,
                'max_iterations': 8,
                'literary_enhancement': True
            },
            
            # Legacy NKATè¨­å®š
            'nkat_legacy': {
                'enabled': True,
                'consistency_mode': True,
                'advanced_mode': True
            },
            
            # çµ±åˆã‚·ã‚¹ãƒ†ãƒ è¨­å®š
            'integration_systems': {
                'repetition_suppression': True,
                'lora_coordination': True,
                'cross_suppression': True
            },
            
            # å‡¦ç†é †åºè¨­å®š
            'processing_pipeline': [
                'cross_suppression',
                'nkat_advanced',
                'lora_coordination',
                'repetition_suppression',
                'nkat_legacy'
            ],
            
            # å”èª¿åˆ¶å¾¡è¨­å®š
            'coordination': {
                'enable_parallel_processing': False,
                'quality_gate_threshold': 0.5,
                'error_recovery_enabled': True,
                'adaptive_optimization': True
            },
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
            'performance': {
                'cache_enabled': True,
                'max_processing_time_ms': 5000,
                'quality_priority': True
            }
        }
    
    def _initialize_systems(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        initialization_results = {}
        
        # NKAT Advanced Processor
        if NKAT_COMPONENTS_AVAILABLE and self.config['nkat_advanced']['enabled']:
            try:
                self.advanced_processor = create_advanced_nkat_processor(
                    self.config['nkat_advanced']
                )
                self.system_coordination.nkat_advanced_active = True
                initialization_results['nkat_advanced'] = True
                self.logger.info("âœ… NKAT Advanced Processor åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                initialization_results['nkat_advanced'] = False
                self.logger.error(f"âŒ NKAT Advanced Processor åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # Legacy NKAT Integration
        if NKAT_COMPONENTS_AVAILABLE and self.config['nkat_legacy']['enabled']:
            try:
                # ãƒ¢ãƒƒã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
                mock_context = type('MockContext', (), self.config['nkat_legacy'])()
                self.legacy_nkat = NKATIntegration(mock_context)
                
                # Advanced Consistency Processor
                self.consistency_processor = AdvancedConsistencyProcessor(
                    self.config['nkat_legacy']
                )
                
                self.system_coordination.nkat_legacy_active = True
                initialization_results['nkat_legacy'] = True
                self.logger.info("âœ… Legacy NKAT System åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                initialization_results['nkat_legacy'] = False
                self.logger.error(f"âŒ Legacy NKAT System åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if INTEGRATION_SYSTEMS_AVAILABLE:
            self._initialize_integration_systems()
        else:
            self.logger.warning("âš ï¸ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆåå¾©æŠ‘åˆ¶v3ã€LoRAã€ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ï¼‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # å”èª¿åŠ¹ç‡ã®è¨ˆç®—
        active_systems = sum([
            self.system_coordination.nkat_advanced_active,
            self.system_coordination.nkat_legacy_active,
            self.system_coordination.repetition_suppression_active,
            self.system_coordination.lora_coordination_active,
            self.system_coordination.cross_suppression_active
        ])
        
        self.system_coordination.coordination_efficiency = active_systems / 5.0
        
        self.logger.info(f"ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†: {active_systems}/5 ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
    
    def _initialize_integration_systems(self):
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        config = self.config['integration_systems']
        
        # åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ 
        if config.get('repetition_suppression', True):
            try:
                repetition_config = {
                    'similarity_threshold': 0.30,
                    'max_distance': 60,
                    'min_compress_rate': 0.02,
                    'enable_4gram_blocking': True,
                    'ngram_block_size': 3,
                    'enable_drp': True,
                    'drp_base': 1.15,
                    'drp_alpha': 0.6
                }
                self.repetition_suppressor = AdvancedRepetitionSuppressorV3(repetition_config)
                self.system_coordination.repetition_suppression_active = True
                self.logger.info("âœ… åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ 
        if config.get('lora_coordination', True):
            try:
                from integration.lora_style_coordinator import create_default_coordinator
                self.lora_coordinator = create_default_coordinator()
                self.system_coordination.lora_coordination_active = True
                self.logger.info("âœ… LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ 
        if config.get('cross_suppression', True):
            try:
                from integration.cross_suppression_engine import create_default_cross_engine
                self.cross_engine = create_default_cross_engine()
                if self.cross_engine.initialize_systems():
                    self.system_coordination.cross_suppression_active = True
                    self.logger.info("âœ… ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  åˆæœŸåŒ–å¤±æ•—: {e}")
    
    def process_text_comprehensive(self, text: str, character: str = None,
                                 context: str = None, session_id: str = None,
                                 style_weight: float = 1.0,
                                 target_quality: float = None) -> NKATProcessingResult:
        """åŒ…æ‹¬çš„ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†"""
        start_time = time.time()
        
        with self.processing_lock:
            self.performance_stats['total_requests'] += 1
            
            processing_stages = {}
            current_text = text
            
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            try:
                # å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                pipeline = self.config['processing_pipeline']
                
                for stage_name in pipeline:
                    stage_start = time.time()
                    stage_result = self._execute_processing_stage(
                        stage_name, current_text, character, context, 
                        session_id, style_weight, target_quality
                    )
                    
                    if stage_result['success']:
                        current_text = stage_result['output_text']
                        processing_stages[stage_name] = {
                            'input': stage_result['input_text'],
                            'output': stage_result['output_text'],
                            'metrics': stage_result.get('metrics', {}),
                            'processing_time_ms': (time.time() - stage_start) * 1000,
                            'success': True
                        }
                    else:
                        processing_stages[stage_name] = {
                            'input': stage_result['input_text'],
                            'output': stage_result['input_text'],  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            'error': stage_result.get('error', 'Unknown error'),
                            'processing_time_ms': (time.time() - stage_start) * 1000,
                            'success': False
                        }
                        
                        if not self.config['coordination']['error_recovery_enabled']:
                            break  # ã‚¨ãƒ©ãƒ¼å›å¾©ãŒç„¡åŠ¹ã®å ´åˆã¯å‡¦ç†åœæ­¢
                
                # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                quality_metrics = self._calculate_quality_metrics(text, current_text)
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                total_time = (time.time() - start_time) * 1000
                performance_metrics = self._calculate_performance_metrics(
                    processing_stages, total_time
                )
                
                # æˆåŠŸåˆ¤å®š
                success = (len(current_text) > 0 and 
                          quality_metrics.get('overall_quality', 0) > 0.3)
                
                if success:
                    self.performance_stats['successful_processes'] += 1
                    if quality_metrics.get('quality_improvement', 0) > 0.1:
                        self.performance_stats['quality_improvements'] += 1
                
                # çµ±è¨ˆæ›´æ–°
                self._update_performance_stats(total_time, success)
                
                return NKATProcessingResult(
                    original_text=text,
                    enhanced_text=current_text,
                    processing_stages=processing_stages,
                    quality_metrics=quality_metrics,
                    performance_metrics=performance_metrics,
                    system_coordination=asdict(self.system_coordination),
                    total_processing_time_ms=total_time,
                    success=success
                )
                
            except Exception as e:
                self.performance_stats['system_errors'] += 1
                self.logger.error(f"åŒ…æ‹¬çš„å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                
                return NKATProcessingResult(
                    original_text=text,
                    enhanced_text=text,  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    processing_stages={},
                    quality_metrics={},
                    performance_metrics={},
                    system_coordination=asdict(self.system_coordination),
                    total_processing_time_ms=(time.time() - start_time) * 1000,
                    success=False,
                    error_message=str(e)
                )
    
    def _execute_processing_stage(self, stage_name: str, text: str, 
                                character: str, context: str, session_id: str,
                                style_weight: float, target_quality: float) -> Dict[str, Any]:
        """å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸ã®å®Ÿè¡Œ"""
        try:
            if stage_name == 'nkat_advanced' and self.advanced_processor:
                enhanced_text, metrics = self.advanced_processor.process_expression(
                    text, character, context, target_quality
                )
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': enhanced_text,
                    'metrics': metrics
                }
            
            elif stage_name == 'nkat_legacy' and self.legacy_nkat:
                enhanced_text = self.legacy_nkat.enhance_text_generation(
                    prompt=context or "",
                    llm_output=text
                )
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': enhanced_text,
                    'metrics': {}
                }
            
            elif stage_name == 'repetition_suppression' and self.repetition_suppressor:
                enhanced_text, metrics = self.repetition_suppressor.suppress_repetitions_with_debug_v3(
                    text, character
                )
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': enhanced_text,
                    'metrics': metrics.__dict__ if hasattr(metrics, '__dict__') else {}
                }
            
            elif stage_name == 'lora_coordination' and self.lora_coordinator:
                enhanced_text, metrics = self.lora_coordinator.process_text_with_coordination(
                    text, character, style_weight
                )
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': enhanced_text,
                    'metrics': metrics
                }
            
            elif stage_name == 'cross_suppression' and self.cross_engine:
                enhanced_text, metrics = self.cross_engine.process_with_cross_suppression(
                    text, character, session_id
                )
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': enhanced_text,
                    'metrics': metrics
                }
            
            else:
                # ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ããªã„å ´åˆ
                return {
                    'success': True,
                    'input_text': text,
                    'output_text': text,  # ãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼
                    'metrics': {}
                }
                
        except Exception as e:
            return {
                'success': False,
                'input_text': text,
                'output_text': text,
                'error': str(e)
            }
    
    def _calculate_quality_metrics(self, original: str, enhanced: str) -> Dict[str, float]:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        if not enhanced or enhanced == original:
            return {
                'overall_quality': 0.5,
                'quality_improvement': 0.0,
                'text_diversity': 0.0,
                'coherence': 1.0
            }
        
        # åŸºæœ¬çš„ãªå“è³ªæŒ‡æ¨™
        compression_rate = (len(original) - len(enhanced)) / len(original)
        word_diversity = len(set(enhanced.split())) / max(len(enhanced.split()), 1)
        
        # å˜ç´”ãªå“è³ªã‚¹ã‚³ã‚¢ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰
        quality_score = 0.5 + min(0.4, word_diversity) + min(0.1, max(0, compression_rate))
        quality_improvement = quality_score - 0.5  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³0.5
        
        return {
            'overall_quality': quality_score,
            'quality_improvement': quality_improvement,
            'text_diversity': word_diversity,
            'coherence': 0.9,  # ç°¡æ˜“å®Ÿè£…
            'compression_rate': compression_rate
        }
    
    def _calculate_performance_metrics(self, processing_stages: Dict[str, Any], 
                                     total_time: float) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        successful_stages = sum(1 for stage in processing_stages.values() 
                              if stage.get('success', False))
        total_stages = len(processing_stages)
        
        stage_times = [stage.get('processing_time_ms', 0) 
                      for stage in processing_stages.values()]
        avg_stage_time = sum(stage_times) / max(len(stage_times), 1)
        
        return {
            'total_processing_time_ms': total_time,
            'average_stage_time_ms': avg_stage_time,
            'stage_success_rate': successful_stages / max(total_stages, 1),
            'processing_efficiency': successful_stages / max(total_time / 1000, 0.001),
            'system_coordination_score': self.system_coordination.coordination_efficiency
        }
    
    def _update_performance_stats(self, processing_time: float, success: bool):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®æ›´æ–°"""
        # å¹³å‡å‡¦ç†æ™‚é–“ã®æ›´æ–°
        total_requests = self.performance_stats['total_requests']
        current_avg = self.performance_stats['average_processing_time']
        new_avg = ((current_avg * (total_requests - 1)) + processing_time) / total_requests
        self.performance_stats['average_processing_time'] = new_avg
        
        # å”èª¿ã‚¹ã‚³ã‚¢ã®æ›´æ–°
        active_systems = sum([
            self.system_coordination.nkat_advanced_active,
            self.system_coordination.nkat_legacy_active,
            self.system_coordination.repetition_suppression_active,
            self.system_coordination.lora_coordination_active,
            self.system_coordination.cross_suppression_active
        ])
        
        self.performance_stats['coordination_score'] = active_systems / 5.0
    
    def get_system_status(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®å–å¾—"""
        return {
            'system_coordination': asdict(self.system_coordination),
            'performance_stats': self.performance_stats,
            'active_systems': {
                'nkat_advanced': self.advanced_processor is not None,
                'nkat_legacy': self.legacy_nkat is not None,
                'repetition_suppression': self.repetition_suppressor is not None,
                'lora_coordination': self.lora_coordinator is not None,
                'cross_suppression': self.cross_engine is not None
            },
            'configuration': {
                'processing_pipeline': self.config['processing_pipeline'],
                'coordination_enabled': self.config['coordination'],
                'performance_settings': self.config['performance']
            }
        }
    
    def optimize_configuration(self) -> Dict[str, Any]:
        """è¨­å®šã®æœ€é©åŒ–"""
        optimization_results = {}
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        success_rate = (self.performance_stats['successful_processes'] / 
                       max(self.performance_stats['total_requests'], 1))
        avg_time = self.performance_stats['average_processing_time']
        
        # æœ€é©åŒ–ææ¡ˆ
        if success_rate < 0.8:
            optimization_results['recommendation'] = "error_recovery_å¼·åŒ–"
            optimization_results['suggested_config'] = {
                'coordination.error_recovery_enabled': True,
                'coordination.quality_gate_threshold': 0.3
            }
        
        if avg_time > 3000:  # 3ç§’ä»¥ä¸Š
            optimization_results['recommendation'] = "performance_å„ªå…ˆ"
            optimization_results['suggested_config'] = {
                'nkat_advanced.max_iterations': 5,
                'performance.quality_priority': False
            }
        
        return optimization_results
    
    def clear_all_caches(self):
        """å…¨ã‚·ã‚¹ãƒ†ãƒ ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        if self.advanced_processor:
            self.advanced_processor.clear_cache()
        
        # ä»–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
        self.logger.info("ğŸ§¹ å…¨ã‚·ã‚¹ãƒ†ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")


def create_nkat_integration_manager(config: Dict[str, Any] = None) -> NKATIntegrationManager:
    """NKATçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ä½œæˆ"""
    return NKATIntegrationManager(config)


if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ¯ NKATçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
    manager = create_nkat_integration_manager()
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
    status = manager.get_system_status()
    print(f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹:")
    print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚·ã‚¹ãƒ†ãƒ æ•°: {sum(status['active_systems'].values())}/5")
    print(f"   å”èª¿åŠ¹ç‡: {status['system_coordination']['coordination_efficiency']:.1%}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            'text': 'ãŠå…„ã¡ã‚ƒã‚“ãŠå…„ã¡ã‚ƒã‚“ã€ã©ã“ã«è¡Œãã®ã§ã™ã‹ãŠå…„ã¡ã‚ƒã‚“ï¼Ÿ',
            'character': 'å¦¹ã‚­ãƒ£ãƒ©',
            'context': 'å®¶æ—ä¼šè©±',
            'session_id': 'demo_session_1'
        },
        {
            'text': 'å¬‰ã—ã„ã§ã™ã€‚ã¨ã¦ã‚‚å¬‰ã—ã„ã§ã™ã€‚æœ¬å½“ã«å¬‰ã—ã„ã§ã™ã€‚',
            'character': 'æ¨¹é‡Œ',
            'context': 'æ„Ÿæƒ…è¡¨ç¾',
            'session_id': 'demo_session_2'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“ çµ±åˆå‡¦ç†ãƒ†ã‚¹ãƒˆ {i}")
        print(f"   ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {case['character']}")
        print(f"   åŸæ–‡: {case['text']}")
        
        # åŒ…æ‹¬çš„å‡¦ç†å®Ÿè¡Œ
        result = manager.process_text_comprehensive(
            case['text'], case['character'], case['context'], case['session_id']
        )
        
        print(f"   æ‹¡å¼µå¾Œ: {result.enhanced_text}")
        print(f"   æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
        print(f"   ç·å‡¦ç†æ™‚é–“: {result.total_processing_time_ms:.1f}ms")
        print(f"   å“è³ªæ”¹å–„: {result.quality_metrics.get('quality_improvement', 0):.3f}")
        
        # å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸è©³ç´°
        print(f"   å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸:")
        for stage_name, stage_data in result.processing_stages.items():
            status_icon = "âœ…" if stage_data.get('success', False) else "âŒ"
            print(f"     {status_icon} {stage_name}: {stage_data.get('processing_time_ms', 0):.1f}ms")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    final_status = manager.get_system_status()
    print(f"\nğŸ“ˆ æœ€çµ‚çµ±è¨ˆ:")
    print(f"   ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {final_status['performance_stats']['total_requests']}")
    print(f"   æˆåŠŸå‡¦ç†: {final_status['performance_stats']['successful_processes']}")
    print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {final_status['performance_stats']['average_processing_time']:.1f}ms")
    print(f"   å”èª¿ã‚¹ã‚³ã‚¢: {final_status['performance_stats']['coordination_score']:.1%}")
    
    # æœ€é©åŒ–ææ¡ˆ
    optimization = manager.optimize_configuration()
    if optimization:
        print(f"\nğŸ”§ æœ€é©åŒ–ææ¡ˆ: {optimization.get('recommendation', 'ãªã—')}")
    
    print("\nâœ… NKATçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ ãƒ‡ãƒ¢å®Œäº†") 