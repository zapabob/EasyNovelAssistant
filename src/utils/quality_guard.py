# -*- coding: utf-8 -*-
"""
Quality Guard System for NKAT Expression Enhancement
å“è³ªã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ  - "ç››ã‚Šéã"é˜²æ­¢ã¨è‡ªå‹•è£œæ­£æ©Ÿèƒ½
"""

import re
import json
import time
import threading
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from collections import defaultdict
import numpy as np
from tqdm import tqdm

@dataclass
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    grammar_score: float  # æ–‡æ³•ã‚¹ã‚³ã‚¢ (0.0-1.0)
    sense_score: float    # å¸¸è­˜æ€§ã‚¹ã‚³ã‚¢ (0.0-1.0)
    coherence_score: float # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ (0.0-1.0)
    diversity_score: float # å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢ (0.0-1.0)
    repetition_rate: float # åå¾©ç‡ (0.0-1.0)
    error_count: int      # ã‚¨ãƒ©ãƒ¼æ•°
    overall_score: float  # ç·åˆã‚¹ã‚³ã‚¢ (0.0-1.0)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'grammar_score': self.grammar_score,
            'sense_score': self.sense_score,
            'coherence_score': self.coherence_score,
            'diversity_score': self.diversity_score,
            'repetition_rate': self.repetition_rate,
            'error_count': self.error_count,
            'overall_score': self.overall_score
        }

class GrammarChecker:
    """æ–‡æ³•ãƒã‚§ãƒƒã‚«ãƒ¼"""
    
    def __init__(self):
        # æ–‡æ³•ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        self.error_patterns = {
            'particle_error': [
                (r'[ã‚’ã‚’ãŠ]([^ã-ã‚”ã‚¡-ãƒ¾])', 'åŠ©è©ã€Œã‚’ã€ã®èª¤ç”¨'),
                (r'[ã¯ã‚]([ãªã«])', 'åŠ©è©ã€Œã¯ã€ã®èª¤ç”¨'),
                (r'([ã‚ã„ã†ãˆãŠ])[ãŒã‹]([ã‚ã„ã†ãˆãŠ])', 'åŠ©è©ã®é‡è¤‡'),
            ],
            'conjugation_error': [
                (r'([ã‚‹å‹•è©])ã‚ŒãŸ', 'å‹•è©æ´»ç”¨ã‚¨ãƒ©ãƒ¼'),
                (r'([ã„å½¢å®¹è©])ã‹ã£ãŸ([^ã-ã‚”ã‚¡-ãƒ¾])', 'å½¢å®¹è©æ´»ç”¨ã‚¨ãƒ©ãƒ¼'),
            ],
            'punctuation_error': [
                (r'[ã€‚ï¼ï¼Ÿ]{3,}', 'å¥èª­ç‚¹ã®éå¤š'),
                (r'[ã€ï¼Œ]{2,}', 'èª­ç‚¹ã®é‡è¤‡'),
                (r'[ã€Œã€]{2,}', 'æ‹¬å¼§ã®é‡è¤‡'),
            ]
        }
        
        self.correction_rules = {
            'particle_correction': [
                (r'ã‚’ã‚’ã‚’', 'ã‚’'),
                (r'ã¯ã¯ã¯ã¯', 'ã¯'),
                (r'ãŒãŒãŒãŒ', 'ãŒ'),
            ],
            'repetition_correction': [
                (r'([ã‚-ã‚“])\1{4,}', r'\1\1\1'),  # 4æ–‡å­—ä»¥ä¸Šã®åå¾©ã‚’3æ–‡å­—ã«
                (r'([ï¼ï¼Ÿ]){4,}', r'\1\1\1'),     # æ„Ÿå˜†ç¬¦ã®éå¤šä¿®æ­£
                (r'(â€¦){3,}', r'\1\1'),            # çœç•¥è¨˜å·ã®éå¤šä¿®æ­£
            ]
        }
    
    def check_grammar(self, text: str) -> Tuple[float, List[Dict[str, Any]]]:
        """æ–‡æ³•ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        errors = []
        error_count = 0
        
        for category, patterns in self.error_patterns.items():
            for pattern, description in patterns:
                matches = re.finditer(pattern, text)
                for match in matches:
                    errors.append({
                        'category': category,
                        'description': description,
                        'position': match.span(),
                        'matched_text': match.group(),
                        'severity': self._calculate_severity(category)
                    })
                    error_count += 1
        
        # æ–‡æ³•ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚¨ãƒ©ãƒ¼æ•°ã«åŸºã¥ãï¼‰
        text_length = len(text)
        if text_length == 0:
            return 1.0, errors
        
        error_density = error_count / max(text_length, 1) * 100
        grammar_score = max(0.0, 1.0 - error_density * 0.1)
        
        return grammar_score, errors
    
    def _calculate_severity(self, category: str) -> float:
        """ã‚¨ãƒ©ãƒ¼ã®é‡è¦åº¦è¨ˆç®—"""
        severity_map = {
            'particle_error': 0.8,
            'conjugation_error': 0.9,
            'punctuation_error': 0.3
        }
        return severity_map.get(category, 0.5)
    
    def auto_correct_grammar(self, text: str) -> str:
        """è‡ªå‹•æ–‡æ³•è£œæ­£"""
        corrected_text = text
        
        for category, rules in self.correction_rules.items():
            for pattern, replacement in rules:
                corrected_text = re.sub(pattern, replacement, corrected_text)
        
        return corrected_text

class SenseChecker:
    """å¸¸è­˜æ€§ãƒã‚§ãƒƒã‚«ãƒ¼"""
    
    def __init__(self):
        # å¸¸è­˜çš„ã§ãªã„è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.nonsense_patterns = [
            (r'([ã‚-ã‚“])\1{10,}', 'ç•°å¸¸ãªåå¾©'),
            (r'[ï¼ï¼Ÿ]{5,}', 'æ„Ÿå˜†ç¬¦ã®éå¤š'),
            (r'[ã€‚]{3,}', 'å¥ç‚¹ã®éå¤š'),
            (r'åŒã˜[^ã€‚]{0,20}åŒã˜[^ã€‚]{0,20}åŒã˜', 'éåº¦ãªåå¾©è¡¨ç¾'),
        ]
        
        # ä¸€èˆ¬çš„ã§ãªã„èªå½™ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.unusual_vocab_patterns = [
            (r'[ï½±-ï¾]{5,}', 'åŠè§’ã‚«ã‚¿ã‚«ãƒŠã®éå¤š'),
            (r'[A-Z]{10,}', 'å¤§æ–‡å­—è‹±å­—ã®éå¤š'),
            (r'[0-9]{8,}', 'æ•°å­—ã®éå¤š'),
        ]
    
    def check_sense(self, text: str) -> Tuple[float, List[Dict[str, Any]]]:
        """å¸¸è­˜æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        issues = []
        issue_count = 0
        
        # éå¸¸è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern, description in self.nonsense_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                issues.append({
                    'type': 'nonsense',
                    'description': description,
                    'position': match.span(),
                    'matched_text': match.group(),
                    'severity': 0.8
                })
                issue_count += 1
        
        # ç•°å¸¸èªå½™ãƒã‚§ãƒƒã‚¯
        for pattern, description in self.unusual_vocab_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                issues.append({
                    'type': 'unusual_vocab',
                    'description': description,
                    'position': match.span(),
                    'matched_text': match.group(),
                    'severity': 0.6
                })
                issue_count += 1
        
        # å¸¸è­˜æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        text_length = len(text)
        if text_length == 0:
            return 1.0, issues
        
        issue_density = issue_count / max(text_length, 1) * 100
        sense_score = max(0.0, 1.0 - issue_density * 0.15)
        
        return sense_score, issues

class DiversityAnalyzer:
    """å¤šæ§˜æ€§åˆ†æå™¨"""
    
    def __init__(self):
        self.vocab_cache = {}
        
    def calculate_diversity(self, text: str) -> float:
        """èªå½™å¤šæ§˜æ€§è¨ˆç®—"""
        if len(text) < 10:
            return 0.0
        
        # å˜èªåˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        words = self._simple_tokenize(text)
        
        if len(words) < 2:
            return 0.0
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯èªå½™ç‡
        unique_words = set(words)
        diversity_score = len(unique_words) / len(words)
        
        return min(diversity_score, 1.0)
    
    def _simple_tokenize(self, text: str) -> List[str]:
        """ç°¡æ˜“ãƒˆãƒ¼ã‚¯ãƒ³åŒ–"""
        # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ã®å¢ƒç•Œã§åˆ†å‰²
        import re
        tokens = re.findall(r'[ã-ã‚“]+|[ã‚¡-ãƒ³]+|[ä¸€-é¾¯]+|[a-zA-Z]+|\d+', text)
        return tokens

class QualityGuard:
    """å“è³ªã‚¬ãƒ¼ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.enabled = config.get('quality_guard_enabled', True)
        self.error_threshold = config.get('auto_correction_threshold', 0.03)
        self.diversity_target = config.get('diversity_target', 0.35)
        self.gamma_adjustment = config.get('gamma_adjustment_step', 0.01)
        
        # å„ãƒã‚§ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–
        self.grammar_checker = GrammarChecker()
        self.sense_checker = SenseChecker()
        self.diversity_analyzer = DiversityAnalyzer()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_checks': 0,
            'corrections_applied': 0,
            'gamma_adjustments': 0,
            'average_quality_score': 0.0,
            'error_prevention_rate': 0.0
        }
        
        # å“è³ªå±¥æ­´
        self.quality_history = []
        self.max_history_size = config.get('quality_history_size', 100)
        
        print(f"ğŸ›¡ï¸ å“è³ªã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ– (é–¾å€¤: {self.error_threshold*100:.1f}%)")
    
    def evaluate_quality(self, text: str, context: str = "") -> QualityMetrics:
        """å“è³ªè©•ä¾¡å®Ÿè¡Œ"""
        if not self.enabled:
            return QualityMetrics(1.0, 1.0, 1.0, 1.0, 0.0, 0, 1.0)
        
        start_time = time.time()
        
        # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        grammar_score, grammar_errors = self.grammar_checker.check_grammar(text)
        sense_score, sense_issues = self.sense_checker.check_sense(text)
        diversity_score = self.diversity_analyzer.calculate_diversity(text)
        
        # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        coherence_score = self._calculate_coherence(text, context)
        
        # åå¾©ç‡è¨ˆç®—
        repetition_rate = self._calculate_repetition_rate(text)
        
        # ç·ã‚¨ãƒ©ãƒ¼æ•°
        total_errors = len(grammar_errors) + len(sense_issues)
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        overall_score = (
            grammar_score * 0.3 +
            sense_score * 0.25 +
            coherence_score * 0.25 +
            diversity_score * 0.2
        )
        
        metrics = QualityMetrics(
            grammar_score=grammar_score,
            sense_score=sense_score,
            coherence_score=coherence_score,
            diversity_score=diversity_score,
            repetition_rate=repetition_rate,
            error_count=total_errors,
            overall_score=overall_score
        )
        
        # çµ±è¨ˆæ›´æ–°
        self._update_stats(metrics, time.time() - start_time)
        
        return metrics
    
    def auto_correct_if_needed(self, text: str, current_gamma: float, 
                              context: str = "") -> Tuple[str, float, bool]:
        """å¿…è¦ã«å¿œã˜ã¦è‡ªå‹•è£œæ­£å®Ÿè¡Œ"""
        if not self.enabled:
            return text, current_gamma, False
        
        # å“è³ªè©•ä¾¡
        metrics = self.evaluate_quality(text, context)
        
        # ã‚¨ãƒ©ãƒ¼ç‡è¨ˆç®—
        text_length = len(text)
        error_rate = metrics.error_count / max(text_length, 1) * 100
        
        correction_applied = False
        new_gamma = current_gamma
        corrected_text = text
        
        # ã‚¨ãƒ©ãƒ¼ç‡ãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆ
        if error_rate > self.error_threshold * 100:
            # è‡ªå‹•æ–‡æ³•è£œæ­£
            corrected_text = self.grammar_checker.auto_correct_grammar(text)
            
            # Î³å€¤èª¿æ•´ï¼ˆå®‰å®šæ€§ã‚’é«˜ã‚ã‚‹ï¼‰
            new_gamma = min(1.0, current_gamma + self.gamma_adjustment)
            
            correction_applied = True
            self.stats['corrections_applied'] += 1
            self.stats['gamma_adjustments'] += 1
            
            print(f"ğŸ”§ å“è³ªã‚¬ãƒ¼ãƒ‰ç™ºå‹•: ã‚¨ãƒ©ãƒ¼ç‡ {error_rate:.1f}% â†’ Î³èª¿æ•´ {current_gamma:.3f} â†’ {new_gamma:.3f}")
        
        # å¤šæ§˜æ€§ä¸è¶³ã®å ´åˆ
        elif metrics.diversity_score < self.diversity_target:
            # Î³å€¤ã‚’ä¸‹ã’ã¦å¤šæ§˜æ€§ã‚’å‘ä¸Š
            new_gamma = max(0.8, current_gamma - self.gamma_adjustment * 0.5)
            
            if new_gamma != current_gamma:
                correction_applied = True
                self.stats['gamma_adjustments'] += 1
                print(f"ğŸ“ˆ å¤šæ§˜æ€§å‘ä¸Š: {metrics.diversity_score:.1f} â†’ Î³èª¿æ•´ {current_gamma:.3f} â†’ {new_gamma:.3f}")
        
        return corrected_text, new_gamma, correction_applied
    
    def _calculate_coherence(self, text: str, context: str) -> float:
        """ä¸€è²«æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not context or len(text) < 10:
            return 1.0
        
        # ç°¡æ˜“çš„ãªä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        context_chars = set(context.lower())
        text_chars = set(text.lower())
        
        # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®é¡ä¼¼åº¦
        common_chars = context_chars & text_chars
        if len(context_chars) == 0:
            return 1.0
        
        char_similarity = len(common_chars) / len(context_chars)
        
        # é•·ã•ã®ä¸€è²«æ€§
        length_ratio = min(len(text), len(context)) / max(len(text), len(context), 1)
        
        coherence_score = (char_similarity * 0.6 + length_ratio * 0.4)
        return min(coherence_score, 1.0)
    
    def _calculate_repetition_rate(self, text: str) -> float:
        """åå¾©ç‡è¨ˆç®—"""
        if len(text) < 4:
            return 0.0
        
        repetition_count = 0
        
        # 2æ–‡å­—ä»¥ä¸Šã®åå¾©æ¤œå‡º
        for length in range(2, min(8, len(text) // 3)):
            for i in range(len(text) - length):
                phrase = text[i:i+length]
                if text.count(phrase) > 1:
                    repetition_count += 1
        
        return min(repetition_count / len(text), 1.0)
    
    def _update_stats(self, metrics: QualityMetrics, processing_time: float):
        """çµ±è¨ˆæƒ…å ±æ›´æ–°"""
        self.stats['total_checks'] += 1
        
        # å“è³ªå±¥æ­´è¿½åŠ 
        self.quality_history.append({
            'timestamp': time.time(),
            'metrics': metrics.to_dict(),
            'processing_time': processing_time
        })
        
        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.quality_history) > self.max_history_size:
            self.quality_history.pop(0)
        
        # å¹³å‡å“è³ªã‚¹ã‚³ã‚¢æ›´æ–°
        recent_scores = [h['metrics']['overall_score'] for h in self.quality_history[-20:]]
        self.stats['average_quality_score'] = sum(recent_scores) / len(recent_scores)
        
        # ã‚¨ãƒ©ãƒ¼é˜²æ­¢ç‡è¨ˆç®—
        recent_error_counts = [h['metrics']['error_count'] for h in self.quality_history[-20:]]
        avg_errors = sum(recent_error_counts) / len(recent_error_counts)
        self.stats['error_prevention_rate'] = max(0.0, 1.0 - avg_errors / 10.0)
    
    def get_quality_report(self) -> Dict[str, Any]:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.quality_history:
            return {"message": "å“è³ªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        recent_metrics = [h['metrics'] for h in self.quality_history[-10:]]
        
        # å¹³å‡å€¤è¨ˆç®—
        avg_grammar = sum(m['grammar_score'] for m in recent_metrics) / len(recent_metrics)
        avg_sense = sum(m['sense_score'] for m in recent_metrics) / len(recent_metrics)
        avg_diversity = sum(m['diversity_score'] for m in recent_metrics) / len(recent_metrics)
        avg_overall = sum(m['overall_score'] for m in recent_metrics) / len(recent_metrics)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        scores_trend = [m['overall_score'] for m in recent_metrics]
        trend_direction = "æ”¹å–„" if len(scores_trend) > 1 and scores_trend[-1] > scores_trend[0] else "å®‰å®š"
        
        return {
            'enabled': self.enabled,
            'error_threshold': self.error_threshold * 100,
            'diversity_target': self.diversity_target * 100,
            'statistics': self.stats,
            'recent_averages': {
                'grammar_score': avg_grammar,
                'sense_score': avg_sense,
                'diversity_score': avg_diversity,
                'overall_score': avg_overall
            },
            'quality_trend': trend_direction,
            'total_evaluations': len(self.quality_history),
            'recommendations': self._generate_recommendations(avg_diversity, avg_overall)
        }
    
    def _generate_recommendations(self, avg_diversity: float, avg_overall: float) -> List[str]:
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        recommendations = []
        
        if avg_diversity < self.diversity_target:
            recommendations.append(f"èªå½™å¤šæ§˜æ€§å‘ä¸Š: ç¾åœ¨{avg_diversity*100:.1f}% â†’ ç›®æ¨™{self.diversity_target*100:.1f}%")
        
        if avg_overall < 0.8:
            recommendations.append(f"å…¨ä½“å“è³ªå‘ä¸Š: ç¾åœ¨{avg_overall*100:.1f}% â†’ æ¨å¥¨80%ä»¥ä¸Š")
        
        if self.stats['corrections_applied'] > self.stats['total_checks'] * 0.1:
            recommendations.append("Î³å€¤ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šè¦‹ç›´ã—ã‚’æ¤œè¨")
        
        if not recommendations:
            recommendations.append("å“è³ªã¯è‰¯å¥½ã§ã™ã€‚ç¾åœ¨ã®è¨­å®šã‚’ç¶­æŒã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def reset_stats(self):
        """çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        self.stats = {
            'total_checks': 0,
            'corrections_applied': 0,
            'gamma_adjustments': 0,
            'average_quality_score': 0.0,
            'error_prevention_rate': 0.0
        }
        self.quality_history.clear()
        print("ğŸ”„ å“è³ªã‚¬ãƒ¼ãƒ‰çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_quality_guard():
    """å“è³ªã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    config = {
        'quality_guard_enabled': True,
        'auto_correction_threshold': 0.03,
        'diversity_target': 0.35,
        'gamma_adjustment_step': 0.01
    }
    
    guard = QualityGuard(config)
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚",  # æ­£å¸¸
        "ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ï¼ï¼ï¼ï¼ï¼ï¼",  # åå¾©éå¤š
        "ç§ã¯ã¯ã¯ã¯ã¯å¬‰ã—ã„ã„ã„ã„ã„ã§ã™ã€‚ã€‚ã€‚ã€‚",  # æ–‡æ³•ã‚¨ãƒ©ãƒ¼
        "Hello World 12345678901234567890",  # ç•°å¸¸èªå½™
    ]
    
    print("ğŸ§ª å“è³ªã‚¬ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    for i, text in enumerate(test_cases, 1):
        print(f"\n--- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ---")
        print(f"å…¥åŠ›: {text}")
        
        metrics = guard.evaluate_quality(text)
        print(f"å“è³ªã‚¹ã‚³ã‚¢: {metrics.overall_score:.2f}")
        print(f"æ–‡æ³•: {metrics.grammar_score:.2f}, å¸¸è­˜æ€§: {metrics.sense_score:.2f}")
        print(f"å¤šæ§˜æ€§: {metrics.diversity_score:.2f}, ã‚¨ãƒ©ãƒ¼æ•°: {metrics.error_count}")
        
        corrected, new_gamma, applied = guard.auto_correct_if_needed(text, 0.98)
        if applied:
            print(f"è£œæ­£é©ç”¨: {corrected}")
            print(f"Î³èª¿æ•´: 0.98 â†’ {new_gamma:.3f}")
        else:
            print("è£œæ­£ä¸è¦")
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = guard.get_quality_report()
    print(f"\nğŸ“Š æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_quality_guard() 