# -*- coding: utf-8 -*-
"""
CI é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆ v3.0
32K ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã§ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç›£è¦–ã¨OOMé˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ 
EasyNovelAssistantçµ±åˆç‰ˆ
"""

import os
import sys
import time
import psutil
import gc
import threading
import asyncio
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import json
import traceback

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False


@dataclass
class MemoryMetrics:
    """ãƒ¡ãƒ¢ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: float
    rss_mb: float  # ç‰©ç†ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)
    vms_mb: float  # ä»®æƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)
    percent: float  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (%)
    available_mb: float  # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª (MB)
    gpu_memory_mb: Optional[float] = None  # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)
    gpu_memory_reserved_mb: Optional[float] = None  # GPU äºˆç´„ãƒ¡ãƒ¢ãƒª (MB)


@dataclass
class EnduranceTestResult:
    """è€ä¹…ãƒ†ã‚¹ãƒˆçµæœ"""
    test_name: str
    target_tokens: int
    generated_tokens: int
    duration_seconds: float
    peak_memory_mb: float
    peak_gpu_memory_mb: Optional[float]
    memory_leak_detected: bool
    oom_events: int
    tokens_per_second: float
    success: bool
    error_message: Optional[str] = None


class MemoryMonitor:
    """ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, interval_seconds: float = 0.5):
        self.interval = interval_seconds
        self.is_monitoring = False
        self.metrics_history: List[MemoryMetrics] = []
        self.monitor_thread: Optional[threading.Thread] = None
        self.process = psutil.Process()
        
        # OOMé–¾å€¤è¨­å®šï¼ˆåˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®90%ï¼‰
        self.oom_threshold_mb = psutil.virtual_memory().available / (1024 * 1024) * 0.9
        self.oom_events = 0
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        self.metrics_history.clear()
        self.oom_events = 0
        
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        print(f"ğŸ” ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹ (OOMé–¾å€¤: {self.oom_threshold_mb:.1f} MB)")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        if not self.is_monitoring:
            return
        
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)
        
        print(f"ğŸ›‘ ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢ (è¨˜éŒ²æ•°: {len(self.metrics_history)})")
    
    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.is_monitoring:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
                memory_info = self.process.memory_info()
                system_memory = psutil.virtual_memory()
                
                # GPUãƒ¡ãƒ¢ãƒªï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                gpu_memory_mb = None
                gpu_reserved_mb = None
                
                if TORCH_AVAILABLE and torch.cuda.is_available():
                    try:
                        gpu_memory_mb = torch.cuda.memory_allocated() / (1024 * 1024)
                        gpu_reserved_mb = torch.cuda.memory_reserved() / (1024 * 1024)
                    except Exception:
                        pass
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                metrics = MemoryMetrics(
                    timestamp=time.time(),
                    rss_mb=memory_info.rss / (1024 * 1024),
                    vms_mb=memory_info.vms / (1024 * 1024),
                    percent=system_memory.percent,
                    available_mb=system_memory.available / (1024 * 1024),
                    gpu_memory_mb=gpu_memory_mb,
                    gpu_memory_reserved_mb=gpu_reserved_mb
                )
                
                self.metrics_history.append(metrics)
                
                # OOMæ¤œå‡º
                if metrics.available_mb < (self.oom_threshold_mb * 0.1):  # é–¾å€¤ã®10%ä»¥ä¸‹
                    self.oom_events += 1
                    print(f"âš ï¸ OOMè­¦å‘Š: åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª {metrics.available_mb:.1f} MB")
                    
                    # ç·Šæ€¥ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                    gc.collect()
                    if TORCH_AVAILABLE and torch.cuda.is_available():
                        torch.cuda.empty_cache()
                
                time.sleep(self.interval)
                
            except Exception as e:
                print(f"âŒ ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(1.0)
    
    def get_peak_memory(self) -> Tuple[float, Optional[float]]:
        """ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—"""
        if not self.metrics_history:
            return 0.0, None
        
        peak_rss = max(m.rss_mb for m in self.metrics_history)
        peak_gpu = None
        
        if any(m.gpu_memory_mb is not None for m in self.metrics_history):
            peak_gpu = max(m.gpu_memory_mb for m in self.metrics_history if m.gpu_memory_mb is not None)
        
        return peak_rss, peak_gpu
    
    def detect_memory_leak(self, window_minutes: int = 5) -> bool:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º"""
        if len(self.metrics_history) < 100:  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³
            return False
        
        # éå»Nåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§ç·šå½¢å›å¸°
        window_seconds = window_minutes * 60
        recent_metrics = [
            m for m in self.metrics_history 
            if (time.time() - m.timestamp) <= window_seconds
        ]
        
        if len(recent_metrics) < 20:
            return False
        
        # ç°¡æ˜“ç·šå½¢å›å¸°ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‚¾ãï¼‰
        timestamps = [m.timestamp for m in recent_metrics]
        memory_values = [m.rss_mb for m in recent_metrics]
        
        n = len(timestamps)
        sum_x = sum(timestamps)
        sum_y = sum(memory_values)
        sum_xy = sum(t * m for t, m in zip(timestamps, memory_values))
        sum_xx = sum(t * t for t in timestamps)
        
        # å‚¾ãè¨ˆç®—
        if n * sum_xx - sum_x * sum_x == 0:
            return False
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_xx - sum_x * sum_x)
        
        # å‚¾ããŒæ­£ã§ã‹ã¤ä¸€å®šå€¤ä»¥ä¸Šã®å ´åˆã€ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¨åˆ¤å®š
        leak_threshold = 1.0  # MB/åˆ†
        return slope > (leak_threshold / 60)  # MB/ç§’ã«æ›ç®—
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """è¦ç´„çµ±è¨ˆ"""
        if not self.metrics_history:
            return {}
        
        rss_values = [m.rss_mb for m in self.metrics_history]
        gpu_values = [m.gpu_memory_mb for m in self.metrics_history if m.gpu_memory_mb is not None]
        
        stats = {
            'duration_minutes': (self.metrics_history[-1].timestamp - self.metrics_history[0].timestamp) / 60,
            'peak_memory_mb': max(rss_values),
            'min_memory_mb': min(rss_values),
            'avg_memory_mb': sum(rss_values) / len(rss_values),
            'memory_samples': len(self.metrics_history),
            'oom_events': self.oom_events,
            'memory_leak_detected': self.detect_memory_leak()
        }
        
        if gpu_values:
            stats.update({
                'peak_gpu_memory_mb': max(gpu_values),
                'avg_gpu_memory_mb': sum(gpu_values) / len(gpu_values)
            })
        
        return stats


class LongTextEnduranceTester:
    """é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.memory_monitor = MemoryMonitor()
        self.test_results: List[EnduranceTestResult] = []
    
    async def run_endurance_test(self, 
                                target_tokens: int = 32000,
                                test_name: str = "32K_endurance",
                                timeout_minutes: int = 30) -> EnduranceTestResult:
        """è€ä¹…ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        
        print(f"ğŸƒ é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆé–‹å§‹: {test_name}")
        print(f"   ç›®æ¨™ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {target_tokens:,}")
        print(f"   ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout_minutes}åˆ†")
        
        start_time = time.time()
        self.memory_monitor.start_monitoring()
        
        try:
            # ãƒ€ãƒŸãƒ¼ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆå®Ÿéš›ã®LLMã¨ç½®ãæ›ãˆï¼‰
            generated_tokens = await self._simulate_long_text_generation(
                target_tokens, timeout_minutes * 60
            )
            
            duration = time.time() - start_time
            peak_memory, peak_gpu = self.memory_monitor.get_peak_memory()
            
            # çµæœã®ä½œæˆ
            result = EnduranceTestResult(
                test_name=test_name,
                target_tokens=target_tokens,
                generated_tokens=generated_tokens,
                duration_seconds=duration,
                peak_memory_mb=peak_memory,
                peak_gpu_memory_mb=peak_gpu,
                memory_leak_detected=self.memory_monitor.detect_memory_leak(),
                oom_events=self.memory_monitor.oom_events,
                tokens_per_second=generated_tokens / duration if duration > 0 else 0,
                success=generated_tokens >= target_tokens * 0.9  # 90%ä»¥ä¸Šã§æˆåŠŸ
            )
            
            self.test_results.append(result)
            
            print(f"âœ… è€ä¹…ãƒ†ã‚¹ãƒˆå®Œäº†: {test_name}")
            print(f"   ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³: {generated_tokens:,} / {target_tokens:,}")
            print(f"   æ‰€è¦æ™‚é–“: {duration:.1f}ç§’")
            print(f"   å‡¦ç†é€Ÿåº¦: {result.tokens_per_second:.1f} tokens/sec")
            print(f"   ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {peak_memory:.1f} MB")
            if peak_gpu:
                print(f"   ãƒ”ãƒ¼ã‚¯GPUãƒ¡ãƒ¢ãƒª: {peak_gpu:.1f} MB")
            print(f"   ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯: {'æ¤œå‡º' if result.memory_leak_detected else 'æœªæ¤œå‡º'}")
            print(f"   OOMã‚¤ãƒ™ãƒ³ãƒˆ: {result.oom_events}å›")
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            peak_memory, peak_gpu = self.memory_monitor.get_peak_memory()
            
            result = EnduranceTestResult(
                test_name=test_name,
                target_tokens=target_tokens,
                generated_tokens=0,
                duration_seconds=duration,
                peak_memory_mb=peak_memory,
                peak_gpu_memory_mb=peak_gpu,
                memory_leak_detected=self.memory_monitor.detect_memory_leak(),
                oom_events=self.memory_monitor.oom_events,
                tokens_per_second=0,
                success=False,
                error_message=str(e)
            )
            
            self.test_results.append(result)
            
            print(f"âŒ è€ä¹…ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_name}")
            print(f"   ã‚¨ãƒ©ãƒ¼: {e}")
            
            return result
            
        finally:
            self.memory_monitor.stop_monitoring()
    
    async def _simulate_long_text_generation(self, target_tokens: int, timeout_seconds: int) -> int:
        """é•·æ–‡ç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        
        # æ®µéšçš„ç”Ÿæˆï¼ˆå®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        generated_tokens = 0
        start_time = time.time()
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆä¸€åº¦ã«ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰
        chunk_size = min(512, target_tokens // 10)
        
        while generated_tokens < target_tokens:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
            if time.time() - start_time > timeout_seconds:
                print(f"â±ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {generated_tokens} tokens ç”Ÿæˆæ¸ˆã¿")
                break
            
            # ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            await self._generate_chunk(chunk_size)
            generated_tokens += chunk_size
            
            # é€²æ—è¡¨ç¤º
            if generated_tokens % (chunk_size * 10) == 0:
                progress = generated_tokens / target_tokens * 100
                elapsed = time.time() - start_time
                tokens_per_sec = generated_tokens / elapsed
                
                print(f"ğŸ“Š é€²æ—: {generated_tokens:,}/{target_tokens:,} tokens "
                      f"({progress:.1f}%) - {tokens_per_sec:.1f} tok/s")
                
                # å®šæœŸçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                gc.collect()
                if TORCH_AVAILABLE and torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        return generated_tokens
    
    async def _generate_chunk(self, chunk_size: int):
        """ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ„å›³çš„ã«å¢—ã‚„ã™ï¼‰"""
        
        # CPUé›†ç´„çš„ãªå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await asyncio.sleep(0.01)  # I/Oå¾…æ©Ÿã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å¢—ã‚„ã™ï¼ˆå¤§ããªãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¦å‰Šé™¤ï¼‰
        if NUMPY_AVAILABLE:
            # NumPyé…åˆ—ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨
            dummy_data = np.random.random((chunk_size, 100))
            _ = dummy_data.mean()  # ä½•ã‚‰ã‹ã®è¨ˆç®—
            del dummy_data
        else:
            # Pythonãƒªã‚¹ãƒˆã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨
            dummy_data = [[i] * 100 for i in range(chunk_size)]
            _ = len(dummy_data)
            del dummy_data
        
        # GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if TORCH_AVAILABLE and torch.cuda.is_available():
            try:
                device = torch.device('cuda')
                tensor = torch.randn(chunk_size, 100, device=device)
                _ = tensor.sum()
                del tensor
            except Exception:
                pass  # GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ãªã©ã¯ç„¡è¦–
    
    def save_results(self, output_file: str):
        """çµæœä¿å­˜"""
        
        summary_data = {
            'test_summary': {
                'total_tests': len(self.test_results),
                'successful_tests': sum(1 for r in self.test_results if r.success),
                'failed_tests': sum(1 for r in self.test_results if not r.success),
                'total_tokens_generated': sum(r.generated_tokens for r in self.test_results),
                'average_tokens_per_second': sum(r.tokens_per_second for r in self.test_results) / max(1, len(self.test_results)),
                'memory_leak_detected': any(r.memory_leak_detected for r in self.test_results),
                'total_oom_events': sum(r.oom_events for r in self.test_results)
            },
            'test_results': [
                {
                    'test_name': r.test_name,
                    'target_tokens': r.target_tokens,
                    'generated_tokens': r.generated_tokens,
                    'duration_seconds': r.duration_seconds,
                    'peak_memory_mb': r.peak_memory_mb,
                    'peak_gpu_memory_mb': r.peak_gpu_memory_mb,
                    'memory_leak_detected': r.memory_leak_detected,
                    'oom_events': r.oom_events,
                    'tokens_per_second': r.tokens_per_second,
                    'success': r.success,
                    'error_message': r.error_message
                }
                for r in self.test_results
            ],
            'memory_monitoring': self.memory_monitor.get_summary_stats()
        }
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ çµæœä¿å­˜: {output_file}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ§ª CI é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆ v3.0")
    print("   32K ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã§ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç›£è¦–ã¨OOMé˜²æ­¢")
    print("=" * 60)
    
    tester = LongTextEnduranceTester()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
    test_cases = [
        (8000, "8K_warmup", 5),
        (16000, "16K_medium", 10),
        (32000, "32K_target", 15),
        (32000, "32K_repeat", 15)  # å†ç¾æ€§ç¢ºèª
    ]
    
    try:
        for target_tokens, test_name, timeout_minutes in test_cases:
            await tester.run_endurance_test(
                target_tokens=target_tokens,
                test_name=test_name,
                timeout_minutes=timeout_minutes
            )
            
            # ãƒ†ã‚¹ãƒˆé–“ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
            print(f"ğŸ˜´ ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ (5ç§’)...")
            await asyncio.sleep(5)
            
            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            gc.collect()
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # çµæœä¿å­˜
        output_file = f"./logs/ci_endurance_test_{int(time.time())}.json"
        tester.save_results(output_file)
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ“‹ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ:")
        print(f"   å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {len(tester.test_results)}")
        successful = sum(1 for r in tester.test_results if r.success)
        print(f"   æˆåŠŸ: {successful} / {len(tester.test_results)}")
        
        total_tokens = sum(r.generated_tokens for r in tester.test_results)
        print(f"   ç·ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³: {total_tokens:,}")
        
        avg_speed = sum(r.tokens_per_second for r in tester.test_results) / len(tester.test_results)
        print(f"   å¹³å‡å‡¦ç†é€Ÿåº¦: {avg_speed:.1f} tokens/sec")
        
        memory_leaks = sum(1 for r in tester.test_results if r.memory_leak_detected)
        print(f"   ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º: {memory_leaks} / {len(tester.test_results)}")
        
        total_oom = sum(r.oom_events for r in tester.test_results)
        print(f"   OOMã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: {total_oom}")
        
        # åˆæ ¼åˆ¤å®š
        if successful == len(tester.test_results) and total_oom == 0:
            print("\nğŸ‰ CI é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆ åˆæ ¼ï¼")
            print("   âœ… å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            print("   âœ… OOMã‚¤ãƒ™ãƒ³ãƒˆ 0ä»¶")
            print("   âœ… 32K ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ å®‰å®šå‹•ä½œç¢ºèª")
            return 0
        else:
            print("\nğŸ“ˆ CI é•·æ–‡è€ä¹…ãƒ†ã‚¹ãƒˆ æ”¹å–„å¿…è¦")
            if successful < len(tester.test_results):
                print(f"   âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {len(tester.test_results) - successful}ä»¶")
            if total_oom > 0:
                print(f"   âš ï¸ OOMã‚¤ãƒ™ãƒ³ãƒˆ: {total_oom}ä»¶")
            return 1
    
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 