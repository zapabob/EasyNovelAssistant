# -*- coding: utf-8 -*-
"""
Enhanced NKAT Expression Engine
è¡¨ç¾ç©ºé–“æ‹¡å¤§ã«ç‰¹åŒ–ã—ãŸNKATæ‹¡å¼µã‚¨ãƒ³ã‚¸ãƒ³
èªå½™å¤šæ§˜æ€§ã€æ–‡ä½“å¤‰åŒ–ã€æ„Ÿæƒ…è¡¨ç¾ã®è±Šã‹ã•ã‚’å¤§å¹…ã«å‘ä¸Š
"""

import re
import time
import random
import json
import numpy as np
from typing import Dict, List, Tuple, Set, Optional
from collections import defaultdict, deque
from dataclasses import dataclass
import os
import hashlib


@dataclass
class ExpressionVariant:
    """è¡¨ç¾ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³"""
    original: str
    variants: List[str]
    context_type: str  # 'emotional', 'formal', 'casual', 'descriptive'
    usage_count: int = 0


class ExpressionExpansionEngine:
    """
    è¡¨ç¾æ‹¡å¼µã‚¨ãƒ³ã‚¸ãƒ³
    å˜èª¿ãªè¡¨ç¾ã‚’å¤šæ§˜ã§è±Šã‹ãªè¡¨ç¾ã«å¤‰æ›
    """
    
    def __init__(self):
        self.expression_database = {}
        self.context_patterns = {}
        self.character_styles = {}
        self.expansion_history = deque(maxlen=1000)
        
        # è¡¨ç¾æ‹¡å¼µè¾æ›¸ã‚’åˆæœŸåŒ–
        self._initialize_expression_database()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "expressions_expanded": 0,
            "vocabulary_additions": 0,
            "style_variations": 0,
            "emotional_enhancements": 0,
            "pattern_diversifications": 0
        }
        
        print("ğŸŒŸ Enhanced NKAT Expression Engine initialized")
    
    def _initialize_expression_database(self):
        """è¡¨ç¾æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        
        # æ„Ÿæƒ…è¡¨ç¾ã®æ‹¡å¼µ
        self.expression_database["emotional"] = {
            # å–œã³ç³»
            "å¬‰ã—ã„": ["æ­“å–œã«æº€ã¡ãŸ", "å¿ƒèºã‚‹", "å¹¸ç¦æ„Ÿã«åŒ…ã¾ã‚ŒãŸ", "å–œã³ã«éœ‡ãˆã‚‹", "æ„Ÿæ¿€ã—ãŸ", "èƒ¸ãŒèºã‚‹", "æ™´ã‚Œã‚„ã‹ãª"],
            "å¬‰ã—ã„ã§ã™": ["å¿ƒã‹ã‚‰å–œã‚“ã§ã„ã¾ã™", "æœ¬å½“ã«å¹¸ã›ã§ã™", "æ„Ÿè¬ã®æ°—æŒã¡ã§ã„ã£ã±ã„ã§ã™", "èƒ¸ãŒç†±ããªã‚Šã¾ã™", "æ¶™ãŒå‡ºãã†ã§ã™"],
            "ã¨ã¦ã‚‚å¬‰ã—ã„": ["è¨€è‘‰ã«ã§ããªã„ã»ã©å¬‰ã—ã„", "å¤¢ã®ã‚ˆã†ã«å¬‰ã—ã„", "ç©ºã«èˆã„ä¸ŠãŒã‚Šãã†ãªã»ã©å¬‰ã—ã„", "å¿ƒãŒå¼¾ã‚€", "èƒ¸ãŒã„ã£ã±ã„ã«ãªã‚‹"],
            
            # é©šãç³»
            "ã‚ã‚": ["ãªã‚“ã¨ã„ã†ã“ã¨ã§ã—ã‚‡ã†", "ä¿¡ã˜ã‚‰ã‚Œãªã„", "ã¾ã•ã‹", "ã“ã‚Œã¯é©šã„ãŸ", "ç›®ã‚’ç–‘ã†"],
            "ã™ã”ã„": ["åœ§å€’çš„", "é©šç•°çš„", "æ¯ã‚’å‘‘ã‚€", "è¨€è‘‰ã‚’å¤±ã†", "æƒ³åƒã‚’è¶…ãˆã‚‹", "å£®è¦³ãª", "çœ©ã—ã„"],
            "ãã‚Œã„": ["ç¾ã—ã„", "è¯éº—ãª", "å„ªé›…ãª", "æ´—ç·´ã•ã‚ŒãŸ", "æ°—å“ã‚ã‚‹", "ä¸Šå“ãª", "ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆãª"],
            
            # èˆˆå¥®ç³»
            "ã‚ã‚ã‚ã‚ã‚": ["èƒ¸ãŒé«˜é³´ã‚‹", "å¿ƒè‡“ãŒè·³ã­ä¸ŠãŒã‚‹", "è¡€ãŒãŸãã‚‹", "å…¨èº«ãŒéœ‡ãˆã‚‹", "æ¯ãŒè’ããªã‚‹"],
            "ã†ã‚ã‚ã‚ã‚ã‚": ["åœ§å€’ã•ã‚Œã‚‹", "è¡æ’ƒãŒèµ°ã‚‹", "é›·ã«æ‰“ãŸã‚ŒãŸã‚ˆã†", "ç¨²å¦»ãŒèµ°ã‚‹", "å…¨ã¦ãŒå¤‰ã‚ã‚‹ç¬é–“"],
            
            # å›°æƒ‘ç³»
            "é›£ã—ã„": ["è¤‡é›‘ã§æ‚©ã¾ã—ã„", "é ­ã‚’æŠ±ãˆã‚‹", "æ€è€ƒãŒæ··ä¹±ã™ã‚‹", "ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„", "è¿·å®®å…¥ã‚Šã—ãã†ãª"]
        }
        
        # æ–‡ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ‹¡å¼µ
        self.expression_database["style"] = {
            "ã§ã™": ["ã§ã™ã­", "ã§ã”ã–ã„ã¾ã™", "ãªã®ã§ã™", "ã§ã™ã‹ã‚‰", "ã§ã™ãŒ"],
            "ã¾ã™": ["ã¾ã™ã­", "ã¾ã™ã‚ˆ", "ã¾ã™ã‹ã‚‰", "ã¾ã™ãŒ", "ã¾ã™ã—"],
            "ã ": ["ã ã­", "ã ã‚ˆ", "ã ã‹ã‚‰", "ã ã—", "ã ã‘ã©"],
            "ã§ã‚ã‚‹": ["ã§ã‚ã‚‹ã­", "ã§ã‚ã‚‹ã‹ã‚‰", "ã§ã‚ã‚‹ãŒ", "ã§ã‚ã‚‹ã—", "ã§ã‚ã£ãŸ"]
        }
        
        # æ¥ç¶šè©ãƒ»å‰¯è©ã®æ‹¡å¼µ
        self.expression_database["connective"] = {
            "ãã†ã§ã™ã­": ["ãã†ã§ã™ã­ã€ç¢ºã‹ã«", "ãªã‚‹ã»ã©", "ãŠã£ã—ã‚ƒã‚‹é€šã‚Šã§ã™", "ãã®é€šã‚Šã§ã™", "ã„ã‹ã«ã‚‚"],
            "ã§ã‚‚": ["ã—ã‹ã—", "ã‘ã‚Œã©", "ãŸã ", "ãã‚Œã§ã‚‚", "ã¨ã¯ã„ãˆ", "ä¸€æ–¹ã§"],
            "ã ã‹ã‚‰": ["ãã‚Œã§", "ãªã®ã§", "å¾“ã£ã¦", "ã‚†ãˆã«", "ã¨ã„ã†ã‚ã‘ã§", "ãã†ã„ã†ã‚ã‘ã§"],
            "ã‚„ã£ã±ã‚Š": ["ã‚„ã¯ã‚Š", "çµå±€", "ã¤ã¾ã‚‹ã¨ã“ã‚", "æ¡ˆã®å®š", "äºˆæƒ³é€šã‚Š", "æ€ã£ãŸé€šã‚Š"]
        }
        
        # æ„Ÿå˜†è©ã®å¤šæ§˜åŒ–
        self.expression_database["interjection"] = {
            "ï¼": ["ï¼", "â€¦ï¼", "ã£ï¼", "ï¼ï¼Ÿ"],
            "ï¼Ÿ": ["ï¼Ÿ", "â€¦ï¼Ÿ", "ã£ï¼Ÿ", "ï¼ï¼Ÿ"],
            "â€¦": ["â€¦", "ã€œ", "â€¦â€¦", "â€¦ã£"],
            "ã€œ": ["ã€œ", "â€¦", "ãƒ¼", "ï½ï½"]
        }
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ã®ç‰¹å¾´çš„è¡¨ç¾
        self.character_expressions = {
            "æ¨¹é‡Œ": {
                "èˆˆå¥®": ["èƒ¸ãŒå¼µã‚Šè£‚ã‘ãã†", "å¿ƒè‡“ãŒçˆ†ç™ºã—ãã†", "å…¨èº«ãŒç«ç…§ã‚‹", "æ„è­˜ãŒé£›ã³ãã†"],
                "å–œã³": ["å¤©ã«ã‚‚æ˜‡ã‚‹å¿ƒåœ°", "å¤¢å¿ƒåœ°", "ã“ã®ä¸Šãªã„å¹¸ç¦", "è‡³ç¦ã®ç¬é–“"],
                "é©šã": ["ç›®ã‚’è¦‹å¼µã‚‹", "è¨€è‘‰ã‚’å¤±ã†", "æ¯ã‚’å‘‘ã‚€", "å¿ƒè‡“ãŒæ­¢ã¾ã‚Šãã†"]
            },
            "ç¾é‡Œ": {
                "å–œã³": ["å¿ƒãŒèºã‚‹", "ç¬‘é¡”ãŒã“ã¼ã‚Œã‚‹", "å¹¸ã›ã„ã£ã±ã„", "æ°—åˆ†æœ€é«˜"],
                "é©šã": ["ã³ã£ãã‚Š", "ã¾ã•ã‹", "ä¿¡ã˜ã‚‰ã‚Œãªã„", "ã©ã†ã—ã‚ˆã†"],
                "å›°æƒ‘": ["ã©ã†ã—ãŸã‚‰ã„ã„ã®", "åˆ†ã‹ã‚‰ãªã„", "è¿·ã£ã¡ã‚ƒã†", "å›°ã£ãŸãª"]
            }
        }
    
    def expand_expression(self, text: str, character: str = "general", context: str = "") -> str:
        """
        è¡¨ç¾ã®æ‹¡å¼µå‡¦ç†
        
        Args:
            text: æ‹¡å¼µå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            character: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            æ‹¡å¼µã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        
        if not text or len(text.strip()) == 0:
            return text
        
        print(f"ğŸ” è¡¨ç¾æ‹¡å¼µé–‹å§‹: {text[:50]}...")
        
        expanded_text = text
        expansion_applied = False
        
        # 1. åå¾©ã®å˜èª¿æ€§ã‚’è§£æ±º
        expanded_text, repetition_fixed = self._diversify_repetitions(expanded_text)
        if repetition_fixed:
            expansion_applied = True
            self.stats["pattern_diversifications"] += 1
        
        # 2. æ„Ÿæƒ…è¡¨ç¾ã®è±Šã‹ã•ã‚’å‘ä¸Š
        expanded_text, emotion_enhanced = self._enhance_emotional_expressions(expanded_text, character)
        if emotion_enhanced:
            expansion_applied = True
            self.stats["emotional_enhancements"] += 1
        
        # 3. èªå½™ã®å¤šæ§˜æ€§ã‚’å‘ä¸Š
        expanded_text, vocab_expanded = self._expand_vocabulary(expanded_text)
        if vocab_expanded:
            expansion_applied = True
            self.stats["vocabulary_additions"] += 1
        
        # 4. æ–‡ä½“ã®å¤‰åŒ–ã‚’è¿½åŠ 
        expanded_text, style_varied = self._vary_sentence_styles(expanded_text)
        if style_varied:
            expansion_applied = True
            self.stats["style_variations"] += 1
        
        # 5. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å›ºæœ‰ã®è¡¨ç¾ã‚’è¿½åŠ 
        expanded_text = self._add_character_specific_expressions(expanded_text, character)
        
        # æ‹¡å¼µå±¥æ­´ã«è¨˜éŒ²
        if expansion_applied:
            self.expansion_history.append({
                "original": text,
                "expanded": expanded_text,
                "character": character,
                "timestamp": time.time(),
                "improvements": {
                    "repetition_fixed": repetition_fixed,
                    "emotion_enhanced": emotion_enhanced,
                    "vocab_expanded": vocab_expanded,
                    "style_varied": style_varied
                }
            })
            self.stats["expressions_expanded"] += 1
        
        print(f"âœ¨ è¡¨ç¾æ‹¡å¼µå®Œäº†: {expanded_text[:50]}... ({'å¤‰æ›´ã‚ã‚Š' if expansion_applied else 'å¤‰æ›´ãªã—'})")
        
        return expanded_text
    
    def _diversify_repetitions(self, text: str) -> Tuple[str, bool]:
        """åå¾©ã®å¤šæ§˜åŒ–"""
        
        changed = False
        result = text
        
        # å®Œå…¨ä¸€è‡´ã™ã‚‹èªå¥ã®åå¾©ã‚’æ¤œå‡ºãƒ»å¤šæ§˜åŒ–
        words = re.findall(r'[ã-ã‚–ã‚¡-ãƒºãƒ¼ä¸€-é¾¯]+', text)
        word_positions = {}
        
        for i, word in enumerate(words):
            if len(word) >= 2:
                if word not in word_positions:
                    word_positions[word] = []
                word_positions[word].append(i)
        
        # 2å›ä»¥ä¸Šå‡ºç¾ã™ã‚‹èªå¥ã‚’å¤šæ§˜åŒ–
        for word, positions in word_positions.items():
            if len(positions) >= 2 and word in self.expression_database["emotional"]:
                variants = self.expression_database["emotional"][word]
                
                # åå¾©ç®‡æ‰€ã«ç•°ãªã‚‹è¡¨ç¾ã‚’é©ç”¨
                for i, pos in enumerate(positions[1:], 1):  # æœ€åˆã¯ä¿æŒ
                    if i < len(variants):
                        replacement = variants[i-1]
                        # å˜èªå¢ƒç•Œã‚’è€ƒæ…®ã—ãŸç½®æ›
                        pattern = r'\b' + re.escape(word) + r'\b'
                        result = re.sub(pattern, replacement, result, count=1)
                        changed = True
        
        # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®åå¾©ã‚‚å¤šæ§˜åŒ–
        for char in ['ã‚', 'ã†', 'ãŠ', 'ã‚', 'ã‚“']:
            pattern = f'{char}{{4,}}'  # 4æ–‡å­—ä»¥ä¸Šã®é€£ç¶š
            matches = re.findall(pattern, result)
            for match in matches:
                if len(match) > 3:
                    # æ®µéšçš„ãªæ„Ÿæƒ…è¡¨ç¾ã«å¤‰æ›
                    variations = [
                        f"{char}{char}â€¦",
                        f"{char}ã£â€¦",
                        f"{char}ã‚â€¦",
                        f"{char}ãƒ¼â€¦"
                    ]
                    replacement = random.choice(variations)
                    result = result.replace(match, replacement, 1)
                    changed = True
        
        return result, changed
    
    def _enhance_emotional_expressions(self, text: str, character: str) -> Tuple[str, bool]:
        """æ„Ÿæƒ…è¡¨ç¾ã®å¼·åŒ–"""
        
        changed = False
        result = text
        
        # æ„Ÿæƒ…è¡¨ç¾ã®æ¤œå‡ºã¨å¼·åŒ–
        emotional_patterns = [
            (r'(å¬‰ã—ã„)(?![\w])', self.expression_database["emotional"].get("å¬‰ã—ã„", [])),
            (r'(ã™ã”ã„)(?![\w])', self.expression_database["emotional"].get("ã™ã”ã„", [])),
            (r'(ãã‚Œã„)(?![\w])', self.expression_database["emotional"].get("ãã‚Œã„", [])),
            (r'(ã‚ã‚)(?![\w])', self.expression_database["emotional"].get("ã‚ã‚", [])),
        ]
        
        for pattern, replacements in emotional_patterns:
            if replacements and re.search(pattern, result):
                replacement = random.choice(replacements)
                result = re.sub(pattern, replacement, result, count=1)
                changed = True
        
        # æ„Ÿå˜†ç¬¦ã®å¤šæ§˜åŒ–
        if "ï¼ï¼ï¼" in result:
            variations = ["ï¼", "â€¦ï¼", "ï¼ï¼Ÿ", "ã£ï¼"]
            result = result.replace("ï¼ï¼ï¼", random.choice(variations))
            changed = True
        
        # çœç•¥è¨˜å·ã®å¤šæ§˜åŒ–
        if "â€¦â€¦" in result:
            variations = ["â€¦", "ã€œ", "ãƒ¼", "â€¦â€¦ã£"]
            result = result.replace("â€¦â€¦", random.choice(variations))
            changed = True
        
        return result, changed
    
    def _expand_vocabulary(self, text: str) -> Tuple[str, bool]:
        """èªå½™ã®æ‹¡å¼µ"""
        
        changed = False
        result = text
        
        # æ¥ç¶šè©ãƒ»å‰¯è©ã®å¤šæ§˜åŒ–
        for original, variants in self.expression_database["connective"].items():
            if original in result:
                replacement = random.choice(variants)
                result = result.replace(original, replacement, 1)
                changed = True
        
        # èªå°¾ã®å¤šæ§˜åŒ–
        patterns = [
            (r'ã§ã™ã€‚', ["ã§ã™ã­ã€‚", "ã§ã™ã‚ˆã€‚", "ã§ã”ã–ã„ã¾ã™ã€‚"]),
            (r'ã¾ã™ã€‚', ["ã¾ã™ã­ã€‚", "ã¾ã™ã‚ˆã€‚", "ã¾ã™ã‹ã‚‰ã€‚"]),
            (r'ã ã€‚', ["ã ã­ã€‚", "ã ã‚ˆã€‚", "ã ã—ã€‚"])
        ]
        
        for pattern, replacements in patterns:
            if re.search(pattern, result):
                replacement = random.choice(replacements)
                result = re.sub(pattern, replacement, result, count=1)
                changed = True
        
        return result, changed
    
    def _vary_sentence_styles(self, text: str) -> Tuple[str, bool]:
        """æ–‡ä½“ã®å¤‰åŒ–"""
        
        changed = False
        result = text
        
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', result)
        if len(sentences) > 3:  # è¤‡æ•°æ–‡ãŒã‚ã‚‹å ´åˆ
            
            # æ–‡é•·ã®å¤‰åŒ–ã‚’è¿½åŠ 
            for i in range(0, len(sentences)-1, 2):  # æ–‡ã®ã¿å¯¾è±¡
                sentence = sentences[i].strip()
                if len(sentence) > 0:
                    
                    # çŸ­ã„æ–‡ã«æ„Ÿæƒ…çš„ãªä¿®é£¾ã‚’è¿½åŠ 
                    if len(sentence) < 10:
                        emotional_modifiers = ["æœ¬å½“ã«", "ã¨ã¦ã‚‚", "ã™ã”ã", "å¿ƒã‹ã‚‰"]
                        if not any(mod in sentence for mod in emotional_modifiers):
                            modifier = random.choice(emotional_modifiers)
                            sentences[i] = f"{modifier}{sentence}"
                            changed = True
                    
                    # é•·ã„æ–‡ã‚’åˆ†å‰²
                    elif len(sentence) > 30 and "ã€" in sentence:
                        parts = sentence.split("ã€", 1)
                        if len(parts) == 2:
                            sentences[i] = f"{parts[0]}ã€‚{parts[1]}"
                            changed = True
            
            result = "".join(sentences)
        
        return result, changed
    
    def _add_character_specific_expressions(self, text: str, character: str) -> str:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å›ºæœ‰è¡¨ç¾ã®è¿½åŠ """
        
        if character not in self.character_expressions:
            return text
        
        char_expressions = self.character_expressions[character]
        result = text
        
        # æ„Ÿæƒ…çŠ¶æ…‹ã«å¿œã˜ãŸè¡¨ç¾ã‚’è¿½åŠ 
        if "ã‚ã‚ã‚ã‚ã‚" in text or "ã†ã‚ã‚ã‚ã‚ã‚" in text:
            # èˆˆå¥®çŠ¶æ…‹
            if "èˆˆå¥®" in char_expressions:
                additional = random.choice(char_expressions["èˆˆå¥®"])
                result = f"{result} {additional}â€¦ï¼"
        
        elif "å¬‰ã—ã„" in text:
            # å–œã³ã®çŠ¶æ…‹
            if "å–œã³" in char_expressions:
                additional = random.choice(char_expressions["å–œã³"])
                result = result.replace("å¬‰ã—ã„", f"{additional}ã§å¬‰ã—ã„")
        
        elif "ã‚ã‚" in text or "ã™ã”ã„" in text:
            # é©šãã®çŠ¶æ…‹
            if "é©šã" in char_expressions:
                additional = random.choice(char_expressions["é©šã"])
                result = f"{result} {additional}â€¦ï¼"
        
        return result
    
    def get_expansion_stats(self) -> Dict:
        """æ‹¡å¼µçµ±è¨ˆã®å–å¾—"""
        
        recent_expansions = list(self.expansion_history)[-10:]
        
        return {
            "total_expansions": self.stats["expressions_expanded"],
            "vocabulary_additions": self.stats["vocabulary_additions"],
            "style_variations": self.stats["style_variations"],
            "emotional_enhancements": self.stats["emotional_enhancements"],
            "pattern_diversifications": self.stats["pattern_diversifications"],
            "recent_expansions": len(recent_expansions),
            "database_size": {
                "emotional": len(self.expression_database["emotional"]),
                "style": len(self.expression_database["style"]),
                "connective": len(self.expression_database["connective"])
            }
        }
    
    def analyze_expression_diversity(self, text: str) -> Dict:
        """è¡¨ç¾å¤šæ§˜æ€§ã®åˆ†æ"""
        
        # èªå½™å¤šæ§˜æ€§
        words = re.findall(r'[ã-ã‚–ã‚¡-ãƒºãƒ¼ä¸€-é¾¯]+', text)
        unique_words = set(words)
        vocab_diversity = len(unique_words) / max(len(words), 1)
        
        # æ–‡ä½“å¤šæ§˜æ€§
        sentences = text.split("ã€‚")
        sentence_patterns = []
        for sentence in sentences:
            if "ã§ã™" in sentence:
                sentence_patterns.append("polite")
            elif "ã " in sentence:
                sentence_patterns.append("casual")
            elif "ã§ã‚ã‚‹" in sentence:
                sentence_patterns.append("formal")
            else:
                sentence_patterns.append("neutral")
        
        pattern_diversity = len(set(sentence_patterns)) / max(len(sentence_patterns), 1)
        
        # æ„Ÿæƒ…è¡¨ç¾å¤šæ§˜æ€§
        emotional_chars = text.count("ï¼") + text.count("ï¼Ÿ") + text.count("â€¦")
        emotion_density = emotional_chars / max(len(text), 1)
        
        return {
            "vocabulary_diversity": vocab_diversity,
            "pattern_diversity": pattern_diversity,
            "emotion_density": emotion_density,
            "total_words": len(words),
            "unique_words": len(unique_words),
            "sentence_count": len([s for s in sentences if s.strip()])
        }


def test_expression_expansion():
    """è¡¨ç¾æ‹¡å¼µã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    
    engine = ExpressionExpansionEngine()
    
    test_cases = [
        {
            "name": "æ„Ÿæƒ…è¡¨ç¾ã®é™å®šæ€§",
            "text": "å¬‰ã—ã„ã§ã™ã€‚ã¨ã¦ã‚‚å¬‰ã—ã„ã§ã™ã€‚æœ¬å½“ã«å¬‰ã—ã„ã§ã™ã€‚å¬‰ã—ã„æ°—æŒã¡ã§ã™ã€‚",
            "character": "æ¨¹é‡Œ"
        },
        {
            "name": "åå¾©è¡¨ç¾ã®å˜èª¿æ€§",
            "text": "ã‚ã‚ã‚ã‚ã‚â€¦ï¼ ã‚ã‚ã‚ã‚ã‚â€¦ï¼ ã†ã‚ã‚ã‚ã‚ã‚â€¦ï¼ ã‚ã‚ã‚ã‚ã‚â€¦ï¼",
            "character": "æ¨¹é‡Œ"
        },
        {
            "name": "èªå½™ã®é™å®šæ€§",
            "text": "ãã†ã§ã™ã­ã€‚ãã†ã§ã™ã­ã€‚ã§ã‚‚é›£ã—ã„ã§ã™ã­ã€‚ã‚„ã£ã±ã‚Šé›£ã—ã„ã§ã™ã­ã€‚",
            "character": "ç¾é‡Œ"
        },
        {
            "name": "æ„Ÿå˜†è¡¨ç¾ã®è²§å›°æ€§",
            "text": "ã‚ã‚ï¼ã‚ã‚ï¼ã™ã”ã„ï¼ã‚ã‚ï¼ãã‚Œã„ï¼ã‚ã‚ï¼",
            "character": "ç¾é‡Œ"
        }
    ]
    
    print("ğŸš€ Enhanced NKAT Expression Engine Test")
    print("=" * 60)
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“ Test Case {i}: {case['name']}")
        print(f"Character: {case['character']}")
        print(f"Original: {case['text']}")
        
        # æ‹¡å¼µå‰ã®åˆ†æ
        before_analysis = engine.analyze_expression_diversity(case['text'])
        
        # è¡¨ç¾æ‹¡å¼µå®Ÿè¡Œ
        expanded = engine.expand_expression(case['text'], case['character'])
        
        # æ‹¡å¼µå¾Œã®åˆ†æ
        after_analysis = engine.analyze_expression_diversity(expanded)
        
        print(f"Expanded: {expanded}")
        print(f"\nğŸ“Š Diversity Analysis:")
        print(f"  Vocabulary: {before_analysis['vocabulary_diversity']:.3f} â†’ {after_analysis['vocabulary_diversity']:.3f}")
        print(f"  Patterns: {before_analysis['pattern_diversity']:.3f} â†’ {after_analysis['pattern_diversity']:.3f}")
        print(f"  Emotion: {before_analysis['emotion_density']:.3f} â†’ {after_analysis['emotion_density']:.3f}")
        print(f"  Words: {before_analysis['unique_words']} â†’ {after_analysis['unique_words']}")
        
        print("-" * 50)
    
    # çµ±è¨ˆè¡¨ç¤º
    stats = engine.get_expansion_stats()
    print(f"\nğŸ“ˆ Expansion Statistics:")
    print(f"Total Expansions: {stats['total_expansions']}")
    print(f"Vocabulary Additions: {stats['vocabulary_additions']}")
    print(f"Style Variations: {stats['style_variations']}")
    print(f"Emotional Enhancements: {stats['emotional_enhancements']}")
    print(f"Pattern Diversifications: {stats['pattern_diversifications']}")


# NKATã¨ã®çµ±åˆã‚¯ãƒ©ã‚¹
class NKATExpressionIntegration:
    """NKATçµ±åˆè¡¨ç¾æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, easy_novel_context):
        self.ctx = easy_novel_context
        self.expression_engine = ExpressionExpansionEngine()
        
        # çµ±åˆè¨­å®š
        self.integration_enabled = self.ctx.get("nkat_expression_expansion", True)
        self.expansion_strength = self.ctx.get("expression_expansion_strength", 0.7)
        
        print("ğŸ¯ NKAT Expression Integration initialized")
    
    def enhance_text_with_expression_expansion(self, prompt: str, llm_output: str) -> str:
        """è¡¨ç¾æ‹¡å¼µã‚’å«ã‚€æ–‡ç« å¼·åŒ–"""
        
        if not self.integration_enabled:
            return llm_output
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡º
        character = self._extract_character(llm_output)
        
        # è¡¨ç¾æ‹¡å¼µå®Ÿè¡Œ
        expanded = self.expression_engine.expand_expression(
            llm_output, character, prompt
        )
        
        return expanded
    
    def _extract_character(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’æŠ½å‡º"""
        
        # ç™ºè©±å½¢å¼ã®æ¤œå‡º
        speaker_match = re.match(r'^([^ï¼šã€Œ]+)ï¼š', text)
        if speaker_match:
            return speaker_match.group(1).strip()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return self.ctx.get("char_name", "general")
    
    def get_integration_stats(self) -> Dict:
        """çµ±åˆçµ±è¨ˆã®å–å¾—"""
        
        engine_stats = self.expression_engine.get_expansion_stats()
        
        return {
            "integration_enabled": self.integration_enabled,
            "expansion_strength": self.expansion_strength,
            "engine_stats": engine_stats,
            "context_character": self.ctx.get("char_name", "unknown")
        }


if __name__ == "__main__":
    test_expression_expansion() 