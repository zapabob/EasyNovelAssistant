# -*- coding: utf-8 -*-
"""
3-gramãƒ–ãƒ­ãƒƒã‚¯æ©Ÿèƒ½ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆï¼ˆè©³ç´°ç‰ˆï¼‰
"""

import sys
import os
import re
from collections import Counter

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
sys.path.insert(0, src_dir)

from utils.repetition_suppressor_v3 import AdvancedRepetitionSuppressorV3

def debug_ngram_extraction(text, ngram_size=3):
    """n-gramæŠ½å‡ºå‡¦ç†ã‚’è©³ç´°ãƒ‡ãƒãƒƒã‚°"""
    print(f"ğŸ” {ngram_size}-gramæŠ½å‡ºãƒ‡ãƒãƒƒã‚°:")
    print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: '{text}' (é•·ã•: {len(text)})")
    
    if len(text) < ngram_size:
        print(f"   â†’ çŸ­ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return []
    
    # n-gramã‚’æŠ½å‡º
    ngrams = []
    for i in range(len(text) - ngram_size + 1):
        ngram = text[i:i+ngram_size]
        has_japanese = re.search(r'[ã‚-ã‚“ã‚¢-ãƒ³ä¸€-é¾¯]', ngram)
        print(f"   ä½ç½®{i}: '{ngram}' - æ—¥æœ¬èª?: {bool(has_japanese)}")
        
        if has_japanese:
            ngrams.append((ngram, i))
    
    # é‡è¤‡ã‚’æ¤œå‡º
    ngram_counts = Counter([ngram for ngram, _ in ngrams])
    repeated_ngrams = {ngram for ngram, count in ngram_counts.items() if count > 1}
    
    print(f"   æŠ½å‡ºã•ã‚ŒãŸ{ngram_size}-gram: {len(ngrams)}å€‹")
    print(f"   å‡ºç¾å›æ•°: {dict(ngram_counts)}")
    print(f"   é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³: {list(repeated_ngrams)}")
    
    return ngrams, repeated_ngrams

def test_ngram_blocking_detailed():
    """3-gramãƒ–ãƒ­ãƒƒã‚¯æ©Ÿèƒ½ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ†ã‚¹ãƒˆè¨­å®š
    config = {
        'similarity_threshold': 0.30,
        'max_distance': 50,
        'min_compress_rate': 0.03,
        'enable_4gram_blocking': True,
        'ngram_block_size': 3,
        'enable_mecab_normalization': False,
        'enable_rhetorical_protection': False,
        'debug_mode': True
    }
    
    suppressor = AdvancedRepetitionSuppressorV3(config)
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_texts = [
        "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã ã‹ã‚‰æ•£æ­©ã—ã¾ã—ã‚‡ã†ã€‚",
        "ã‚ã„ã†ã‚ã„ã†ã‚ã„ã†",
        "ãã‚„ãã‚„ãã‚„",
        "ä»Šæ—¥ä»Šæ—¥ä»Šæ—¥",
        "ãŠå…„ã¡ã‚ƒã‚“ãŠå…„ã¡ã‚ƒã‚“"
    ]
    
    print("ğŸ”§ 3-gramãƒ–ãƒ­ãƒƒã‚¯æ©Ÿèƒ½è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆ {i}: {text}")
        
        # æ‰‹å‹•ã§n-gramæŠ½å‡ºã‚’ãƒ†ã‚¹ãƒˆ
        ngrams, repeated = debug_ngram_extraction(text, 3)
        
        # å®Ÿéš›ã®3-gramãƒ–ãƒ­ãƒƒã‚¯æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ”§ å®Ÿéš›ã®3-gramãƒ–ãƒ­ãƒƒã‚¯å‡¦ç†:")
        result = suppressor._apply_4gram_blocking(text)
        blocks_applied = getattr(suppressor, '_ngram_blocks_applied', 0)
        
        print(f"   å…¥åŠ›: '{text}'")
        print(f"   å‡ºåŠ›: '{result}'")
        print(f"   ãƒ–ãƒ­ãƒƒã‚¯é©ç”¨å›æ•°: {blocks_applied}")
        print(f"   å¤‰åŒ–: {'ã‚ã‚Š' if text != result else 'ãªã—'}")
        
        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒªã‚»ãƒƒãƒˆ
        suppressor._ngram_blocks_applied = 0
        suppressor.debug_log = []
        
        print("-" * 60)

if __name__ == "__main__":
    test_ngram_blocking_detailed() 