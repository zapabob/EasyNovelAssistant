# 2025-06-21 GGUF追加機能実装ログ

## 概要
EasyNovelAssistantにローカルLLMのGGUFファイルをメニューから追加できる機能を実装しました。

## 実装内容

### 1. ModelMenuクラスの拡張 (`model_menu.py`)
- **新機能**: `add_gguf_file()` メソッドを追加
- **メニュー追加**: "GGUFファイルを追加..." メニュー項目を最上部に配置
- **ファイル選択**: tkinterのfiledialogを使用してGGUFファイルを選択
- **設定入力**: 以下の項目をダイアログで入力
  - モデル表示名（ファイル名から自動推測、編集可能）
  - GPU層数（7B: 33, 13B: 41, 70B: 65の推奨値を表示）
  - コンテキストサイズ（2048〜131072、デフォルト4096）

### 2. ファイル管理機能
- **自動コピー**: 選択されたGGUFファイルをKoboldCppディレクトリに自動コピー
- **重複チェック**: 既存モデル名・ファイル名の重複を確認し、上書き確認
- **設定保存**: `llm.json`にモデル設定を保存
- **リアルタイム更新**: メモリ内のコンテキストも即座に更新

### 3. KoboldCppクラスの修正 (`kobold_cpp.py`)
- **ローカルファイル対応**: `local_file` フラグによる処理分岐
- **初期化処理**: ローカルファイルの場合、ダウンロード関連処理をスキップ
- **バッチファイル生成**: ローカルファイル用のcurl_cmdを空文字に設定
- **ダウンロード処理**: ローカルファイルの場合、ダウンロードをスキップ

## 技術仕様

### ファイル構造
```json
{
  "モデル名": {
    "max_gpu_layer": 33,
    "context_size": 4096,
    "urls": ["file://path/to/model.gguf"],
    "file_name": "model.gguf",
    "local_file": true
  }
}
```

### 処理フロー
1. ユーザーがメニューから「GGUFファイルを追加...」を選択
2. ファイル選択ダイアログでGGUFファイルを選択
3. モデル名、GPU層数、コンテキストサイズを入力
4. KoboldCppディレクトリにファイルをコピー
5. llm.jsonに設定を保存
6. メモリ内のコンテキストを更新
7. 完了メッセージを表示

## エラーハンドリング
- ファイル存在チェック
- 権限エラー対応
- JSON形式エラー対応
- ユーザーキャンセル対応
- 例外処理とエラーメッセージ表示

## 使用方法
1. メニューバーの「モデル」→「GGUFファイルを追加...」を選択
2. GGUFファイルを選択
3. 表示名、GPU層数、コンテキストサイズを設定
4. 「OK」で完了
5. 追加されたモデルがメニューに表示される

## 対応ファイル形式
- `.gguf` (主要対象)
- `*.*` (すべてのファイル、フォールバック)

## 動作環境
- Windows 11 (PowerShell)
- Python 3.x
- tkinter (GUI)
- KoboldCpp (推論エンジン)

## 今後の拡張可能性
- モデル削除機能
- モデル設定編集機能
- 自動GPU層数検出
- モデル情報表示機能
- バッチ追加機能

## 実装完了日
2025年6月21日

## 実装者
AI Assistant (Claude Sonnet 4)

## 修正履歴

### 2025-06-21 追加修正: ファイル名サニタイズ処理
- **問題**: モデル名に`?`や`=`などの無効な文字が含まれている場合、バッチファイル作成時に`[Errno 22] Invalid argument`エラーが発生
- **原因**: HuggingFaceのURLパラメータがモデル名に含まれる場合がある
- **解決**: `Path.get_path_name()`メソッドを使用してファイル名をサニタイズ
- **対象ファイル**: 
  - `EasyNovelAssistant/EasyNovelAssistant/src/kobold_cpp.py`
  - `EasyNovelAssistant-main/EasyNovelAssistant/src/kobold_cpp.py`
  - `EasyNovelAssistant-main/EasyNovelAssistant/setup/EasyNovelAssistant/src/kobold_cpp.py`

### 修正内容
```python
# 修正前
bat_file = os.path.join(Path.kobold_cpp, f'Run-{llm["name"]}-C{context_size // 1024}K-L0.bat')

# 修正後
safe_name = Path.get_path_name(llm["name"])
bat_file = os.path.join(Path.kobold_cpp, f'Run-{safe_name}-C{context_size // 1024}K-L0.bat')
```

## 新機能追加: 直接GGUF選択機能

### 2025-06-21 追加実装: GGUFファイル直接選択機能
- **新機能**: `select_gguf_file_directly()` メソッドを追加
- **メニュー項目**: "GGUFファイルを直接選択..." を最上部に配置
- **即座使用**: ファイル選択後、設定保存せずに即座にモデルを起動
- **一時的設定**: `temporary: true` フラグで一時的なモデルとして管理
- **簡易設定**: GPU層数のみ設定、コンテキストサイズは4096固定

### 機能比較
| 機能 | GGUFファイルを追加 | GGUFファイルを直接選択 |
|------|-------------------|----------------------|
| 用途 | 永続的にモデル追加 | 一時的にモデル使用 |
| 設定項目 | 名前・GPU層数・コンテキスト | GPU層数のみ |
| 保存 | llm.jsonに保存 | メモリ内のみ |
| 再起動後 | 利用可能 | 利用不可 |

### 使用シーン
- **直接選択**: テスト用途、一回限りの使用
- **追加**: 継続的に使用するモデル

## 備考
- CUDA対応RTX3080での動作を想定
- 電源断保護機能は既存システムを活用
- 日本語UIで統一
- エラーメッセージも日本語対応
- ファイル名サニタイズ処理により、URL由来の無効文字を自動除去
- [LM Studio](https://github.com/lmstudio-ai/configs/issues/11)や[LocalAI](https://github.com/mudler/LocalAI/discussions/1096)と同様の直接選択機能を実装 