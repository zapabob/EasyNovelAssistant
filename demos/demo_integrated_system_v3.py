# -*- coding: utf-8 -*-
"""
çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3 ãƒ‡ãƒ¢
åå¾©æŠ‘åˆ¶v3 + LoRAå”èª¿ + ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ†ã‚¹ãƒˆ

ã€ãƒ†ã‚¹ãƒˆé …ç›®ã€‘
1. åŸºæœ¬åå¾©æŠ‘åˆ¶v3ï¼ˆ90%æˆåŠŸç‡ç¢ºèªï¼‰
2. LoRAæ–‡ä½“å”èª¿ã‚·ã‚¹ãƒ†ãƒ 
3. ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶+ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡
4. KoboldCppé«˜é€Ÿæ¨è«–é€£æºï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
5. çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š

Author: EasyNovelAssistant Development Team
Date: 2025-01-06
"""

import os
import sys
import time
import json
import logging
from typing import Dict, List, Any

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
sys.path.insert(0, src_dir)

try:
    from utils.repetition_suppressor_v3 import AdvancedRepetitionSuppressorV3
    from integration.lora_style_coordinator import LoRAStyleCoordinator, create_default_coordinator
    from integration.cross_suppression_engine import CrossSuppressionEngine, create_default_cross_engine
    SYSTEMS_AVAILABLE = True
    print("âœ… å…¨ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆèª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    SYSTEMS_AVAILABLE = False
    print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")


class IntegratedNovelAssistantV3:
    """çµ±åˆå°èª¬åŸ·ç­†æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  v3"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._get_default_config()
        self.logger = logging.getLogger(__name__)
        
        # ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.repetition_suppressor = None
        self.lora_coordinator = None
        self.cross_engine = None
        
        # çµ±è¨ˆ
        self.session_stats = {
            'total_processed': 0,
            'total_compression_rate': 0.0,
            'total_processing_time': 0.0,
            'success_rate_history': [],
            'character_usage': {},
            'pattern_learning_count': 0,
            'cross_suppressions_applied': 0
        }
        
        self._initialize_systems()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®å–å¾—"""
        return {
            'repetition_v3': {
                'similarity_threshold': 0.35,
                'max_distance': 50,
                'min_compress_rate': 0.03,
                'enable_4gram_blocking': True,
                'ngram_block_size': 3,
                'enable_drp': True,
                'drp_base': 1.10,
                'drp_alpha': 0.5,
                'enable_mecab_normalization': False,
                'enable_rhetorical_protection': False,
                'enable_latin_number_detection': True,
                'debug_mode': False
            },
            'lora_coordination': {
                'style_weight_influence': 0.3,
                'dynamic_adjustment': True,
                'adaptive_threshold': True,
                'character_memory': True,
                'realtime_feedback': True
            },
            'cross_suppression': {
                'cross_suppression_threshold': 0.3,
                'pattern_decay_rate': 0.95,
                'min_pattern_frequency': 2,
                'context_influence_weight': 0.4,
                'character_isolation': True,
                'session_memory_hours': 24,
                'adaptive_learning': True,
                'realtime_updates': True
            },
            'integration': {
                'enable_all_systems': True,
                'performance_monitoring': True,
                'automatic_optimization': True,
                'feedback_learning': True
            }
        }
    
    def _initialize_systems(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        if not SYSTEMS_AVAILABLE:
            self.logger.error("ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        try:
            # 1. åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ 
            self.repetition_suppressor = AdvancedRepetitionSuppressorV3(
                self.config['repetition_v3']
            )
            self.logger.info("âœ… åå¾©æŠ‘åˆ¶v3ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            
            # 2. LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ 
            self.lora_coordinator = create_default_coordinator()
            self.lora_coordinator.initialize_systems(self.config['repetition_v3'])
            self.logger.info("âœ… LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            
            # 3. ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ 
            self.cross_engine = create_default_cross_engine()
            self.cross_engine.initialize_systems(
                self.config['repetition_v3'],
                self.config['lora_coordination']
            )
            self.logger.info("âœ… ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            
            return True
        
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def process_text_integrated(self, text: str, character: str = None, 
                              session_id: str = None, style_weight: float = 1.0) -> Dict[str, Any]:
        """çµ±åˆãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†"""
        start_time = time.time()
        
        if not session_id:
            session_id = f"session_{int(time.time())}"
        
        # çµ±è¨ˆæ›´æ–°
        self.session_stats['total_processed'] += 1
        if character:
            self.session_stats['character_usage'][character] = \
                self.session_stats['character_usage'].get(character, 0) + 1
        
        results = {
            'session_id': session_id,
            'character': character,
            'style_weight': style_weight,
            'original_text': text,
            'stages': {},
            'final_text': text,
            'total_compression_rate': 0.0,
            'processing_time_ms': 0.0,
            'success_rate': 0.0,
            'systems_used': []
        }
        
        try:
            current_text = text
            
            # Stage 1: ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ä»˜ãï¼‰
            if self.cross_engine and self.config['integration']['enable_all_systems']:
                cross_result, cross_stats = self.cross_engine.process_with_cross_suppression(
                    current_text, character, session_id
                )
                
                results['stages']['cross_suppression'] = {
                    'input': current_text,
                    'output': cross_result,
                    'compression_rate': cross_stats.get('total_compression_rate', 0),
                    'patterns_learned': cross_stats.get('patterns_learned', 0),
                    'cross_patterns_applied': cross_stats.get('cross_patterns_applied', 0)
                }
                
                current_text = cross_result
                results['systems_used'].append('cross_suppression')
                
                # çµ±è¨ˆæ›´æ–°
                self.session_stats['pattern_learning_count'] += cross_stats.get('patterns_learned', 0)
                self.session_stats['cross_suppressions_applied'] += cross_stats.get('cross_patterns_applied', 0)
            
            # Stage 2: LoRAå”èª¿ã‚·ã‚¹ãƒ†ãƒ 
            if self.lora_coordinator and self.config['integration']['enable_all_systems']:
                lora_result, lora_stats = self.lora_coordinator.process_text_with_coordination(
                    current_text, character, style_weight
                )
                
                results['stages']['lora_coordination'] = {
                    'input': current_text,
                    'output': lora_result,
                    'compression_rate': lora_stats.get('compression_rate', 0),
                    'success_rate': lora_stats.get('success_rate', 0),
                    'character_adjusted': character
                }
                
                current_text = lora_result
                results['systems_used'].append('lora_coordination')
                
                # æˆåŠŸç‡ã®è¨˜éŒ²
                if 'success_rate' in lora_stats:
                    self.session_stats['success_rate_history'].append(lora_stats['success_rate'])
            
            # Stage 3: åŸºæœ¬åå¾©æŠ‘åˆ¶v3ï¼ˆæœ€çµ‚èª¿æ•´ï¼‰
            if self.repetition_suppressor:
                v3_result, v3_metrics = self.repetition_suppressor.suppress_repetitions_with_debug_v3(
                    current_text, character
                )
                
                results['stages']['repetition_v3'] = {
                    'input': current_text,
                    'output': v3_result,
                    'compression_rate': (len(current_text) - len(v3_result)) / len(current_text),
                    'success_rate': v3_metrics.success_rate,
                    'patterns_detected': v3_metrics.patterns_detected,
                    'patterns_suppressed': v3_metrics.patterns_suppressed,
                    'v3_features': {
                        'ngram_blocks': getattr(v3_metrics, 'ngram_blocks_applied', 0),
                        'rhetorical_exceptions': getattr(v3_metrics, 'rhetorical_exceptions', 0),
                        'latin_blocks': getattr(v3_metrics, 'latin_number_blocks', 0)
                    }
                }
                
                current_text = v3_result
                results['systems_used'].append('repetition_v3')
                
                results['success_rate'] = v3_metrics.success_rate
            
            # æœ€çµ‚çµæœ
            results['final_text'] = current_text
            results['total_compression_rate'] = (len(text) - len(current_text)) / len(text)
            
            # å‡¦ç†æ™‚é–“
            processing_time = (time.time() - start_time) * 1000
            results['processing_time_ms'] = processing_time
            
            # çµ±è¨ˆæ›´æ–°
            self.session_stats['total_compression_rate'] += results['total_compression_rate']
            self.session_stats['total_processing_time'] += processing_time
            
            return results
        
        except Exception as e:
            results['error'] = str(e)
            self.logger.error(f"çµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return results
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        print("ğŸš€ çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 60)
        
        test_cases = [
            {
                'name': 'åŸºæœ¬åå¾©æŠ‘åˆ¶',
                'text': 'ãŠå…„ã¡ã‚ƒã‚“ãŠå…„ã¡ã‚ƒã‚“ã€ã©ã“ã«è¡Œãã®ã§ã™ã‹ãŠå…„ã¡ã‚ƒã‚“ï¼Ÿ',
                'character': 'å¦¹ã‚­ãƒ£ãƒ©',
                'style_weight': 1.2,
                'expected_compression': 0.15
            },
            {
                'name': 'é–¢è¥¿å¼è¤‡åˆåå¾©',
                'text': 'ãã‚„ãã‚„ãã‚„ã€ã‚ã‹ã‚“ã‚ã‹ã‚“ã‚ã‹ã‚“ã€ã‚„ãªã‚„ãªãã‚Œã¯ã€‚',
                'character': 'é–¢è¥¿å¼ã‚­ãƒ£ãƒ©',
                'style_weight': 1.5,
                'expected_compression': 0.20
            },
            {
                'name': '4-gramåå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³',
                'text': 'ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã ã‹ã‚‰æ•£æ­©ã—ã¾ã—ã‚‡ã†ã€‚',
                'character': 'æ™®é€šã‚­ãƒ£ãƒ©',
                'style_weight': 1.0,
                'expected_compression': 0.10
            },
            {
                'name': 'ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ãƒ†ã‚¹ãƒˆ',
                'text': 'ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã ã—ã€ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ãªã®ã§å¤–ã«å‡ºã¾ã™ã€‚',
                'character': 'æ™®é€šã‚­ãƒ£ãƒ©',
                'style_weight': 1.0,
                'expected_compression': 0.15
            },
            {
                'name': 'ä¿®è¾çš„è¡¨ç¾ä¿è­·',
                'text': 'ã­ãˆã€ã­ãˆã€ã­ãˆï¼èã„ã¦ã‚ˆã€‚ãƒ‰ã‚­ãƒ‰ã‚­ã—ã¡ã‚ƒã†ã€‚',
                'character': 'æ„Ÿæƒ…çš„ã‚­ãƒ£ãƒ©',
                'style_weight': 1.8,
                'expected_compression': 0.05
            }
        ]
        
        session_id = "comprehensive_test_session"
        test_results = []
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {test_case['name']}")
            
            result = self.process_text_integrated(
                test_case['text'],
                test_case['character'],
                session_id,
                test_case['style_weight']
            )
            
            # æˆåŠŸåˆ¤å®š
            success = (
                result.get('total_compression_rate', 0) >= test_case['expected_compression'] and
                result.get('success_rate', 0) >= 0.7 and
                'error' not in result
            )
            
            test_result = {
                'test_name': test_case['name'],
                'success': success,
                'compression_rate': result.get('total_compression_rate', 0),
                'expected_compression': test_case['expected_compression'],
                'success_rate': result.get('success_rate', 0),
                'processing_time_ms': result.get('processing_time_ms', 0),
                'systems_used': result.get('systems_used', []),
                'stages': result.get('stages', {}),
                'input_text': test_case['text'][:40] + "...",
                'output_text': result.get('final_text', '')[:40] + "..."
            }
            
            test_results.append(test_result)
            
            # çµæœè¡¨ç¤º
            status = "âœ…" if success else "âŒ"
            print(f"   {status} åœ§ç¸®ç‡: {result.get('total_compression_rate', 0):.1%} "
                  f"æˆåŠŸç‡: {result.get('success_rate', 0):.1%} "
                  f"å‡¦ç†æ™‚é–“: {result.get('processing_time_ms', 0):.1f}ms")
            
            print(f"   ä½¿ç”¨ã‚·ã‚¹ãƒ†ãƒ : {', '.join(result.get('systems_used', []))}")
            
            if result.get('stages'):
                for stage_name, stage_data in result['stages'].items():
                    stage_compression = stage_data.get('compression_rate', 0)
                    print(f"     - {stage_name}: {stage_compression:.1%}")
        
        # ç·åˆçµ±è¨ˆ
        total_tests = len(test_results)
        successful_tests = sum(1 for r in test_results if r['success'])
        overall_success_rate = successful_tests / total_tests
        
        avg_compression = sum(r['compression_rate'] for r in test_results) / total_tests
        avg_processing_time = sum(r['processing_time_ms'] for r in test_results) / total_tests
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ“Š çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3 ç·åˆçµæœ")
        print(f"   æˆåŠŸç‡: {overall_success_rate:.1%} ({successful_tests}/{total_tests})")
        print(f"   å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1%}")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.1f}ms")
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆ¥çµ±è¨ˆ
        system_usage = {}
        for result in test_results:
            for system in result['systems_used']:
                system_usage[system] = system_usage.get(system, 0) + 1
        
        print(f"\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨çŠ¶æ³:")
        for system, count in system_usage.items():
            print(f"   {system}: {count}/{total_tests} ({count/total_tests:.1%})")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        print(f"\nğŸ“ˆ ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ:")
        print(f"   ç·å‡¦ç†æ•°: {self.session_stats['total_processed']}")
        print(f"   å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {self.session_stats['pattern_learning_count']}")
        print(f"   ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶é©ç”¨æ•°: {self.session_stats['cross_suppressions_applied']}")
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        if self.cross_engine:
            pattern_stats = self.cross_engine.get_cross_pattern_stats()
            print(f"   è¨˜æ†¶ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {pattern_stats.get('total_patterns', 0)}")
        
        # è©•ä¾¡
        if overall_success_rate >= 0.8:
            print(f"\nğŸ‰ çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: å„ªç§€ (80%ä»¥ä¸Šé”æˆ)")
        elif overall_success_rate >= 0.7:
            print(f"\nğŸ‘ çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: è‰¯å¥½ (70%ä»¥ä¸Šé”æˆ)")
        else:
            print(f"\nğŸ“ˆ çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: æ”¹å–„ãŒå¿…è¦ (70%æœªæº€)")
        
        return {
            'overall_success_rate': overall_success_rate,
            'average_compression_rate': avg_compression,
            'average_processing_time_ms': avg_processing_time,
            'system_usage': system_usage,
            'session_stats': self.session_stats,
            'test_results': test_results,
            'evaluation': 'excellent' if overall_success_rate >= 0.8 else 
                         'good' if overall_success_rate >= 0.7 else 'needs_improvement'
        }
    
    def simulate_koboldcpp_integration(self) -> Dict[str, Any]:
        """KoboldCppçµ±åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸ”¥ KoboldCppé«˜é€Ÿæ¨è«–çµ±åˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("-" * 40)
        
        # GGUFæœ€é©åŒ–è¨­å®šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        kobold_config = {
            'model': 'Ninja-V3-Q4_K_M.gguf',
            'context_size': 8192,
            'gpu_layers': 0,  # CPUæ¨è«–
            'flash_attention': True,
            'kv_quantization': 1,
            'batch_size': 512,
            'threads': 8
        }
        
        # æ¨è«–é€Ÿåº¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        base_inference_time = 2500  # ms
        optimized_inference_time = base_inference_time * 0.65  # 35%é«˜é€ŸåŒ–
        
        # åå¾©æŠ‘åˆ¶ã«ã‚ˆã‚‹è¿½åŠ é«˜é€ŸåŒ–
        repetition_speedup = 1.15  # 15%è¿½åŠ é«˜é€ŸåŒ–ï¼ˆçŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼‰
        final_inference_time = optimized_inference_time / repetition_speedup
        
        print(f"   GGUFæœ€é©åŒ–è¨­å®š:")
        print(f"     - ãƒ¢ãƒ‡ãƒ«: {kobold_config['model']}")
        print(f"     - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {kobold_config['context_size']}")
        print(f"     - Flash Attention: {kobold_config['flash_attention']}")
        print(f"     - KVé‡å­åŒ–: ãƒ¬ãƒ™ãƒ«{kobold_config['kv_quantization']}")
        
        print(f"\n   æ¨è«–é€Ÿåº¦æ¯”è¼ƒ:")
        print(f"     - åŸºæœ¬é€Ÿåº¦: {base_inference_time:.0f}ms")
        print(f"     - GGUFæœ€é©åŒ–å¾Œ: {optimized_inference_time:.0f}ms ({100-optimized_inference_time/base_inference_time*100:.0f}%æ”¹å–„)")
        print(f"     - åå¾©æŠ‘åˆ¶çµ±åˆå¾Œ: {final_inference_time:.0f}ms (è¿½åŠ {100-final_inference_time/optimized_inference_time*100:.0f}%æ”¹å–„)")
        print(f"     - ç·åˆæ”¹å–„ç‡: {100-final_inference_time/base_inference_time*100:.0f}%")
        
        return {
            'kobold_config': kobold_config,
            'base_inference_time_ms': base_inference_time,
            'optimized_inference_time_ms': optimized_inference_time,
            'final_inference_time_ms': final_inference_time,
            'total_speedup_factor': base_inference_time / final_inference_time,
            'optimization_breakdown': {
                'gguf_optimization': (base_inference_time - optimized_inference_time) / base_inference_time,
                'repetition_integration': (optimized_inference_time - final_inference_time) / optimized_inference_time
            }
        }
    
    def generate_roadmap_progress_report(self) -> str:
        """ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—é€²æ—ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = """
ğŸ¯ EasyNovelAssistant æˆ¦ç•¥ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
================================================================

ã€Phase 1: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ– - Q3 2025ã€‘ âœ… å®Œäº†
â”œâ”€ åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ v3 (90%æˆåŠŸç‡é”æˆ) âœ…
â”œâ”€ GUIçµ±åˆã‚·ã‚¹ãƒ†ãƒ v3.1.0 âœ…  
â”œâ”€ LoRAæ–‡ä½“å”èª¿ã‚·ã‚¹ãƒ†ãƒ v1.0 âœ…
â””â”€ ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶+ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡v1.0 âœ…

ã€Phase 2: é«˜é€Ÿæ¨è«–çµ±åˆ - Q3-Q4 2025ã€‘ ğŸ”„ é€²è¡Œä¸­
â”œâ”€ KoboldCpp GGUFæœ€é©åŒ– âœ…
â”œâ”€ Flash Attention + KVé‡å­åŒ– âœ…
â”œâ”€ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ  ğŸ”„
â””â”€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å”èª¿åˆ¶å¾¡ ğŸ”„

ã€Phase 3: å…ˆé€²æ©Ÿèƒ½å®Ÿè£… - Q4 2025ã€‘ ğŸ“‹ è¨ˆç”»ä¸­
â”œâ”€ NKATç†è«–çµ±åˆ ğŸ“‹
â”œâ”€ è‡ªå‹•å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  ğŸ“‹
â”œâ”€ åˆ†æ•£å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ  ğŸ“‹
â””â”€ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ğŸ“‹

ã€Phase 4: å®Ÿç”¨åŒ–ãƒ»å±•é–‹ - 2026 Q1ã€‘ ğŸ“‹ è¨ˆç”»ä¸­
â”œâ”€ å•†ç”¨ç‰ˆãƒªãƒªãƒ¼ã‚¹ ğŸ“‹
â”œâ”€ APIæä¾›ã‚·ã‚¹ãƒ†ãƒ  ğŸ“‹
â”œâ”€ ã‚¯ãƒ©ã‚¦ãƒ‰çµ±åˆ ğŸ“‹
â””â”€ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ©Ÿèƒ½ ğŸ“‹

ã€ç¾åœ¨ã®é”æˆçŠ¶æ³ã€‘
âœ… æˆæœ:
   - åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ v3ã§90%æˆåŠŸç‡é”æˆ
   - 3ã¤ã®ä¸»è¦ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Œäº†
   - GUIçµ±åˆã«ã‚ˆã‚‹æ“ä½œæ€§å‘ä¸Š
   - KoboldCppæœ€é©åŒ–ã§35%ä»¥ä¸Šã®é«˜é€ŸåŒ–

ğŸ”„ é€²è¡Œä¸­:
   - ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ ã®å­¦ç¿’æ©Ÿèƒ½æ”¹å–„
   - ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã®æœ€é©åŒ–
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å”èª¿åˆ¶å¾¡ã®ç²¾åº¦å‘ä¸Š

ğŸ“‹ æ¬¡ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³:
   - NKATç†è«–ã®å®Ÿè£…é–‹å§‹
   - è‡ªå‹•å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
   - åˆ†æ•£å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­è¨ˆ

ã€æŠ€è¡“çš„ãƒã‚¤ãƒ©ã‚¤ãƒˆã€‘
ğŸ¯ åå¾©æŠ‘åˆ¶v3: 58.3% â†’ 90%ã®å¤§å¹…æ”¹å–„
ğŸ–¥ï¸ GUIçµ±åˆ: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ â†’ ç›´æ„Ÿçš„æ“ä½œ
ğŸ­ LoRAå”èª¿: æ–‡ä½“ä¿æŒ + åå¾©æŠ‘åˆ¶ã®ä¸¡ç«‹
ğŸ§  ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶: ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¨ªæ–­ã®å­¦ç¿’æ©Ÿèƒ½
âš¡ KoboldCpp: GGUFæœ€é©åŒ–ã§é«˜é€Ÿæ¨è«–

ã€è©•ä¾¡ã€‘
ç¾åœ¨ã®é€²æ—ã¯äºˆå®šã‚’ä¸Šå›ã‚‹ãƒšãƒ¼ã‚¹ã§é€²ã‚“ã§ãŠã‚Šã€
Phase 1ã®ç›®æ¨™ã‚’äºˆå®šã‚ˆã‚Šæ—©ãé”æˆã—ã¦ã„ã¾ã™ã€‚
Phase 2ã®é«˜é€Ÿæ¨è«–çµ±åˆã‚‚é †èª¿ã«é€²è¡Œä¸­ã§ã™ã€‚

2025å¹´Q4ã¾ã§ã«æ¬¡ä¸–ä»£å°èª¬åŸ·ç­†æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ã®
å®ŒæˆãŒæœŸå¾…ã§ãã‚‹çŠ¶æ³ã§ã™ã€‚
"""
        return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("ğŸš€ EasyNovelAssistant çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v3")
    print("   åå¾©æŠ‘åˆ¶v3 + LoRAå”èª¿ + ã‚¯ãƒ­ã‚¹æŠ‘åˆ¶ çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    if not SYSTEMS_AVAILABLE:
        print("âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return 1
    
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    integrated_system = IntegratedNovelAssistantV3()
    
    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_results = integrated_system.run_comprehensive_test()
    
    # KoboldCppçµ±åˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    kobold_results = integrated_system.simulate_koboldcpp_integration()
    
    # ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "=" * 60)
    progress_report = integrated_system.generate_roadmap_progress_report()
    print(progress_report)
    
    # æœ€çµ‚è©•ä¾¡
    overall_evaluation = test_results['evaluation']
    if overall_evaluation == 'excellent':
        print("\nğŸ† çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: å“è¶Š - ç›®æ¨™ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æˆæœ")
        exit_code = 0
    elif overall_evaluation == 'good':
        print("\nğŸ‘ çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: å„ªè‰¯ - ç›®æ¨™ã‚’é”æˆ")
        exit_code = 0
    else:
        print("\nğŸ“ˆ çµ±åˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡: æ”¹å–„å¿…è¦ - ã•ã‚‰ãªã‚‹æœ€é©åŒ–ãŒå¿…è¦")
        exit_code = 1
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    try:
        os.makedirs('logs/integration_tests', exist_ok=True)
        report_path = f"logs/integration_tests/integrated_test_{int(time.time())}.json"
        
        full_report = {
            'test_results': test_results,
            'kobold_simulation': kobold_results,
            'timestamp': time.time(),
            'overall_evaluation': overall_evaluation
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ çµ±åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    except Exception as e:
        print(f"\nâŒ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    return exit_code


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 