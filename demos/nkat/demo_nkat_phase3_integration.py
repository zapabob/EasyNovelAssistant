# -*- coding: utf-8 -*-
"""
NKAT Phase 3 çµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢
é«˜åº¦ãªéå¯æ›ãƒ†ãƒ³ã‚½ãƒ«å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®æ¤œè¨¼

ã€ãƒ†ã‚¹ãƒˆé …ç›®ã€‘
1. NKAT Advanced Tensor Processing System
2. NKAT Integration Manager 
3. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆç¢ºèª
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
5. å“è³ªæ”¹å–„æ¸¬å®š

Author: EasyNovelAssistant Development Team
Date: 2025-01-06
Version: Phase 3 Integration Test
"""

import os
import sys
import json
import time
import logging
from typing import Dict, List, Any
from collections import defaultdict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from nkat.nkat_advanced_tensor import create_advanced_nkat_processor
    from nkat.nkat_integration_manager import create_nkat_integration_manager
    NKAT_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ NKAT ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    NKAT_AVAILABLE = False


class NKATPhase3TestSuite:
    """NKAT Phase 3 ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.test_results = {
            'advanced_tensor_tests': [],
            'integration_manager_tests': [],
            'performance_benchmarks': [],
            'quality_measurements': [],
            'system_coordination_tests': []
        }
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
        self.test_cases = self._define_test_cases()
        
        self.logger.info("ğŸ§ª NKAT Phase 3 ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆåˆæœŸåŒ–å®Œäº†")
    
    def _define_test_cases(self) -> List[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å®šç¾©"""
        return [
            {
                'id': 'repetition_case_1',
                'text': 'ãŠå…„ã¡ã‚ƒã‚“ãŠå…„ã¡ã‚ƒã‚“ã€ã©ã“ã«è¡Œãã®ã§ã™ã‹ãŠå…„ã¡ã‚ƒã‚“ï¼Ÿ',
                'character': 'å¦¹ã‚­ãƒ£ãƒ©',
                'context': 'å®¶æ—ä¼šè©±',
                'expected_improvement': 'repetition_reduction',
                'priority': 'high'
            },
            {
                'id': 'emotional_expression_1',
                'text': 'å¬‰ã—ã„ã§ã™ã€‚ã¨ã¦ã‚‚å¬‰ã—ã„ã§ã™ã€‚æœ¬å½“ã«å¬‰ã—ã„ã§ã™ã€‚',
                'character': 'æ¨¹é‡Œ',
                'context': 'æ„Ÿæƒ…è¡¨ç¾',
                'expected_improvement': 'emotional_enhancement',
                'priority': 'high'
            },
            {
                'id': 'monotonous_response_1',
                'text': 'ãã†ã§ã™ã­ã€‚ãã†ã§ã™ã­ã€‚ã§ã‚‚é›£ã—ã„ã§ã™ã­ã€‚',
                'character': 'ç¾é‡Œ',
                'context': 'ç›¸æ§Œä¼šè©±',
                'expected_improvement': 'variety_increase',
                'priority': 'medium'
            },
            {
                'id': 'complex_narrative_1',
                'text': 'å½¼å¥³ã¯ç¾ã—ã„æœã®å…‰ã®ä¸­ã§ã€ç¾ã—ã„èŠ±ã‚’è¦‹ã¤ã‚ãªãŒã‚‰ã€ç¾ã—ã„æ€ã„å‡ºã‚’æ€ã„å‡ºã—ã¦ã„ãŸã€‚',
                'character': 'ä¸»äººå…¬',
                'context': 'å¿ƒç†æå†™',
                'expected_improvement': 'vocabulary_diversification',
                'priority': 'medium'
            },
            {
                'id': 'dialogue_enhancement_1',
                'text': 'ã€Œã“ã‚“ã«ã¡ã¯ã€ã¨å½¼ã¯è¨€ã£ãŸã€‚ã€Œã“ã‚“ã«ã¡ã¯ã€ã¨å½¼å¥³ã‚‚è¨€ã£ãŸã€‚ã€Œã“ã‚“ã«ã¡ã¯ã€ã¨å­ä¾›ã‚‚è¨€ã£ãŸã€‚',
                'character': 'ç¾¤è¡†',
                'context': 'ä¼šè©±ã‚·ãƒ¼ãƒ³',
                'expected_improvement': 'dialogue_variation',
                'priority': 'high'
            }
        ]
    
    def run_comprehensive_tests(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("ğŸš€ NKAT Phase 3 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 70)
        
        # ã‚·ã‚¹ãƒ†ãƒ å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
        if not NKAT_AVAILABLE:
            print("âŒ NKATã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return {'success': False, 'error': 'NKAT systems not available'}
        
        # 1. Advanced Tensor Processing Tests
        print("\nğŸ”¬ 1. Advanced Tensor Processing ãƒ†ã‚¹ãƒˆ")
        print("-" * 50)
        self._test_advanced_tensor_processing()
        
        # 2. Integration Manager Tests  
        print("\nğŸ¯ 2. Integration Manager ãƒ†ã‚¹ãƒˆ")
        print("-" * 50)
        self._test_integration_manager()
        
        # 3. Performance Benchmarks
        print("\nâš¡ 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        print("-" * 50)
        self._run_performance_benchmarks()
        
        # 4. Quality Measurements
        print("\nğŸ“Š 4. å“è³ªæ¸¬å®š")
        print("-" * 50)
        self._measure_quality_improvements()
        
        # 5. System Coordination Tests
        print("\nğŸ”— 5. ã‚·ã‚¹ãƒ†ãƒ å”èª¿ãƒ†ã‚¹ãƒˆ")
        print("-" * 50)
        self._test_system_coordination()
        
        # çµæœé›†è¨ˆ
        return self._compile_test_results()
    
    def _test_advanced_tensor_processing(self):
        """Advanced Tensor Processing ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
            config = {
                'tensor_dimension': 128,  # ãƒ†ã‚¹ãƒˆç”¨
                'quality_threshold': 0.6,
                'max_iterations': 5,
                'literary_enhancement': True
            }
            processor = create_advanced_nkat_processor(config)
            
            for i, test_case in enumerate(self.test_cases):
                print(f"  ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i+1}: {test_case['id']}")
                
                start_time = time.time()
                enhanced_text, metrics = processor.process_expression(
                    test_case['text'],
                    test_case['character'],
                    test_case['context']
                )
                processing_time = (time.time() - start_time) * 1000
                
                test_result = {
                    'test_case_id': test_case['id'],
                    'original_text': test_case['text'],
                    'enhanced_text': enhanced_text,
                    'processing_time_ms': processing_time,
                    'quality_metrics': metrics,
                    'expected_improvement': test_case['expected_improvement'],
                    'success': len(enhanced_text) > 0
                }
                
                self.test_results['advanced_tensor_tests'].append(test_result)
                
                # çµæœè¡¨ç¤º
                print(f"    åŸæ–‡: {test_case['text'][:50]}...")
                print(f"    æ‹¡å¼µ: {enhanced_text[:50]}...")
                print(f"    å“è³ªæ”¹å–„: {metrics.get('quality_improvement', 0):.3f}")
                print(f"    å‡¦ç†æ™‚é–“: {processing_time:.1f}ms")
                print(f"    æˆåŠŸ: {'âœ…' if test_result['success'] else 'âŒ'}")
                print()
                
        except Exception as e:
            print(f"âŒ Advanced Tensor Processing ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"Advanced Tensor Processing test error: {e}")
    
    def _test_integration_manager(self):
        """Integration Manager ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
            manager = create_nkat_integration_manager()
            
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
            status = manager.get_system_status()
            active_systems = sum(status['active_systems'].values())
            
            print(f"  ğŸ“Š ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚·ã‚¹ãƒ†ãƒ æ•°: {active_systems}/5")
            print(f"  ğŸ”§ å”èª¿åŠ¹ç‡: {status['system_coordination']['coordination_efficiency']:.1%}")
            
            for i, test_case in enumerate(self.test_cases):
                print(f"\n  çµ±åˆå‡¦ç†ãƒ†ã‚¹ãƒˆ {i+1}: {test_case['id']}")
                
                # åŒ…æ‹¬çš„å‡¦ç†å®Ÿè¡Œ
                result = manager.process_text_comprehensive(
                    test_case['text'],
                    test_case['character'],
                    test_case['context'],
                    session_id=f"test_session_{i+1}"
                )
                
                test_result = {
                    'test_case_id': test_case['id'],
                    'processing_result': result,
                    'system_coordination': result.system_coordination,
                    'processing_stages': len(result.processing_stages),
                    'total_time_ms': result.total_processing_time_ms,
                    'success': result.success
                }
                
                self.test_results['integration_manager_tests'].append(test_result)
                
                # çµæœè¡¨ç¤º
                print(f"    æ‹¡å¼µçµæœ: {result.enhanced_text[:50]}...")
                print(f"    å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸æ•°: {len(result.processing_stages)}")
                print(f"    ç·å‡¦ç†æ™‚é–“: {result.total_processing_time_ms:.1f}ms")
                print(f"    å“è³ªæ”¹å–„: {result.quality_metrics.get('quality_improvement', 0):.3f}")
                print(f"    æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
                
                # ã‚¹ãƒ†ãƒ¼ã‚¸è©³ç´°
                for stage_name, stage_data in result.processing_stages.items():
                    status_icon = "âœ…" if stage_data.get('success', False) else "âŒ"
                    print(f"      {status_icon} {stage_name}: {stage_data.get('processing_time_ms', 0):.1f}ms")
                
        except Exception as e:
            print(f"âŒ Integration Manager ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"Integration Manager test error: {e}")
    
    def _run_performance_benchmarks(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        try:
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨­å®š
            benchmark_iterations = 3
            
            # Advanced Tensor Processing ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("  ğŸ”¬ Advanced Tensor Processing ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            processor = create_advanced_nkat_processor({
                'tensor_dimension': 256,
                'max_iterations': 10
            })
            
            tensor_times = []
            for iteration in range(benchmark_iterations):
                start_time = time.time()
                for test_case in self.test_cases[:3]:  # æœ€åˆã®3ã‚±ãƒ¼ã‚¹
                    processor.process_expression(
                        test_case['text'],
                        test_case['character'],
                        test_case['context']
                    )
                iteration_time = (time.time() - start_time) * 1000
                tensor_times.append(iteration_time)
                print(f"    åå¾© {iteration+1}: {iteration_time:.1f}ms")
            
            # Integration Manager ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("\n  ğŸ¯ Integration Manager ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            manager = create_nkat_integration_manager()
            
            integration_times = []
            for iteration in range(benchmark_iterations):
                start_time = time.time()
                for test_case in self.test_cases[:3]:
                    manager.process_text_comprehensive(
                        test_case['text'],
                        test_case['character'],
                        test_case['context']
                    )
                iteration_time = (time.time() - start_time) * 1000
                integration_times.append(iteration_time)
                print(f"    åå¾© {iteration+1}: {iteration_time:.1f}ms")
            
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜
            benchmark_results = {
                'tensor_processing': {
                    'times_ms': tensor_times,
                    'average_ms': sum(tensor_times) / len(tensor_times),
                    'min_ms': min(tensor_times),
                    'max_ms': max(tensor_times)
                },
                'integration_manager': {
                    'times_ms': integration_times,
                    'average_ms': sum(integration_times) / len(integration_times),
                    'min_ms': min(integration_times),
                    'max_ms': max(integration_times)
                }
            }
            
            self.test_results['performance_benchmarks'].append(benchmark_results)
            
            # çµæœè¡¨ç¤º
            print(f"\n  ğŸ“ˆ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:")
            print(f"    Tensor Processing å¹³å‡: {benchmark_results['tensor_processing']['average_ms']:.1f}ms")
            print(f"    Integration Manager å¹³å‡: {benchmark_results['integration_manager']['average_ms']:.1f}ms")
            
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _measure_quality_improvements(self):
        """å“è³ªæ”¹å–„ã®æ¸¬å®š"""
        try:
            # å“è³ªæ¸¬å®šã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            processor = create_advanced_nkat_processor()
            manager = create_nkat_integration_manager()
            
            quality_comparisons = []
            
            for test_case in self.test_cases:
                print(f"  ğŸ“ å“è³ªæ¸¬å®š: {test_case['id']}")
                
                # 1. åŸæ–‡ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
                baseline_quality = self._calculate_text_quality(test_case['text'])
                
                # 2. Advanced Tensor Processing
                tensor_enhanced, tensor_metrics = processor.process_expression(
                    test_case['text'],
                    test_case['character'],
                    test_case['context']
                )
                tensor_quality = self._calculate_text_quality(tensor_enhanced)
                
                # 3. Integration Managerï¼ˆå…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆï¼‰
                integration_result = manager.process_text_comprehensive(
                    test_case['text'],
                    test_case['character'],
                    test_case['context']
                )
                integration_quality = self._calculate_text_quality(integration_result.enhanced_text)
                
                comparison = {
                    'test_case_id': test_case['id'],
                    'baseline_quality': baseline_quality,
                    'tensor_quality': tensor_quality,
                    'integration_quality': integration_quality,
                    'tensor_improvement': tensor_quality - baseline_quality,
                    'integration_improvement': integration_quality - baseline_quality,
                    'tensor_vs_integration': integration_quality - tensor_quality
                }
                
                quality_comparisons.append(comparison)
                
                # çµæœè¡¨ç¤º
                print(f"    ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å“è³ª: {baseline_quality:.3f}")
                print(f"    Tensorå‡¦ç†å“è³ª: {tensor_quality:.3f} (æ”¹å–„: {comparison['tensor_improvement']:+.3f})")
                print(f"    çµ±åˆå‡¦ç†å“è³ª: {integration_quality:.3f} (æ”¹å–„: {comparison['integration_improvement']:+.3f})")
                print(f"    çµ±åˆå„ªä½æ€§: {comparison['tensor_vs_integration']:+.3f}")
                print()
            
            self.test_results['quality_measurements'] = quality_comparisons
            
            # å…¨ä½“çµ±è¨ˆ
            avg_tensor_improvement = sum(c['tensor_improvement'] for c in quality_comparisons) / len(quality_comparisons)
            avg_integration_improvement = sum(c['integration_improvement'] for c in quality_comparisons) / len(quality_comparisons)
            
            print(f"  ğŸ“Š å“è³ªæ”¹å–„çµ±è¨ˆ:")
            print(f"    Tensor Processing å¹³å‡æ”¹å–„: {avg_tensor_improvement:+.3f}")
            print(f"    Integration Manager å¹³å‡æ”¹å–„: {avg_integration_improvement:+.3f}")
            
        except Exception as e:
            print(f"âŒ å“è³ªæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _calculate_text_quality(self, text: str) -> float:
        """ç°¡æ˜“çš„ãªãƒ†ã‚­ã‚¹ãƒˆå“è³ªè¨ˆç®—"""
        if not text:
            return 0.0
        
        # åŸºæœ¬æŒ‡æ¨™
        words = text.split()
        unique_words = set(words)
        
        # èªå½™å¤šæ§˜æ€§
        vocabulary_diversity = len(unique_words) / max(len(words), 1)
        
        # æ–‡ã®å¤šæ§˜æ€§ï¼ˆç°¡æ˜“ï¼‰
        sentences = text.split('ã€‚')
        sentence_lengths = [len(s.split()) for s in sentences if s.strip()]
        sentence_diversity = len(set(sentence_lengths)) / max(len(sentence_lengths), 1)
        
        # åå¾©åº¦ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
        repetition_penalty = 0.0
        for word in unique_words:
            count = words.count(word)
            if count > 2:
                repetition_penalty += (count - 2) * 0.1
        
        # ç·åˆå“è³ªã‚¹ã‚³ã‚¢
        quality_score = (vocabulary_diversity * 0.4 + 
                        sentence_diversity * 0.3 + 
                        0.3) - min(repetition_penalty, 0.5)
        
        return max(0.0, min(1.0, quality_score))
    
    def _test_system_coordination(self):
        """ã‚·ã‚¹ãƒ†ãƒ å”èª¿ãƒ†ã‚¹ãƒˆ"""
        try:
            print("  ğŸ”— ã‚·ã‚¹ãƒ†ãƒ å”èª¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
            
            # ç•°ãªã‚‹è¨­å®šã§ã®çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
            configs = [
                {'name': 'å…¨ã‚·ã‚¹ãƒ†ãƒ æœ‰åŠ¹', 'config': {}},
                {'name': 'Tensor Processing ã®ã¿', 'config': {
                    'integration_systems': {
                        'repetition_suppression': False,
                        'lora_coordination': False,
                        'cross_suppression': False
                    }
                }},
                {'name': 'Legacy ã‚·ã‚¹ãƒ†ãƒ ç„¡åŠ¹', 'config': {
                    'nkat_legacy': {'enabled': False}
                }}
            ]
            
            coordination_results = []
            
            for config_set in configs:
                print(f"\n    è¨­å®š: {config_set['name']}")
                manager = create_nkat_integration_manager(config_set['config'])
                
                status = manager.get_system_status()
                active_count = sum(status['active_systems'].values())
                coordination_efficiency = status['system_coordination']['coordination_efficiency']
                
                # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§å‡¦ç†æ™‚é–“æ¸¬å®š
                test_case = self.test_cases[0]  # æœ€åˆã®ã‚±ãƒ¼ã‚¹
                start_time = time.time()
                result = manager.process_text_comprehensive(
                    test_case['text'],
                    test_case['character'],
                    test_case['context']
                )
                processing_time = (time.time() - start_time) * 1000
                
                coordination_result = {
                    'config_name': config_set['name'],
                    'active_systems': active_count,
                    'coordination_efficiency': coordination_efficiency,
                    'processing_time_ms': processing_time,
                    'quality_improvement': result.quality_metrics.get('quality_improvement', 0),
                    'success': result.success
                }
                
                coordination_results.append(coordination_result)
                
                print(f"      ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚·ã‚¹ãƒ†ãƒ : {active_count}/5")
                print(f"      å”èª¿åŠ¹ç‡: {coordination_efficiency:.1%}")
                print(f"      å‡¦ç†æ™‚é–“: {processing_time:.1f}ms")
                print(f"      å“è³ªæ”¹å–„: {coordination_result['quality_improvement']:.3f}")
            
            self.test_results['system_coordination_tests'] = coordination_results
            
        except Exception as e:
            print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ å”èª¿ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _compile_test_results(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆçµæœã®é›†è¨ˆ"""
        print("\nğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœé›†è¨ˆ")
        print("=" * 50)
        
        # æˆåŠŸç‡è¨ˆç®—
        tensor_success_rate = self._calculate_success_rate(self.test_results['advanced_tensor_tests'])
        integration_success_rate = self._calculate_success_rate(self.test_results['integration_manager_tests'])
        
        # å¹³å‡å“è³ªæ”¹å–„
        avg_quality_improvement = 0.0
        if self.test_results['quality_measurements']:
            avg_quality_improvement = sum(
                q['integration_improvement'] for q in self.test_results['quality_measurements']
            ) / len(self.test_results['quality_measurements'])
        
        # å¹³å‡å‡¦ç†æ™‚é–“
        avg_processing_time = 0.0
        if self.test_results['performance_benchmarks']:
            benchmark = self.test_results['performance_benchmarks'][0]
            avg_processing_time = benchmark['integration_manager']['average_ms']
        
        # ã‚·ã‚¹ãƒ†ãƒ å”èª¿åŠ¹ç‡
        coordination_efficiency = 0.0
        if self.test_results['system_coordination_tests']:
            coordination_efficiency = max(
                c['coordination_efficiency'] for c in self.test_results['system_coordination_tests']
            )
        
        final_results = {
            'success': True,
            'test_summary': {
                'total_test_cases': len(self.test_cases),
                'tensor_success_rate': tensor_success_rate,
                'integration_success_rate': integration_success_rate,
                'average_quality_improvement': avg_quality_improvement,
                'average_processing_time_ms': avg_processing_time,
                'coordination_efficiency': coordination_efficiency
            },
            'detailed_results': self.test_results,
            'phase3_readiness': self._assess_phase3_readiness()
        }
        
        # çµæœè¡¨ç¤º
        print(f"  âœ… Advanced Tensor Processing æˆåŠŸç‡: {tensor_success_rate:.1%}")
        print(f"  âœ… Integration Manager æˆåŠŸç‡: {integration_success_rate:.1%}")
        print(f"  ğŸ“ˆ å¹³å‡å“è³ªæ”¹å–„: {avg_quality_improvement:+.3f}")
        print(f"  âš¡ å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.1f}ms")
        print(f"  ğŸ”— å”èª¿åŠ¹ç‡: {coordination_efficiency:.1%}")
        
        return final_results
    
    def _calculate_success_rate(self, test_results: List[Dict]) -> float:
        """æˆåŠŸç‡è¨ˆç®—"""
        if not test_results:
            return 0.0
        
        successful = sum(1 for result in test_results if result.get('success', False))
        return successful / len(test_results)
    
    def _assess_phase3_readiness(self) -> Dict[str, Any]:
        """Phase 3 æº–å‚™çŠ¶æ³è©•ä¾¡"""
        readiness_criteria = {
            'tensor_processing_functional': False,
            'integration_manager_functional': False,
            'quality_improvement_achieved': False,
            'performance_acceptable': False,
            'system_coordination_working': False
        }
        
        # åŸºæº–è©•ä¾¡
        if self.test_results['advanced_tensor_tests']:
            tensor_success = self._calculate_success_rate(self.test_results['advanced_tensor_tests'])
            readiness_criteria['tensor_processing_functional'] = tensor_success >= 0.8
        
        if self.test_results['integration_manager_tests']:
            integration_success = self._calculate_success_rate(self.test_results['integration_manager_tests'])
            readiness_criteria['integration_manager_functional'] = integration_success >= 0.8
        
        if self.test_results['quality_measurements']:
            avg_improvement = sum(q['integration_improvement'] for q in self.test_results['quality_measurements']) / len(self.test_results['quality_measurements'])
            readiness_criteria['quality_improvement_achieved'] = avg_improvement > 0.1
        
        if self.test_results['performance_benchmarks']:
            benchmark = self.test_results['performance_benchmarks'][0]
            avg_time = benchmark['integration_manager']['average_ms']
            readiness_criteria['performance_acceptable'] = avg_time < 5000  # 5ç§’ä»¥å†…
        
        if self.test_results['system_coordination_tests']:
            max_efficiency = max(c['coordination_efficiency'] for c in self.test_results['system_coordination_tests'])
            readiness_criteria['system_coordination_working'] = max_efficiency >= 0.6
        
        overall_readiness = sum(readiness_criteria.values()) / len(readiness_criteria)
        
        return {
            'criteria': readiness_criteria,
            'overall_readiness_score': overall_readiness,
            'phase3_ready': overall_readiness >= 0.8,
            'recommendation': self._get_readiness_recommendation(readiness_criteria)
        }
    
    def _get_readiness_recommendation(self, criteria: Dict[str, bool]) -> str:
        """æº–å‚™çŠ¶æ³ã«åŸºã¥ãæ¨å¥¨äº‹é …"""
        failed_criteria = [k for k, v in criteria.items() if not v]
        
        if not failed_criteria:
            return "Phase 3 å®Ÿè£…æº–å‚™å®Œäº† âœ…"
        elif len(failed_criteria) <= 2:
            return f"è»½å¾®ãªèª¿æ•´ãŒå¿…è¦: {', '.join(failed_criteria)}"
        else:
            return f"é‡è¦ãªæ”¹å–„ãŒå¿…è¦: {', '.join(failed_criteria)}"


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸš€ NKAT Phase 3 çµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢")
    print("=" * 70)
    print("é«˜åº¦ãªéå¯æ›ãƒ†ãƒ³ã‚½ãƒ«å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¨çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®æ¤œè¨¼")
    print()
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    test_suite = NKATPhase3TestSuite()
    results = test_suite.run_comprehensive_tests()
    
    # æœ€çµ‚è©•ä¾¡
    print("\nğŸ¯ Phase 3 æº–å‚™çŠ¶æ³è©•ä¾¡")
    print("=" * 50)
    
    if results['success']:
        readiness = results['phase3_readiness']
        print(f"ğŸ“Š ç·åˆæº–å‚™åº¦: {readiness['overall_readiness_score']:.1%}")
        print(f"ğŸ¯ Phase 3 æº–å‚™çŠ¶æ³: {'âœ… æº–å‚™å®Œäº†' if readiness['phase3_ready'] else 'âš ï¸ èª¿æ•´å¿…è¦'}")
        print(f"ğŸ’¡ æ¨å¥¨äº‹é …: {readiness['recommendation']}")
        
        print("\nğŸ“‹ æº–å‚™åŸºæº–è©³ç´°:")
        for criterion, status in readiness['criteria'].items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"  {status_icon} {criterion.replace('_', ' ').title()}")
        
        # çµæœä¿å­˜
        output_file = f"nkat_phase3_test_results_{int(time.time())}.json"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_file}")
        except Exception as e:
            print(f"âš ï¸ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
        if 'error' in results:
            print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {results['error']}")
    
    print("\nâœ… NKAT Phase 3 çµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢å®Œäº†")


if __name__ == "__main__":
    main() 