# -*- coding: utf-8 -*-
"""
åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  v3 ã‚¯ã‚¤ãƒƒã‚¯ãƒ‡ãƒ¢
æˆåŠŸç‡80%é”æˆã®ãŸã‚ã®ã€Œãƒ©ã‚¹ãƒˆ21.7ptã€æ”¹å–„ç‰ˆ

ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¾‹:
python demo_repetition_v3_quick.py --sim 0.50 --max_dist 50 --ngram 4 --min_compress 0.05 --drp-base 1.05 --drp-alpha 0.4
"""

import argparse
import json
import os
import sys
import time
from typing import Dict, List

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
sys.path.insert(0, src_dir)

try:
    from utils.repetition_suppressor_v3 import AdvancedRepetitionSuppressorV3, SuppressionMetricsV3
    print("âœ… v3ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    print(f"âŒ v3ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    print("   v2ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
    from utils.repetition_suppressor import AdvancedRepetitionSuppressor, SuppressionMetrics
    
    # v3äº’æ›ãƒ¬ã‚¤ãƒ¤ãƒ¼
    class AdvancedRepetitionSuppressorV3(AdvancedRepetitionSuppressor):
        def suppress_repetitions_with_debug_v3(self, text, character_name=None):
            result, metrics = self.suppress_repetitions_with_debug(text, character_name)
            # v3ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¸ã®å¤‰æ›
            v3_metrics = type('SuppressionMetricsV3', (), {
                'input_length': metrics.input_length,
                'output_length': metrics.output_length,
                'patterns_detected': metrics.patterns_detected,
                'patterns_suppressed': metrics.patterns_suppressed,
                'detection_misses': metrics.detection_misses,
                'over_compressions': metrics.over_compressions,
                'processing_time_ms': metrics.processing_time_ms,
                'success_rate': metrics.success_rate,
                'ngram_blocks_applied': 0,
                'mecab_normalizations': 0,
                'rhetorical_exceptions': 0,
                'latin_number_blocks': 0,
                'min_compress_rate': 0.05
            })()
            return result, v3_metrics
    
    SuppressionMetricsV3 = SuppressionMetrics


def create_v3_test_cases() -> List[Dict]:
    """v3å¼·åŒ–ç‰ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆ80%é”æˆç”¨ï¼‰"""
    return [
        # === åŸºæœ¬åŒèªåå¾©ï¼ˆv3é‡ç‚¹å¯¾è±¡ï¼‰ ===
        {
            "name": "åŸºæœ¬åŒèªåå¾©",
            "input": "ãŠå…„ã¡ã‚ƒã‚“ãŠå…„ã¡ã‚ƒã‚“ã€ã©ã“ã«è¡Œãã®ã§ã™ã‹ãŠå…„ã¡ã‚ƒã‚“ï¼Ÿ",
            "character": "å¦¹",
            "expected_patterns": ["ãŠå…„ã¡ã‚ƒã‚“"],
            "category": "same_word",
            "target_compression": 0.15
        },
        {
            "name": "é–¢è¥¿å¼åŒèªåå¾©",
            "input": "ãã‚„ãã‚„ãã‚„ã€ã‚ã‹ã‚“ã‚ã‹ã‚“ã‚ã‹ã‚“ã€ã‚„ãªã‚„ãªãã‚Œã¯ã€‚",
            "character": "é–¢è¥¿å¼ã‚­ãƒ£ãƒ©",
            "expected_patterns": ["ãã‚„", "ã‚ã‹ã‚“", "ã‚„ãª"],
            "category": "dialect",
            "target_compression": 0.20
        },
        {
            "name": "èªå°¾åå¾©è¤‡åˆ",
            "input": "ã§ã™ã§ã™ã­ã€ã¾ã™ã¾ã™ã‚ˆã€ã§ã—ã‚‡ã§ã—ã‚‡ã†ã€‚",
            "character": "ä¸å¯§èªã‚­ãƒ£ãƒ©",
            "expected_patterns": ["ã§ã™", "ã¾ã™", "ã§ã—ã‚‡"],
            "category": "ending",
            "target_compression": 0.10
        },
        
        # === 4-gramãƒ–ãƒ­ãƒƒã‚¯å¯¾è±¡ ===
        {
            "name": "4-gramåå¾©",
            "input": "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã ã‹ã‚‰æ•£æ­©ã—ã¾ã—ã‚‡ã†ã€‚",
            "character": "æ™®é€šã®äºº",
            "expected_patterns": ["ä»Šæ—¥ã¯è‰¯ã„"],
            "category": "ngram",
            "target_compression": 0.08
        },
        
        # === ãƒ©ãƒ†ãƒ³æ–‡å­—ãƒ»æ•°å­—é€£ç•ª ===
        {
            "name": "é€£ç•ªåå¾©",
            "input": "wwwwwwã€ãã†ã§ã™ã­ã€‚777777ã£ã¦æ•°å­—ã§ã™ã‹ï¼Ÿ",
            "character": "ãƒãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼",
            "expected_patterns": ["wwwwww", "777777"],
            "category": "latin_number",
            "target_compression": 0.12
        },
        
        # === ä¿®è¾çš„ä¾‹å¤–ä¿è­·ãƒ†ã‚¹ãƒˆ ===
        {
            "name": "ä¿®è¾çš„åå¾©ä¿è­·",
            "input": "ã­ãˆã€ã­ãˆã€ã­ãˆï¼èã„ã¦ã‚ˆã€‚",
            "character": "æ„Ÿæƒ…çš„ã‚­ãƒ£ãƒ©",
            "expected_patterns": [],  # ä¿è­·ã•ã‚Œã‚‹ã¹ã
            "category": "rhetorical",
            "target_compression": 0.0  # åœ§ç¸®ã•ã‚Œãªã„
        },
        {
            "name": "éŸ³è±¡å¾´èªä¿è­·",
            "input": "ãƒ‰ã‚­ãƒ‰ã‚­ã—ã¡ã‚ƒã†ã€‚ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã­ï¼",
            "character": "å…ƒæ°—ã‚­ãƒ£ãƒ©",
            "expected_patterns": [],  # ä¿è­·ã•ã‚Œã‚‹ã¹ã
            "category": "onomatopoeia",
            "target_compression": 0.0
        },
        
        # === è¤‡é›‘ã‚±ãƒ¼ã‚¹ ===
        {
            "name": "è¤‡åˆåå¾©",
            "input": "å¬‰ã—ã„å¬‰ã—ã„ã€æ¥½ã—ã„æ¥½ã—ã„ã€å¹¸ã›å¹¸ã›ã¨ã„ã†æ„Ÿã˜ã§ã™ã§ã™ã€‚",
            "character": "ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚­ãƒ£ãƒ©",
            "expected_patterns": ["å¬‰ã—ã„", "æ¥½ã—ã„", "å¹¸ã›", "ã§ã™"],
            "category": "complex",
            "target_compression": 0.15
        },
        {
            "name": "æ„Ÿå˜†è©éå¤š",
            "input": "ã‚ã‚ã‚ã‚ã‚ã‚ã‚ï¼ã†ã‚ã‚ã‚ã‚ã‚ã‚ã‚ï¼ãã‚ƒã‚ã‚ã‚ã‚ã‚ã‚ï¼",
            "character": "æ„Ÿæƒ…è±Šã‹ã‚­ãƒ£ãƒ©",
            "expected_patterns": ["ã‚ã‚ã‚ã‚ã‚ã‚ã‚", "ã†ã‚ã‚ã‚ã‚ã‚ã‚ã‚", "ãã‚ƒã‚ã‚ã‚ã‚ã‚ã‚"],
            "category": "interjection",
            "target_compression": 0.25
        },
        
        # === å¢ƒç•Œã‚±ãƒ¼ã‚¹ ===
        {
            "name": "çŸ­æ–‡åå¾©",
            "input": "ã¯ã„ã€ã¯ã„ã€ã¯ã„ã€‚",
            "character": "ç›¸æ§Œã‚­ãƒ£ãƒ©",
            "expected_patterns": ["ã¯ã„"],
            "category": "short",
            "target_compression": 0.20
        }
    ]


def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ"""
    parser = argparse.ArgumentParser(description='åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  v3 ã‚¯ã‚¤ãƒƒã‚¯ãƒ‡ãƒ¢')
    
    # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--sim', type=float, default=0.50, help='é¡ä¼¼åº¦é–¾å€¤ (default: 0.50)')
    parser.add_argument('--max_dist', type=int, default=50, help='æœ€å¤§æ¤œå‡ºè·é›¢ (default: 50)')
    parser.add_argument('--min_compress', type=float, default=0.05, help='æœ€å°åœ§ç¸®ç‡ (default: 0.05)')
    
    # v3æ–°æ©Ÿèƒ½
    parser.add_argument('--ngram', type=int, default=4, help='n-gramãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º (default: 4)')
    parser.add_argument('--drp-base', type=float, default=1.05, help='DRPåŸºæº–å€¤ (default: 1.05)')
    parser.add_argument('--drp-alpha', type=float, default=0.4, help='DRPã‚¢ãƒ«ãƒ•ã‚¡å€¤ (default: 0.4)')
    parser.add_argument('--enable-mecab', action='store_true', help='MeCabæ­£è¦åŒ–ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--disable-rhetorical', action='store_true', help='ä¿®è¾çš„ä¿è­·ã‚’ç„¡åŠ¹åŒ–')
    
    # å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument('--target-rate', type=float, default=0.80, help='ç›®æ¨™æˆåŠŸç‡ (default: 0.80)')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°å‡ºåŠ›')
    parser.add_argument('--save-report', type=str, help='ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å')
    
    return parser.parse_args()


def create_v3_config(args) -> Dict:
    """å¼•æ•°ã‹ã‚‰v3è¨­å®šã‚’æ§‹ç¯‰"""
    return {
        'similarity_threshold': args.sim,
        'max_distance': args.max_dist,
        'min_compress_rate': args.min_compress,
        'enable_4gram_blocking': args.ngram > 0,
        'ngram_block_size': args.ngram,
        'enable_drp': True,
        'drp_base': args.drp_base,
        'drp_alpha': args.drp_alpha,
        'enable_mecab_normalization': args.enable_mecab,
        'enable_rhetorical_protection': not args.disable_rhetorical,
        'enable_aggressive_mode': True,
        'debug_mode': args.verbose,
        'min_repeat_threshold': 1,
        'enable_latin_number_detection': True
    }


def run_v3_quick_test(config: Dict, test_cases: List[Dict], target_success_rate: float = 0.8) -> Dict:
    """v3ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print(f"ğŸš€ åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  v3 ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"   ç›®æ¨™æˆåŠŸç‡: {target_success_rate:.1%}")
    print(f"   ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {len(test_cases)}ä»¶")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    suppressor = AdvancedRepetitionSuppressorV3(config)
    
    results = []
    category_stats = {}
    
    start_time = time.time()
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {test_case['name']}")
        
        # å‡¦ç†å®Ÿè¡Œ
        result_text, metrics = suppressor.suppress_repetitions_with_debug_v3(
            test_case['input'], 
            test_case['character']
        )
        
        # æˆåŠŸåˆ¤å®šï¼ˆv3åŸºæº–ï¼‰
        compression_rate = (metrics.input_length - metrics.output_length) / metrics.input_length
        meets_compression_target = compression_rate >= test_case.get('target_compression', config['min_compress_rate'])
        success = metrics.success_rate >= 0.7 and meets_compression_target  # v3ã§ã¯70%+åœ§ç¸®é”æˆã‚’æˆåŠŸã¨ã™ã‚‹
        
        # çµæœè¨˜éŒ²
        test_result = {
            'test_case': test_case['name'],
            'category': test_case['category'],
            'success': success,
            'success_rate': metrics.success_rate,
            'compression_rate': compression_rate,
            'target_compression': test_case.get('target_compression', config['min_compress_rate']),
            'input_length': metrics.input_length,
            'output_length': metrics.output_length,
            'patterns_detected': metrics.patterns_detected,
            'patterns_suppressed': metrics.patterns_suppressed,
            'processing_time_ms': metrics.processing_time_ms,
            'input_text': test_case['input'][:50] + "..." if len(test_case['input']) > 50 else test_case['input'],
            'output_text': result_text[:50] + "..." if len(result_text) > 50 else result_text,
            'v3_features': {
                'ngram_blocks': getattr(metrics, 'ngram_blocks_applied', 0),
                'mecab_normalizations': getattr(metrics, 'mecab_normalizations', 0),
                'rhetorical_exceptions': getattr(metrics, 'rhetorical_exceptions', 0),
                'latin_blocks': getattr(metrics, 'latin_number_blocks', 0)
            }
        }
        
        results.append(test_result)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category = test_case['category']
        if category not in category_stats:
            category_stats[category] = {'total': 0, 'success': 0}
        category_stats[category]['total'] += 1
        if success:
            category_stats[category]['success'] += 1
        
        # çµæœè¡¨ç¤º
        status_icon = "âœ…" if success else "âŒ"
        print(f"   {status_icon} æˆåŠŸç‡: {metrics.success_rate:.1%}, åœ§ç¸®ç‡: {compression_rate:.1%}")
        
        if config.get('debug_mode', False):
            print(f"      å…¥åŠ›: {test_case['input'][:40]}...")
            print(f"      å‡ºåŠ›: {result_text[:40]}...")
            print(f"      å‡¦ç†æ™‚é–“: {metrics.processing_time_ms:.1f}ms")
            
            # v3æ©Ÿèƒ½ã®ä½¿ç”¨çŠ¶æ³
            v3_features = test_result['v3_features']
            if any(v3_features.values()):
                print(f"      v3æ©Ÿèƒ½: 4-gram={v3_features['ngram_blocks']}, MeCab={v3_features['mecab_normalizations']}, ä¿®è¾={v3_features['rhetorical_exceptions']}, é€£ç•ª={v3_features['latin_blocks']}")
    
    total_time = time.time() - start_time
    
    # ç·åˆçµ±è¨ˆ
    total_tests = len(results)
    total_success = sum(1 for r in results if r['success'])
    overall_success_rate = total_success / total_tests if total_tests > 0 else 0
    
    avg_compression = sum(r['compression_rate'] for r in results) / total_tests if total_tests > 0 else 0
    avg_processing_time = sum(r['processing_time_ms'] for r in results) / total_tests if total_tests > 0 else 0
    
    # v3æ©Ÿèƒ½çµ±è¨ˆ
    total_ngram_blocks = sum(r['v3_features']['ngram_blocks'] for r in results)
    total_mecab_normalizations = sum(r['v3_features']['mecab_normalizations'] for r in results)
    total_rhetorical_exceptions = sum(r['v3_features']['rhetorical_exceptions'] for r in results)
    total_latin_blocks = sum(r['v3_features']['latin_blocks'] for r in results)
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š v3ã‚·ã‚¹ãƒ†ãƒ ç·åˆçµæœ")
    print(f"   æˆåŠŸç‡: {overall_success_rate:.1%} ({total_success}/{total_tests})")
    print(f"   ç›®æ¨™é”æˆ: {'ğŸ‰ é”æˆï¼' if overall_success_rate >= target_success_rate else 'âŒ æœªé”'}")
    print(f"   å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1%}")
    print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.1f}ms")
    print(f"   ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
    
    print(f"\nğŸ”§ v3æ©Ÿèƒ½ä½¿ç”¨çŠ¶æ³:")
    print(f"   4-gramãƒ–ãƒ­ãƒƒã‚¯: {total_ngram_blocks}å›")
    print(f"   MeCabæ­£è¦åŒ–: {total_mecab_normalizations}å›")
    print(f"   ä¿®è¾çš„ä¾‹å¤–: {total_rhetorical_exceptions}å›")
    print(f"   é€£ç•ªé™¤å»: {total_latin_blocks}å›")
    
    print(f"\nğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥æˆåŠŸç‡:")
    for category, stats in category_stats.items():
        success_rate = stats['success'] / stats['total']
        print(f"   {category}: {success_rate:.1%} ({stats['success']}/{stats['total']})")
    
    # å¤±æ•—ã‚±ãƒ¼ã‚¹ã®åˆ†æ
    failed_cases = [r for r in results if not r['success']]
    if failed_cases:
        print(f"\nâŒ å¤±æ•—ã‚±ãƒ¼ã‚¹åˆ†æ ({len(failed_cases)}ä»¶):")
        for case in failed_cases:
            print(f"   - {case['test_case']}: æˆåŠŸç‡{case['success_rate']:.1%}, åœ§ç¸®ç‡{case['compression_rate']:.1%}")
    
    # æ”¹å–„ææ¡ˆ
    if overall_success_rate < target_success_rate:
        gap = target_success_rate - overall_success_rate
        print(f"\nğŸ” æ”¹å–„ææ¡ˆï¼ˆæ®‹ã‚Š{gap:.1%}ptï¼‰:")
        
        if avg_compression < config['min_compress_rate']:
            print(f"   - åœ§ç¸®ç‡å‘ä¸Š: ç¾åœ¨{avg_compression:.1%} â†’ ç›®æ¨™{config['min_compress_rate']:.1%}")
            print(f"     â†’ similarity_threshold ã‚’ {config['similarity_threshold']:.2f} â†’ {max(0.3, config['similarity_threshold'] - 0.1):.2f} ã«ä¸‹ã’ã‚‹")
        
        worst_category = min(category_stats.items(), key=lambda x: x[1]['success'] / x[1]['total'])
        print(f"   - æœ€å¼±ã‚«ãƒ†ã‚´ãƒª: {worst_category[0]} ({worst_category[1]['success']}/{worst_category[1]['total']})")
        
        if total_ngram_blocks == 0:
            print(f"   - 4-gramãƒ–ãƒ­ãƒƒã‚¯æœªä½¿ç”¨ â†’ ngram_block_size ã‚’3ã«ä¸‹ã’ã‚‹")
        
        if total_rhetorical_exceptions > total_success // 2:
            print(f"   - ä¿®è¾çš„ä¾‹å¤–ãŒå¤šã™ã â†’ enable_rhetorical_protection=False ã‚’æ¤œè¨")
    
    # è¨­å®šæœ€é©åŒ–ææ¡ˆ
    print(f"\nâš™ï¸ æ¬¡å›æ¨å¥¨è¨­å®š:")
    optimized_config = dict(config)
    if overall_success_rate < target_success_rate:
        optimized_config['similarity_threshold'] = max(0.3, config['similarity_threshold'] - 0.05)
        if avg_compression < config['min_compress_rate']:
            optimized_config['min_compress_rate'] = max(0.03, config['min_compress_rate'] - 0.01)
    
    print(f"   --sim {optimized_config['similarity_threshold']:.2f} --max_dist {optimized_config['max_distance']} --ngram {optimized_config.get('ngram_block_size', 4)} --min_compress {optimized_config['min_compress_rate']:.2f} --drp-base {optimized_config['drp_base']:.2f} --drp-alpha {optimized_config['drp_alpha']:.1f}")
    
    return {
        'overall_success_rate': overall_success_rate,
        'target_achievement': overall_success_rate >= target_success_rate,
        'total_tests': total_tests,
        'total_success': total_success,
        'average_compression_rate': avg_compression,
        'average_processing_time_ms': avg_processing_time,
        'total_processing_time_s': total_time,
        'v3_feature_usage': {
            'ngram_blocks': total_ngram_blocks,
            'mecab_normalizations': total_mecab_normalizations,
            'rhetorical_exceptions': total_rhetorical_exceptions,
            'latin_blocks': total_latin_blocks
        },
        'category_stats': category_stats,
        'failed_cases': failed_cases,
        'optimized_config': optimized_config,
        'config_used': config,
        'detailed_results': results
    }


def save_report(report: Dict, filename: str):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        os.makedirs('logs/v3_tests', exist_ok=True)
        filepath = f'logs/v3_tests/{filename}'
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {filepath}")
    except Exception as e:
        print(f"\nâŒ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    args = parse_args()
    
    print("ğŸ”¥ åå¾©æŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  v3 - ã€Œãƒ©ã‚¹ãƒˆ21.7ptã€å¼·åŒ–ç‰ˆ")
    print("   58.3% â†’ 80% é”æˆã‚’ç›®æŒ‡ã—ã¾ã™ï¼")
    print("=" * 60)
    
    # è¨­å®šæ§‹ç¯‰
    config = create_v3_config(args)
    
    print("âš™ï¸ v3è¨­å®š:")
    print(f"   é¡ä¼¼åº¦é–¾å€¤: {config['similarity_threshold']}")
    print(f"   æœ€å¤§è·é›¢: {config['max_distance']}")
    print(f"   æœ€å°åœ§ç¸®ç‡: {config['min_compress_rate']:.1%}")
    print(f"   4-gramãƒ–ãƒ­ãƒƒã‚¯: {config['enable_4gram_blocking']} (ã‚µã‚¤ã‚º: {config.get('ngram_block_size', 0)})")
    print(f"   DRP: base={config['drp_base']}, alpha={config['drp_alpha']}")
    print(f"   MeCab: {config['enable_mecab_normalization']}")
    print(f"   ä¿®è¾çš„ä¿è­·: {config['enable_rhetorical_protection']}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æº–å‚™
    test_cases = create_v3_test_cases()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    report = run_v3_quick_test(config, test_cases, args.target_rate)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    if args.save_report:
        save_report(report, args.save_report)
    
    # æœ€çµ‚åˆ¤å®š
    if report['target_achievement']:
        print(f"\nğŸ‰ ç›®æ¨™é”æˆï¼ æˆåŠŸç‡ {report['overall_success_rate']:.1%} â‰¥ {args.target_rate:.1%}")
        print("   80%ãƒ©ã‚¤ãƒ³ã«åˆ°é”ã—ã¾ã—ãŸï¼ğŸ”¥")
    else:
        gap = args.target_rate - report['overall_success_rate']
        print(f"\nğŸ“ˆ ã‚ã¨{gap:.1%}pt ã§ç›®æ¨™é”æˆã§ã™")
        print("   æ¬¡å›æ¨å¥¨è¨­å®šã§å†ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ãã ã•ã„")
    
    return 0 if report['target_achievement'] else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 